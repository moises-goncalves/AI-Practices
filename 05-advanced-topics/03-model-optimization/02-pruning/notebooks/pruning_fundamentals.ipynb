{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 剪枝基础理论与实现\n",
        "\n",
        "**SOTA 教育标准** | 包含剪枝原理、重要性评估、非结构化剪枝实现\n",
        "\n",
        "---\n",
        "\n",
        "## 1. 剪枝核心原理\n",
        "\n",
        "### 1.1 为什么剪枝？\n",
        "\n",
        "**过参数化问题**: 现代神经网络存在大量冗余参数。\n",
        "\n",
        "**剪枝目标**:\n",
        "- 减少模型大小（存储）\n",
        "- 加速推理（计算）\n",
        "- 降低能耗（部署）\n",
        "\n",
        "### 1.2 剪枝分类\n",
        "\n",
        "| 类型 | 粒度 | 硬件友好 | 压缩率 |\n",
        "|:-----|:-----|:--------:|:------:|\n",
        "| 非结构化 | 单个权重 | 低 | 高 |\n",
        "| 结构化 | 通道/层 | 高 | 中 |\n",
        "| 半结构化 | N:M 稀疏 | 中 | 中 |\n",
        "\n",
        "### 1.3 重要性评估\n",
        "\n",
        "**基于幅度**: $\\text{Importance}(w) = |w|$\n",
        "\n",
        "**基于梯度**: $\\text{Importance}(w) = |w \\cdot \\nabla_w L|$\n",
        "\n",
        "**基于 Hessian**: $\\text{Importance}(w) = w^2 \\cdot H_{ww}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. 非结构化剪枝实现"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "@dataclass\nclass PruningConfig:\n    \"\"\"剪枝配置。\"\"\"\n    sparsity: float = 0.5  # 目标稀疏度\n    method: str = \"magnitude\"  # magnitude, gradient, random\n    scope: str = \"global\"  # global, local"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "class MagnitudePruner:\n    \"\"\"基于幅度的剪枝器。\n\n    Core Idea:\n        移除绝对值最小的权重。\n\n    Mathematical Theory:\n        mask = |w| > threshold\n        threshold = quantile(|w|, sparsity)\n\n    Summary:\n        简单有效，是最常用的剪枝方法。\n    \"\"\"\n\n    def __init__(self, model: nn.Module, config: PruningConfig):\n        self.model = model\n        self.config = config\n        self.masks: Dict[str, Tensor] = {}\n\n    def compute_threshold(self, weights: List[Tensor]) -> float:\n        \"\"\"计算全局剪枝阈值。\"\"\"\n        all_weights = torch.cat([w.abs().flatten() for w in weights])\n        threshold = torch.quantile(all_weights, self.config.sparsity)\n        return threshold.item()\n\n    def prune(self) -> Dict[str, float]:\n        \"\"\"执行剪枝。\"\"\"\n        weights = [p for n, p in self.model.named_parameters() if p.dim() > 1]\n        threshold = self.compute_threshold(weights)\n\n        stats = {}\n        for name, param in self.model.named_parameters():\n            if param.dim() > 1:\n                mask = (param.abs() > threshold).float()\n                self.masks[name] = mask\n                param.data *= mask\n                sparsity = 1 - mask.mean().item()\n                stats[name] = sparsity\n\n        return stats\n    def __init__(self, model: nn.Module, config: PruningConfig):\n        self.model = model\n        self.config = config\n        self.masks: Dict[str, Tensor] = {}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. 可视化分析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_pruning(model: nn.Module, sparsity: float = 0.5) -> None:\n",
        "    \"\"\"可视化剪枝效果。\"\"\"\n",
        "    # 获取第一层权重\n",
        "    weight = list(model.parameters())[0].data.clone()\n",
        "\n",
        "    # 剪枝\n",
        "    threshold = torch.quantile(weight.abs().flatten(), sparsity)\n",
        "    mask = (weight.abs() > threshold).float()\n",
        "    weight_pruned = weight * mask\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    # 原始权重分布\n",
        "    axes[0].hist(weight.flatten().numpy(), bins=50, alpha=0.7)\n",
        "    axes[0].axvline(-threshold.item(), color='r', linestyle='--', label='Threshold')\n",
        "    axes[0].axvline(threshold.item(), color='r', linestyle='--')\n",
        "    axes[0].set_title('Original Weight Distribution')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 剪枝后分布\n",
        "    axes[1].hist(weight_pruned.flatten().numpy(), bins=50, alpha=0.7, color='orange')\n",
        "    axes[1].set_title(f'After Pruning ({sparsity*100:.0f}% sparse)')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    # 掩码可视化\n",
        "    axes[2].imshow(mask[:32, :32].numpy(), cmap='binary')\n",
        "    axes[2].set_title('Pruning Mask (32x32)')\n",
        "    axes[2].colorbar(ax=axes[2], label='Keep (1) / Prune (0)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 创建新模型并可视化\n",
        "model = nn.Linear(128, 64)\n",
        "visualize_pruning(model, sparsity=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. 总结\n",
        "\n",
        "| 概念 | 公式/方法 | 说明 |\n",
        "|:-----|:---------|:-----|\n",
        "| **幅度剪枝** | $\\text{mask} = |w| > \\theta$ | 移除小权重 |\n",
        "| **全局剪枝** | 所有层统一阈值 | 更均衡 |\n",
        "| **局部剪枝** | 每层独立阈值 | 保持层结构 |\n",
        "\n",
        "**关键点**:\n",
        "1. 非结构化剪枝压缩率高但硬件不友好\n",
        "2. 幅度剪枝简单有效\n",
        "3. 剪枝后需要微调恢复精度"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}