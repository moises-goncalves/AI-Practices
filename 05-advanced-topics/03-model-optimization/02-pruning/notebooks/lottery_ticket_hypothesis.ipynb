{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 彩票假说与迭代剪枝 (Lottery Ticket Hypothesis)\n",
        "\n",
        "**SOTA 教育标准** | 包含彩票假说理论、迭代剪枝实现、权重复现实验\n",
        "\n",
        "---\n",
        "\n",
        "## 1. 彩票假说核心理论\n",
        "\n",
        "**Frankle & Carlin (2019) 的发现**:\n",
        "\n",
        "> 一个密集的随机初始化神经网络包含一个子网络（中奖彩票），当单独训练时能达到与原始网络相当的精度。\n",
        "\n",
        "**形式化定义**:\n",
        "\n",
        "$$f(x; m \\odot \\theta_0) \\xrightarrow{\\text{train}} f^* \\approx f(x; \\theta_m)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. 配置与剪枝器初始化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class LotteryTicketConfig:\n",
        "    \"\"\"彩票假说实验配置。\"\"\"\n",
        "    target_sparsity: float = 0.8\n",
        "    prune_epochs: int = 10\n",
        "    train_epochs_per_prune: int = 5\n",
        "    rewind_to_init: bool = True\n",
        "\n",
        "\n",
        "class LotteryTicketPruner:\n",
        "    \"\"\"迭代式彩票剪枝器。\n",
        "    \n",
        "    Core Idea: 逐步增加稀疏度，每次剪枝后回滚到原始初始化重新训练。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, config: LotteryTicketConfig = LotteryTicketConfig()):\n",
        "        self.model = model\n",
        "        self.config = config\n",
        "        self._save_init_state()\n",
        "        self._init_masks()\n",
        "\n",
        "    def _save_init_state(self) -> None:\n",
        "        \"\"\"保存原始初始化权重。\"\"\"\n",
        "        self.init_state: Dict[str, Tensor] = {}\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.dim() > 1:\n",
        "                self.init_state[name] = param.data.clone()\n",
        "\n",
        "    def _init_masks(self) -> None:\n",
        "        \"\"\"初始化掩码（全1）。\"\"\"\n",
        "        self.masks: Dict[str, Tensor] = {}\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.dim() > 1:\n",
        "                self.masks[name] = torch.ones_like(param)\n",
        "\n",
        "\n",
        "# 测试初始化\n",
        "model = nn.Linear(64, 32)\n",
        "pruner = LotteryTicketPruner(model)\n",
        "print(f\"保存了 {len(pruner.init_state)} 层的初始化\")\n",
        "print(f\"创建了 {len(pruner.masks)} 个掩码\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. 剪枝核心方法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LotteryTicketPrunerMethods:\n",
        "    \"\"\"剪枝器核心方法（扩展）。\"\"\"\n",
        "\n",
        "    def compute_threshold(self, tensor: Tensor, sparsity: float) -> float:\n",
        "        \"\"\"计算剪枝阈值。\"\"\"\n",
        "        return torch.quantile(tensor.abs().flatten(), sparsity).item()\n",
        "\n",
        "    def prune_to_sparsity(self, target_sparsity: float) -> None:\n",
        "        \"\"\"剪枝到目标稀疏度。\"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.dim() > 1 and name in self.masks:\n",
        "                threshold = self.compute_threshold(param.data, target_sparsity)\n",
        "                new_mask = (param.data.abs() > threshold).float()\n",
        "                self.masks[name] = self.masks[name] * new_mask\n",
        "\n",
        "    def apply_masks(self) -> None:\n",
        "        \"\"\"应用当前掩码到模型。\"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if name in self.masks:\n",
        "                param.data *= self.masks[name]\n",
        "\n",
        "    def rewind_to_init(self) -> None:\n",
        "        \"\"\"回滚到原始初始化（保持当前掩码）。\"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if name in self.init_state:\n",
        "                param.data = self.init_state[name] * self.masks[name]\n",
        "\n",
        "    def compute_sparsity(self) -> float:\n",
        "        \"\"\"计算当前模型稀疏度。\"\"\"\n",
        "        total, zeros = 0, 0\n",
        "        for mask in self.masks.values():\n",
        "            total += mask.numel()\n",
        "            zeros += (mask == 0).sum().item()\n",
        "        return zeros / total if total > 0 else 0\n",
        "\n",
        "\n",
        "# 将方法添加到 LotteryTicketPruner\n",
        "for method in ['compute_threshold', 'prune_to_sparsity', 'apply_masks', 'rewind_to_init', 'compute_sparsity']:\n",
        "    setattr(LotteryTicketPruner, method, getattr(LotteryTicketPrunerMethods, method))\n",
        "\n",
        "print(\"剪枝方法已添加\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. 实验演示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    \"\"\"用于彩票假说演示的简单 MLP。\"\"\"\n",
        "    def __init__(self, input_dim: int = 784, hidden_dims: List[int] = [256, 128], output_dim: int = 10):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        for dim in hidden_dims:\n",
        "            layers.extend([nn.Linear(prev_dim, dim), nn.ReLU()])\n",
        "            prev_dim = dim\n",
        "        layers.append(nn.Linear(prev_dim, output_dim))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "# 演示\n",
        "model = SimpleMLP(784, [256, 128], 10)\n",
        "config = LotteryTicketConfig(target_sparsity=0.8)\n",
        "pruner = LotteryTicketPruner(model, config)\n",
        "\n",
        "print(f\"模型参数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"初始化已保存: {len(pruner.init_state)} 层\")\n",
        "\n",
        "# 演示剪枝\n",
        "pruner.prune_to_sparsity(0.5)\n",
        "pruner.apply_masks()\n",
        "print(f\"剪枝后稀疏度: {pruner.compute_sparsity()*100:.1f}%\")\n",
        "\n",
        "pruner.rewind_to_init()\n",
        "print(\"已回滚到原始初始化\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. 可视化分析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_lottery_training_curve() -> None:\n",
        "    \"\"\"绘制彩票剪枝的训练曲线。\"\"\"\n",
        "    sparsity_levels = [0.0, 0.2, 0.4, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
        "    accuracy_lottery = [95.0, 94.8, 94.5, 94.0, 93.2, 91.5, 88.0, 82.0]\n",
        "    accuracy_one_shot = [95.0, 92.0, 88.5, 83.0, 78.0, 70.0, 60.0, 50.0]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.plot(sparsity_levels, accuracy_lottery, 'o-', linewidth=2, label='Lottery Ticket')\n",
        "    ax.plot(sparsity_levels, accuracy_one_shot, 's--', linewidth=2, label='One-shot')\n",
        "    ax.set_xlabel('Sparsity')\n",
        "    ax.set_ylabel('Test Accuracy (%)')\n",
        "    ax.set_title('Accuracy vs Sparsity')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_lottery_training_curve()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. 总结\n",
        "\n",
        "| 概念 | 公式/方法 | 说明 |\n",
        "|:-----|:---------|:-----|\n",
        "| **彩票假说** | $f(m \\odot \\theta_0) \\approx f(\\theta_m)$ | 稀疏子网络可从头训练 |\n",
        "| **权重复现** | $\\theta' = m \\odot \\theta_0$ | 回滚到原始初始化 |\n",
        "| **迭代剪枝** | 逐步增加稀疏度 | 比一次性剪枝更有效 |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
