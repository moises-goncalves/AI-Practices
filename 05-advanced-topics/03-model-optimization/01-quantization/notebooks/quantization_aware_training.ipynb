{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 量化感知训练 (Quantization-Aware Training, QAT)\n",
        "\n",
        "**SOTA 教育标准** | 包含 QAT 原理、伪量化、STE 梯度估计、完整训练流程\n",
        "\n",
        "---\n",
        "\n",
        "## 1. QAT 核心原理\n",
        "\n",
        "### 1.1 为什么需要 QAT？\n",
        "\n",
        "**PTQ 的局限性**:\n",
        "- 低比特量化（INT4/INT2）精度损失大\n",
        "- 对异常值敏感\n",
        "- 无法恢复量化引入的误差\n",
        "\n",
        "**QAT 的优势**:\n",
        "- 训练时模拟量化效果\n",
        "- 网络学习适应量化噪声\n",
        "- 可达到接近 FP32 的精度\n",
        "\n",
        "### 1.2 伪量化 (Fake Quantization)\n",
        "\n",
        "**核心思想**: 前向传播模拟量化，反向传播使用 STE。\n",
        "\n",
        "$$\\text{FakeQuant}(x) = s \\cdot \\text{clip}(\\text{round}(x/s), q_{min}, q_{max})$$\n",
        "\n",
        "**前向**: 量化 -> 反量化（模拟量化误差）\n",
        "**反向**: 直通估计器 (Straight-Through Estimator)\n",
        "\n",
        "### 1.3 STE 梯度估计\n",
        "\n",
        "**问题**: `round()` 函数梯度为零，无法反向传播。\n",
        "\n",
        "**解决方案**: Straight-Through Estimator\n",
        "\n",
        "$$\\frac{\\partial \\text{FakeQuant}(x)}{\\partial x} \\approx \\mathbf{1}_{x \\in [q_{min} \\cdot s, q_{max} \\cdot s]}$$\n",
        "\n",
        "即：在量化范围内，梯度直通；超出范围，梯度为零。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. STE 实现"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StraightThroughEstimator(torch.autograd.Function):\n",
        "    \"\"\"直通估计器 (STE)。\n",
        "\n",
        "    Core Idea:\n",
        "        前向传播执行量化，反向传播直接传递梯度。\n",
        "\n",
        "    Mathematical Theory:\n",
        "        Forward: y = round(x)\n",
        "        Backward: dx = dy (直通)\n",
        "\n",
        "    Summary:\n",
        "        这是 QAT 能够工作的关键技术。\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x: Tensor, scale: Tensor, zero_point: Tensor, qmin: int, qmax: int) -> Tensor:\n",
        "        # 量化\n",
        "        x_int = torch.round(x / scale + zero_point)\n",
        "        x_int = torch.clamp(x_int, qmin, qmax)\n",
        "        # 反量化\n",
        "        x_q = (x_int - zero_point) * scale\n",
        "        # 保存用于反向传播\n",
        "        ctx.save_for_backward(x, scale)\n",
        "        ctx.qmin = qmin\n",
        "        ctx.qmax = qmax\n",
        "        return x_q\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output: Tensor) -> Tuple[Tensor, None, None, None, None]:\n",
        "        x, scale = ctx.saved_tensors\n",
        "        # STE: 在量化范围内直通梯度\n",
        "        x_normalized = x / scale\n",
        "        mask = (x_normalized >= ctx.qmin) & (x_normalized <= ctx.qmax)\n",
        "        grad_input = grad_output * mask.float()\n",
        "        return grad_input, None, None, None, None\n",
        "\n",
        "\n",
        "# 测试 STE\n",
        "x = torch.randn(4, requires_grad=True)\n",
        "scale = torch.tensor(0.1)\n",
        "zero_point = torch.tensor(0.0)\n",
        "\n",
        "x_q = StraightThroughEstimator.apply(x, scale, zero_point, -128, 127)\n",
        "loss = x_q.sum()\n",
        "loss.backward()\n",
        "\n",
        "print(f\"Input: {x.data}\")\n",
        "print(f\"Quantized: {x_q.data}\")\n",
        "print(f\"Gradient: {x.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. QAT 模块实现"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FakeQuantize(nn.Module):\n",
        "    \"\"\"伪量化模块。\n",
        "\n",
        "    Core Idea:\n",
        "        在训练时模拟量化效果，使网络适应量化噪声。\n",
        "\n",
        "    Mathematical Theory:\n",
        "        y = scale * clip(round(x/scale + zp), qmin, qmax) - zp * scale\n",
        "\n",
        "    Complexity:\n",
        "        Time: O(n)\n",
        "        Space: O(1) 额外空间\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, bits: int = 8, symmetric: bool = True):\n",
        "        super().__init__()\n",
        "        self.bits = bits\n",
        "        self.symmetric = symmetric\n",
        "\n",
        "        if symmetric:\n",
        "            self.qmin = -(2 ** (bits - 1))\n",
        "            self.qmax = 2 ** (bits - 1) - 1\n",
        "        else:\n",
        "            self.qmin = 0\n",
        "            self.qmax = 2 ** bits - 1\n",
        "\n",
        "        # 可学习的量化参数\n",
        "        self.register_buffer(\"scale\", torch.tensor(1.0))\n",
        "        self.register_buffer(\"zero_point\", torch.tensor(0.0))\n",
        "        self.register_buffer(\"initialized\", torch.tensor(False))\n",
        "\n",
        "    def update_params(self, x: Tensor) -> None:\n",
        "        \"\"\"更新量化参数。\"\"\"\n",
        "        with torch.no_grad():\n",
        "            x_min, x_max = x.min(), x.max()\n",
        "            if self.symmetric:\n",
        "                max_abs = max(abs(x_min), abs(x_max))\n",
        "                self.scale.fill_(max_abs / self.qmax if max_abs > 0 else 1.0)\n",
        "                self.zero_point.fill_(0.0)\n",
        "            else:\n",
        "                self.scale.fill_((x_max - x_min) / (self.qmax - self.qmin))\n",
        "                self.zero_point.fill_(self.qmin - x_min / self.scale)\n",
        "            self.initialized.fill_(True)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        if self.training and not self.initialized:\n",
        "            self.update_params(x)\n",
        "        return StraightThroughEstimator.apply(\n",
        "            x, self.scale, self.zero_point, self.qmin, self.qmax\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class QATLinear(nn.Module):\n",
        "    \"\"\"QAT 线性层。\n",
        "\n",
        "    Core Idea:\n",
        "        在训练时对权重和激活值进行伪量化。\n",
        "\n",
        "    Summary:\n",
        "        这是 QAT 的核心组件，训练后可直接导出为 INT8 模型。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features: int, out_features: int, bias: bool = True, bits: int = 8):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "        self.weight_fake_quant = FakeQuantize(bits=bits, symmetric=True)\n",
        "        self.activation_fake_quant = FakeQuantize(bits=bits, symmetric=False)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # 量化权重\n",
        "        w_q = self.weight_fake_quant(self.linear.weight)\n",
        "        # 量化激活\n",
        "        x_q = self.activation_fake_quant(x)\n",
        "        # 线性运算\n",
        "        return F.linear(x_q, w_q, self.linear.bias)\n",
        "\n",
        "\n",
        "# 测试\n",
        "qat_layer = QATLinear(64, 32)\n",
        "x = torch.randn(8, 64)\n",
        "y = qat_layer(x)\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {y.shape}\")\n",
        "print(f\"Weight scale: {qat_layer.weight_fake_quant.scale.item():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. QAT 训练流程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleQATModel(nn.Module):\n",
        "    \"\"\"简单的 QAT 模型示例。\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim: int = 784, hidden_dim: int = 256, output_dim: int = 10):\n",
        "        super().__init__()\n",
        "        self.fc1 = QATLinear(input_dim, hidden_dim)\n",
        "        self.fc2 = QATLinear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "\n",
        "def train_qat_model(model: nn.Module, epochs: int = 5) -> list:\n",
        "    \"\"\"QAT 训练函数。\"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses = []\n",
        "\n",
        "    # 模拟训练数据\n",
        "    for epoch in range(epochs):\n",
        "        x = torch.randn(32, 784)\n",
        "        y = torch.randint(0, 10, (32,))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return losses\n",
        "\n",
        "\n",
        "# 训练\n",
        "model = SimpleQATModel()\n",
        "losses = train_qat_model(model, epochs=10)\n",
        "\n",
        "# 可视化\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(losses, 'b-o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('QAT Training Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. 总结\n",
        "\n",
        "| 概念 | 公式/方法 | 说明 |\n",
        "|:-----|:---------|:-----|\n",
        "| **伪量化** | $\\text{FQ}(x) = s \\cdot \\text{clip}(\\text{round}(x/s), q_{min}, q_{max})$ | 模拟量化效果 |\n",
        "| **STE** | $\\frac{\\partial y}{\\partial x} = 1$ (范围内) | 直通梯度估计 |\n",
        "| **QAT 优势** | 训练时适应量化噪声 | 精度接近 FP32 |\n",
        "\n",
        "**关键点**:\n",
        "1. QAT 在训练时模拟量化效果\n",
        "2. STE 解决了 round() 不可导的问题\n",
        "3. QAT 适合低比特量化（INT4/INT2）\n",
        "4. 训练后可直接导出为量化模型"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
