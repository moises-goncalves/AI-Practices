{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TensorRT 推理优化\n",
        "\n",
        "**SOTA 教育标准** | 包含 TensorRT 基础、INT8 量化、性能优化\n",
        "\n",
        "---\n",
        "\n",
        "## 1. TensorRT 概述\n",
        "\n",
        "**TensorRT**: NVIDIA 高性能深度学习推理优化器\n",
        "\n",
        "| 优化 | 说明 | 加速 |\n",
        "|:-----|:-----|:----:|\n",
        "| **层融合** | Conv+BN+ReLU → 单kernel | 1.5-2x |\n",
        "| **精度校准** | FP32 → FP16/INT8 | 2-4x |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "TRT_AVAILABLE = False\n",
        "try:\n",
        "    import tensorrt as trt\n",
        "    print(f\"TensorRT: {trt.__version__}\")\n",
        "    TRT_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"TensorRT not installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. TensorRT 配置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TensorRTConfig:\n",
        "    \"\"\"TensorRT 构建配置。\"\"\"\n",
        "    precision: str = \"fp16\"  # fp32, fp16, int8\n",
        "    max_batch_size: int = 16\n",
        "    max_workspace_size: int = 1 << 30  # 1GB\n",
        "\n",
        "\n",
        "class TensorRTBuilder:\n",
        "    \"\"\"TensorRT 引擎构建器。\n",
        "    \n",
        "    Core Idea: 将 ONNX 模型转换为优化的 TensorRT 引擎。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: TensorRTConfig = TensorRTConfig()):\n",
        "        self.config = config\n",
        "        if TRT_AVAILABLE:\n",
        "            self.logger = trt.Logger(trt.Logger.WARNING)\n",
        "            self.builder = trt.Builder(self.logger)\n",
        "\n",
        "    def build_from_onnx(self, onnx_path: str) -> Optional[bytes]:\n",
        "        \"\"\"从 ONNX 构建 TensorRT 引擎。\"\"\"\n",
        "        if not TRT_AVAILABLE:\n",
        "            print(\"TensorRT not available\")\n",
        "            return None\n",
        "        print(f\"Building TensorRT engine from {onnx_path}\")\n",
        "        return None  # 实际实现需要完整的 TensorRT API\n",
        "\n",
        "\n",
        "# 测试\n",
        "builder = TensorRTBuilder()\n",
        "print(f\"配置: {builder.config}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. INT8 量化校准"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class INT8Calibrator:\n",
        "    \"\"\"INT8 量化校准器。\n",
        "    \n",
        "    Core Idea: 使用校准数据集确定最优的量化参数。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data: np.ndarray, batch_size: int = 32):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.current_idx = 0\n",
        "\n",
        "    def get_batch(self) -> Optional[np.ndarray]:\n",
        "        \"\"\"获取下一批校准数据。\"\"\"\n",
        "        if self.current_idx >= len(self.data):\n",
        "            return None\n",
        "        end = min(self.current_idx + self.batch_size, len(self.data))\n",
        "        batch = self.data[self.current_idx:end]\n",
        "        self.current_idx = end\n",
        "        return batch\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_idx = 0\n",
        "\n",
        "\n",
        "# 测试\n",
        "cal_data = np.random.randn(100, 3, 32, 32).astype(np.float32)\n",
        "calibrator = INT8Calibrator(cal_data)\n",
        "batch = calibrator.get_batch()\n",
        "print(f\"校准批次形状: {batch.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. INT8 量化模拟"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_int8(tensor: np.ndarray, method: str = \"minmax\") -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"模拟 INT8 量化。\"\"\"\n",
        "    if method == \"minmax\":\n",
        "        scale = max(abs(tensor.min()), abs(tensor.max())) / 127\n",
        "    else:  # percentile\n",
        "        scale = np.percentile(np.abs(tensor), 99.9) / 127\n",
        "    \n",
        "    quantized = np.clip(np.round(tensor / scale), -128, 127).astype(np.int8)\n",
        "    dequantized = quantized.astype(np.float32) * scale\n",
        "    error = np.abs(tensor - dequantized).mean()\n",
        "    return dequantized, error\n",
        "\n",
        "\n",
        "# 测试\n",
        "activations = np.random.randn(1000).astype(np.float32)\n",
        "for method in [\"minmax\", \"percentile\"]:\n",
        "    _, error = simulate_int8(activations, method)\n",
        "    print(f\"{method}: Mean Error = {error:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. 性能可视化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_tensorrt_speedup() -> None:\n",
        "    \"\"\"可视化 TensorRT 加速效果。\"\"\"\n",
        "    models = [\"ResNet-50\", \"VGG-16\", \"BERT\", \"YOLOv5\"]\n",
        "    pytorch = [15.2, 22.5, 45.0, 12.0]\n",
        "    trt_fp16 = [4.2, 6.5, 15.0, 4.0]\n",
        "    trt_int8 = [2.8, 4.2, 10.0, 2.5]\n",
        "\n",
        "    x = np.arange(len(models))\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    \n",
        "    ax.bar(x - 0.25, pytorch, 0.25, label='PyTorch', color='blue')\n",
        "    ax.bar(x, trt_fp16, 0.25, label='TRT FP16', color='orange')\n",
        "    ax.bar(x + 0.25, trt_int8, 0.25, label='TRT INT8', color='red')\n",
        "    \n",
        "    ax.set_xlabel('Model')\n",
        "    ax.set_ylabel('Latency (ms)')\n",
        "    ax.set_title('TensorRT Speedup')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(models)\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    for i, m in enumerate(models):\n",
        "        print(f\"{m}: PyTorch {pytorch[i]}ms → INT8 {trt_int8[i]}ms ({pytorch[i]/trt_int8[i]:.1f}x)\")\n",
        "\n",
        "\n",
        "visualize_tensorrt_speedup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. 总结\n",
        "\n",
        "| 精度 | 加速 | 精度损失 | 适用场景 |\n",
        "|:-----|:----:|:--------:|:---------|\n",
        "| **FP16** | 2-3x | <0.1% | 通用推理 |\n",
        "| **INT8** | 3-5x | <1% | 高吞吐量 |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
