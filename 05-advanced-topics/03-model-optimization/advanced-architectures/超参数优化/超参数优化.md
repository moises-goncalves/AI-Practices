# 超参数优化 (Hyperparameter Optimization)

## 核心概念

超参数是在模型训练之前设定的参数，它们控制着学习过程本身，而不是通过训练学习得到。超参数优化是寻找最优超参数组合以最大化模型性能的系统性方法。

### 常见超参数类型

**模型架构参数：**
- 网络层数、每层神经元数
- 卷积核大小、数量
- Dropout比例

**训练参数：**
- 学习率 (Learning Rate)
- 批次大小 (Batch Size)
- 训练轮数 (Epochs)
- 优化器类型及其参数（momentum, beta等）

**正则化参数：**
- L1/L2正则化系数
- Dropout率
- Early Stopping patience

## 超参数优化流程

### 标准流程

1. **定义搜索空间**
   ```python
   search_space = {
       'learning_rate': [0.001, 0.01, 0.1],
       'batch_size': [32, 64, 128],
       'hidden_units': [64, 128, 256],
       'dropout_rate': [0.2, 0.3, 0.5]
   }
   ```

2. **构建模型**：根据超参数创建模型实例

3. **训练与评估**：在训练集上拟合，在验证集上评估

4. **选择下一组超参数**：根据优化策略决定

5. **迭代**：重复步骤2-4，直到满足停止条件

6. **最终训练**：使用最优超参数在完整训练集上训练

7. **测试评估**：在独立测试集上评估最终模型

8. **部署**：将最优模型部署到生产环境

### 关键注意事项

**数据划分的重要性：**
- 训练集：用于模型参数学习
- 验证集：用于超参数选择和模型评估
- 测试集：最终性能评估（不可用于调参）

**避免过拟合验证集：**
- 多次在验证集上调参会导致间接过拟合
- 使用交叉验证可以缓解这个问题
- 保留独立的测试集进行最终评估

## 常用超参数优化方法

### 1. 网格搜索 (Grid Search)

遍历所有参数组合：

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'learning_rate': [0.001, 0.01, 0.1],
    'batch_size': [32, 64, 128],
    'dropout_rate': [0.2, 0.3, 0.5]
}

# 总计: 3 × 3 × 3 = 27 种组合
```

**优点：**
- 穷举所有可能，不会遗漏
- 适合参数空间较小的情况
- 容易并行化

**缺点：**
- 计算成本随维度指数增长
- 对连续参数不够高效
- 很多组合可能是次优的

**适用场景：**
- 参数数量少（≤4个）
- 参数取值范围明确
- 计算资源充足

### 2. 随机搜索 (Random Search)

随机采样参数组合：

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform, randint

param_distributions = {
    'learning_rate': uniform(0.0001, 0.1),  # 连续分布
    'batch_size': [32, 64, 128, 256],       # 离散选择
    'dropout_rate': uniform(0.1, 0.5)       # 连续分布
}

random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_distributions,
    n_iter=50,  # 尝试50次
    cv=5,
    random_state=42
)
```

**优点：**
- 对高维空间更高效
- 可以处理连续参数
- 容易控制计算预算

**缺点：**
- 可能错过最优解
- 没有利用历史信息

**适用场景：**
- 参数空间较大
- 有连续参数
- 计算预算有限

### 3. 贝叶斯优化 (Bayesian Optimization)

使用概率模型指导搜索：

```python
from bayes_opt import BayesianOptimization

def model_evaluate(learning_rate, dropout_rate, hidden_units):
    # 构建和评估模型
    model = create_model(
        learning_rate=learning_rate,
        dropout_rate=dropout_rate,
        hidden_units=int(hidden_units)
    )
    score = train_and_evaluate(model)
    return score

optimizer = BayesianOptimization(
    f=model_evaluate,
    pbounds={
        'learning_rate': (0.0001, 0.1),
        'dropout_rate': (0.1, 0.5),
        'hidden_units': (32, 256)
    },
    random_state=42
)

optimizer.maximize(
    init_points=5,   # 随机探索点数
    n_iter=25        # 优化迭代次数
)
```

**优点：**
- 利用历史信息指导搜索
- 对昂贵评估函数很高效
- 平衡探索与利用

**缺点：**
- 对高维空间可能效果降低
- 需要更多计算开销（代理模型）

**适用场景：**
- 模型训练成本高
- 参数空间中等维度（≤20维）
- 追求更好的优化效率

### 4. 遗传算法 (Genetic Algorithms)

模拟自然选择过程：

```python
from deap import base, creator, tools, algorithms

# 定义适应度函数
def evaluate_individual(individual):
    learning_rate, batch_size, dropout_rate = individual
    # 训练和评估模型
    score = train_model(learning_rate, batch_size, dropout_rate)
    return (score,)

# 设置遗传算法
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)

toolbox = base.Toolbox()
toolbox.register("individual", tools.initIterate, creator.Individual,
                 lambda: [random.uniform(0.0001, 0.1),    # learning_rate
                         random.choice([32, 64, 128]),     # batch_size
                         random.uniform(0.1, 0.5)])        # dropout_rate

# 运行遗传算法
population = toolbox.population(n=50)
algorithms.eaSimple(population, toolbox, cxpb=0.7, mutpb=0.2, ngen=20)
```

**优点：**
- 适合复杂的搜索空间
- 能够逃离局部最优
- 高度可并行化

**缺点：**
- 需要调整多个算法参数
- 收敛可能较慢

### 5. Hyperband / ASHA

基于连续减半的早停策略：

```python
from ray import tune
from ray.tune.schedulers import ASHAScheduler

# 定义训练函数
def train_model(config):
    model = create_model(config)
    for epoch in range(config['max_epochs']):
        # 训练一个epoch
        train_one_epoch(model)
        # 在验证集上评估
        val_score = evaluate(model)
        # 报告中间结果
        tune.report(score=val_score)

# 配置ASHA调度器
scheduler = ASHAScheduler(
    max_t=100,          # 最大训练轮数
    grace_period=10,    # 最小训练轮数
    reduction_factor=3  # 淘汰比例
)

# 运行超参数搜索
analysis = tune.run(
    train_model,
    config={
        'learning_rate': tune.loguniform(1e-4, 1e-1),
        'batch_size': tune.choice([32, 64, 128]),
        'dropout_rate': tune.uniform(0.1, 0.5)
    },
    num_samples=50,
    scheduler=scheduler,
    metric='score',
    mode='max'
)
```

**优点：**
- 自动早停表现差的配置
- 大幅节省计算资源
- 特别适合深度学习

**缺点：**
- 可能过早淘汰慢启动的配置

### 6. 人口基优化 (Population Based Training, PBT)

动态调整超参数：

```python
from ray.tune.schedulers import PopulationBasedTraining

pbt_scheduler = PopulationBasedTraining(
    time_attr='training_iteration',
    metric='val_accuracy',
    mode='max',
    perturbation_interval=5,
    hyperparam_mutations={
        'learning_rate': lambda: np.random.uniform(0.0001, 0.01),
        'dropout_rate': lambda: np.random.uniform(0.1, 0.5)
    }
)
```

**优点：**
- 在训练过程中调整超参数
- 探索和利用并行进行
- 特别适合长时间训练的模型

### 7. Optuna框架

现代化的超参数优化库：

```python
import optuna

def objective(trial):
    # 建议超参数
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    hidden_units = trial.suggest_int('hidden_units', 32, 256, step=32)

    # 构建和训练模型
    model = create_model(learning_rate, batch_size, dropout_rate, hidden_units)
    score = train_and_evaluate(model)

    return score

# 创建研究对象
study = optuna.create_study(
    direction='maximize',
    sampler=optuna.samplers.TPESampler(),  # 贝叶斯优化
    pruner=optuna.pruners.MedianPruner()   # 早停策略
)

# 运行优化
study.optimize(objective, n_trials=100, timeout=3600)

# 查看最佳结果
print(f"最佳参数: {study.best_params}")
print(f"最佳得分: {study.best_value}")
```

## 使用Keras Tuner进行超参数优化

### 基本示例

```python
import keras_tuner as kt
from tensorflow import keras

def build_model(hp):
    model = keras.Sequential()

    # 调整层数
    for i in range(hp.Int('num_layers', 1, 3)):
        model.add(keras.layers.Dense(
            units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),
            activation='relu'
        ))
        model.add(keras.layers.Dropout(
            rate=hp.Float(f'dropout_{i}', 0, 0.5, step=0.1)
        ))

    model.add(keras.layers.Dense(10, activation='softmax'))

    # 调整学习率
    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

# 创建调优器
tuner = kt.RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=50,
    executions_per_trial=2,  # 每个配置训练2次取平均
    directory='tuner_results',
    project_name='my_project'
)

# 搜索最佳超参数
tuner.search(
    x_train, y_train,
    epochs=10,
    validation_data=(x_val, y_val),
    callbacks=[keras.callbacks.EarlyStopping(patience=3)]
)

# 获取最佳模型
best_model = tuner.get_best_models(num_models=1)[0]
best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]
```

### 高级用法

```python
# 使用Hyperband
tuner = kt.Hyperband(
    build_model,
    objective='val_accuracy',
    max_epochs=50,
    factor=3,
    hyperband_iterations=2,
    directory='hyperband_results'
)

# 使用贝叶斯优化
tuner = kt.BayesianOptimization(
    build_model,
    objective='val_accuracy',
    max_trials=50,
    num_initial_points=10,
    directory='bayesian_results'
)
```

## 超参数调优技巧

### 1. 分阶段调优

```python
# 阶段1：粗调（大范围，少样本）
coarse_search_space = {
    'learning_rate': [1e-4, 1e-3, 1e-2, 1e-1],
    'batch_size': [32, 128, 512]
}

# 阶段2：精调（小范围，多样本）
fine_search_space = {
    'learning_rate': [5e-4, 7e-4, 1e-3, 1.5e-3],  # 围绕最优值
    'batch_size': [96, 128, 160]
}
```

### 2. 使用交叉验证

```python
from sklearn.model_selection import cross_val_score

def evaluate_with_cv(params, n_folds=5):
    scores = []
    kfold = KFold(n_splits=n_folds, shuffle=True)

    for train_idx, val_idx in kfold.split(X_train):
        model = create_model(params)
        model.fit(X_train[train_idx], y_train[train_idx])
        score = model.evaluate(X_train[val_idx], y_train[val_idx])
        scores.append(score)

    return np.mean(scores)
```

### 3. 早停策略

```python
early_stopping = keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    callbacks=[early_stopping],
    epochs=1000  # 设置足够大的值，依赖早停
)
```

### 4. 学习率调度

```python
# 尝试不同的学习率调度策略
lr_schedules = {
    'constant': lambda epoch: 0.001,
    'step_decay': lambda epoch: 0.001 * 0.95 ** (epoch // 10),
    'exponential': lambda epoch: 0.001 * np.exp(-0.1 * epoch),
    'cosine': lambda epoch: 0.001 * (1 + np.cos(epoch * np.pi / epochs)) / 2
}
```

### 5. 参数重要性分析

```python
import optuna

# 使用Optuna的参数重要性分析
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# 分析参数重要性
importance = optuna.importance.get_param_importances(study)
print("参数重要性排序：")
for param, score in importance.items():
    print(f"{param}: {score:.4f}")
```

### 6. 可视化优化过程

```python
import optuna.visualization as vis

# 优化历史
vis.plot_optimization_history(study)

# 参数关系
vis.plot_param_importances(study)

# 并行坐标图
vis.plot_parallel_coordinate(study)

# 切片图
vis.plot_slice(study)
```

## 注意事项

### 常见陷阱

1. **信息泄漏**
   - 不要在测试集上调参
   - 验证集使用过度会导致间接过拟合
   - 解决方案：使用嵌套交叉验证

2. **计算资源浪费**
   - 网格搜索在高维空间效率极低
   - 解决方案：优先使用随机搜索或贝叶斯优化

3. **忽视模型方差**
   - 单次训练结果可能不稳定
   - 解决方案：每个配置训练多次取平均

4. **搜索空间设置不当**
   - 范围太窄：错过最优解
   - 范围太宽：浪费计算资源
   - 解决方案：基于经验和文献确定合理范围

### 最佳实践

1. **从简单开始**
   - 先优化少数关键超参数（如学习率）
   - 逐步增加优化的参数数量

2. **利用领域知识**
   - 基于类似任务的经验设置初始范围
   - 参考相关论文和实践

3. **监控和记录**
   - 记录所有实验配置和结果
   - 使用实验跟踪工具（如MLflow、Weights & Biases）

4. **资源管理**
   - 设置合理的计算预算
   - 使用早停避免浪费
   - 利用并行计算加速

5. **结果验证**
   - 在独立测试集上验证最终模型
   - 检查模型在不同数据分布上的稳定性

## 实用工具对比

| 工具 | 优点 | 缺点 | 适用场景 |
|------|------|------|----------|
| **Keras Tuner** | Keras原生支持，易用 | 功能相对基础 | Keras/TensorFlow项目 |
| **Optuna** | 现代化API，功能丰富 | 需要额外学习 | 通用机器学习项目 |
| **Ray Tune** | 分布式支持好，可扩展性强 | 配置复杂 | 大规模分布式训练 |
| **Hyperopt** | 成熟稳定 | API较老 | 需要TPE算法时 |
| **Scikit-Optimize** | 与scikit-learn集成好 | 主要面向传统ML | scikit-learn项目 |

## 总结

超参数优化是提升模型性能的重要手段：

1. **选择合适的方法**：根据计算预算和问题特点选择
2. **设置合理的搜索空间**：基于经验和领域知识
3. **避免常见陷阱**：注意信息泄漏和过度调优验证集
4. **平衡效率和效果**：在计算成本和优化质量间权衡
5. **系统化管理实验**：使用工具记录和分析所有实验

在实际应用中，超参数优化应该是一个迭代过程，不断积累经验和洞察，逐步提升模型性能。
