{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# 深度可分离卷积 (Depthwise Separable Convolution)\n\n## 核心概念\n\n深度可分离卷积是一种高效的卷积操作，它将标准卷积分解为两个独立的步骤：\n1. **深度卷积 (Depthwise Convolution)**：对每个输入通道独立进行空间卷积\n2. **逐点卷积 (Pointwise Convolution)**：使用1×1卷积整合通道信息\n\n## 为什么使用深度可分离卷积\n\n### 计算效率优势\n\n对于一个标准卷积：\n- 输入：H × W × C_in\n- 卷积核：K × K × C_in × C_out\n- 计算量：H × W × K × K × C_in × C_out\n\n深度可分离卷积的计算量：\n- 深度卷积：H × W × K × K × C_in\n- 逐点卷积：H × W × C_in × C_out\n- 总计算量：H × W × (K² × C_in + C_in × C_out)\n\n**计算量减少比例**：\n$$\\frac{1}{C_{out}} + \\frac{1}{K^2}$$\n\n对于3×3卷积和128个输出通道：约减少 **8-9倍** 的计算量！\n\n### 参数效率优势\n\n- 标准卷积参数量：K × K × C_in × C_out\n- 深度可分离卷积参数量：K × K × C_in + C_in × C_out\n- 参数减少倍数：约 8-9倍（对于3×3卷积）\n\n### 适用场景\n\n- 移动端和嵌入式设备部署\n- 计算资源受限的场景\n- 实时推理需求\n- 大规模模型压缩\n- 轻量级网络架构（如MobileNet、Xception）",
   "id": "6ec50798c25a7f35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.datasets import cifar10\nimport matplotlib.pyplot as plt\n\nprint(f\"TensorFlow版本: {tf.__version__}\")\n\n# 数据准备\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# 数据预处理\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\n\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)\n\nprint(f\"训练集形状: {x_train.shape}\")\nprint(f\"测试集形状: {x_test.shape}\")",
   "id": "32cb631df55f6317"
  },
  {
   "cell_type": "markdown",
   "id": "0emd3gzi8vbs",
   "source": "## 模型对比实验\n\n我们将创建两个CNN模型进行对比：\n1. 使用标准卷积的模型\n2. 使用深度可分离卷积的模型\n\n两个模型将保持相似的架构，以便公平比较它们的性能、参数量和训练速度。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3coezed4rgb",
   "source": "def create_standard_cnn():\n    \"\"\"创建使用标准卷积的模型\"\"\"\n    model = models.Sequential([\n        # 第一个卷积块\n        layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        # 第二个卷积块\n        layers.Conv2D(64, (3, 3), padding='same'),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        # 第三个卷积块\n        layers.Conv2D(128, (3, 3), padding='same'),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        # 全连接层\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(10, activation='softmax')\n    ], name='StandardCNN')\n    \n    return model\n\n\ndef create_separable_cnn():\n    \"\"\"创建使用深度可分离卷积的模型\"\"\"\n    model = models.Sequential([\n        # 第一个卷积块 - 使用SeparableConv2D\n        layers.SeparableConv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        # 第二个卷积块\n        layers.SeparableConv2D(64, (3, 3), padding='same'),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        # 第三个卷积块\n        layers.SeparableConv2D(128, (3, 3), padding='same'),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        # 全连接层\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(10, activation='softmax')\n    ], name='SeparableCNN')\n    \n    return model\n\n\n# 创建两个模型\nmodel_standard = create_standard_cnn()\nmodel_separable = create_separable_cnn()\n\nprint(\"标准卷积模型：\")\nmodel_standard.summary()\n\nprint(\"\\n深度可分离卷积模型：\")\nmodel_separable.summary()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ayrurpta2np",
   "source": "## 参数量和计算量对比\n\n让我们详细比较两个模型的参数量和计算复杂度：",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7ewrpxy1ryu",
   "source": "# 计算参数量\nparams_standard = model_standard.count_params()\nparams_separable = model_separable.count_params()\n\nprint(\"=\" * 60)\nprint(\"模型参数量对比\".center(60))\nprint(\"=\" * 60)\nprint(f\"标准卷积模型参数量:      {params_standard:,} 个\")\nprint(f\"深度可分离卷积模型参数量: {params_separable:,} 个\")\nprint(f\"参数减少比例:            {(1 - params_separable/params_standard)*100:.2f}%\")\nprint(f\"参数减少倍数:            {params_standard/params_separable:.2f}x\")\nprint(\"=\" * 60)\n\n# 分析各层参数\nprint(\"\\n标准卷积层详细分析：\")\nfor layer in model_standard.layers:\n    if 'conv' in layer.name.lower():\n        print(f\"  {layer.name}: {layer.count_params():,} 个参数\")\n\nprint(\"\\n深度可分离卷积层详细分析：\")\nfor layer in model_separable.layers:\n    if 'separable' in layer.name.lower():\n        print(f\"  {layer.name}: {layer.count_params():,} 个参数\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8c312mjnam",
   "source": "## 模型训练\n\n我们使用相同的训练配置来公平比较两个模型：",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "74c8b99th3q",
   "source": "# 编译模型\nmodel_standard.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel_separable.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# 训练参数\nepochs = 20\nbatch_size = 128\nvalidation_split = 0.1\n\nprint(\"开始训练标准卷积模型...\")\nhistory_standard = model_standard.fit(\n    x_train, y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=validation_split,\n    verbose=1\n)\n\nprint(\"\\n开始训练深度可分离卷积模型...\")\nhistory_separable = model_separable.fit(\n    x_train, y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=validation_split,\n    verbose=1\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "99ufhen6i8",
   "source": "## 结果评估与可视化",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "fz2pdsk0xg",
   "source": "# 评估测试集性能\nprint(\"=\" * 60)\nprint(\"测试集性能评估\".center(60))\nprint(\"=\" * 60)\n\ntest_loss_standard, test_acc_standard = model_standard.evaluate(x_test, y_test, verbose=0)\ntest_loss_separable, test_acc_separable = model_separable.evaluate(x_test, y_test, verbose=0)\n\nprint(f\"标准卷积模型:\")\nprint(f\"  测试准确率: {test_acc_standard:.4f}\")\nprint(f\"  测试损失:   {test_loss_standard:.4f}\")\n\nprint(f\"\\n深度可分离卷积模型:\")\nprint(f\"  测试准确率: {test_acc_separable:.4f}\")\nprint(f\"  测试损失:   {test_loss_separable:.4f}\")\n\nprint(f\"\\n性能差异:\")\nprint(f\"  准确率差异: {(test_acc_separable - test_acc_standard)*100:+.2f}%\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "rjmj2b8l8s",
   "source": "# 可视化训练过程\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# 训练准确率对比\naxes[0].plot(history_standard.history['accuracy'], label='训练准确率（标准卷积）', marker='o', alpha=0.7)\naxes[0].plot(history_standard.history['val_accuracy'], label='验证准确率（标准卷积）', marker='o', alpha=0.7)\naxes[0].plot(history_separable.history['accuracy'], label='训练准确率（深度可分离）', marker='s', alpha=0.7)\naxes[0].plot(history_separable.history['val_accuracy'], label='验证准确率（深度可分离）', marker='s', alpha=0.7)\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_title('Model Accuracy Comparison')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# 训练损失对比\naxes[1].plot(history_standard.history['loss'], label='训练损失（标准卷积）', marker='o', alpha=0.7)\naxes[1].plot(history_standard.history['val_loss'], label='验证损失（标准卷积）', marker='o', alpha=0.7)\naxes[1].plot(history_separable.history['loss'], label='训练损失（深度可分离）', marker='s', alpha=0.7)\naxes[1].plot(history_separable.history['val_loss'], label='验证损失（深度可分离）', marker='s', alpha=0.7)\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Loss')\naxes[1].set_title('Model Loss Comparison')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "phvdm1b39cc",
   "source": "## 深度可分离卷积的实现细节\n\n### SeparableConv2D的工作原理\n\n在Keras中，`SeparableConv2D`层实际上是两个操作的组合：\n\n```python\n# 伪代码说明\noutput = DepthwiseConv2D(input)  # 步骤1：深度卷积\noutput = PointwiseConv2D(output)  # 步骤2：1×1卷积\n```\n\n### 关键参数说明\n\n- **depth_multiplier**（默认=1）：控制深度卷积的输出通道数\n  - 实际输出通道数 = input_channels × depth_multiplier\n  - 通常保持默认值1即可\n  \n- **depthwise_regularizer** 和 **pointwise_regularizer**：\n  - 可以分别对两个卷积操作应用正则化\n  \n- **use_bias**：\n  - 通常在使用BatchNormalization时设置为False",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "y2slmq5anys",
   "source": "## 最佳实践与使用建议\n\n### 何时使用深度可分离卷积\n\n**推荐使用的场景：**\n1. **移动端部署**：减少模型大小和计算量，提高推理速度\n2. **资源受限环境**：嵌入式设备、边缘计算\n3. **实时应用**：需要快速推理的场景\n4. **大规模模型**：在保持性能的前提下减小模型体积\n\n**不推荐使用的场景：**\n1. **小型模型**：标准卷积可能更有效\n2. **需要最高精度**：在某些任务上，标准卷积可能表现更好\n3. **低层特征提取**：网络的前几层可能更适合使用标准卷积\n\n### 设计技巧\n\n1. **混合使用**：\n   ```python\n   # 前几层使用标准卷积提取低级特征\n   layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))\n   \n   # 后续层使用深度可分离卷积\n   layers.SeparableConv2D(64, (3, 3), activation='relu')\n   ```\n\n2. **配合BatchNormalization**：\n   ```python\n   layers.SeparableConv2D(filters, kernel_size, use_bias=False)\n   layers.BatchNormalization()\n   layers.Activation('relu')\n   ```\n\n3. **合理选择depth_multiplier**：\n   - 默认值1适用于大多数情况\n   - 增大可以提升表达能力，但会增加计算量\n\n4. **注意输入输出通道比例**：\n   - 当输入通道数较少时，深度可分离卷积优势不明显\n   - 当通道数较多(≥64)时，效率提升显著\n\n### 著名应用案例\n\n- **MobileNet系列**：专为移动设备设计的轻量级网络\n- **Xception**：极端版Inception，大量使用深度可分离卷积\n- **EfficientNet**：在多个维度上平衡模型效率",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "vljmyihpwhc",
   "source": "## 总结\n\n通过本实验，我们观察到深度可分离卷积的以下特点：\n\n### 优势\n1. **参数效率**：相比标准卷积减少约8-9倍参数量\n2. **计算效率**：大幅降低FLOPs，提升推理速度\n3. **性能保持**：在大多数任务上性能损失很小\n4. **可扩展性**：适合构建轻量级和高效的深度网络\n\n### 权衡考虑\n1. **精度轻微下降**：某些任务可能有小幅精度损失\n2. **训练时间**：由于参数更少，可能需要更多epoch达到收敛\n3. **适用范围**：并非所有场景都适合，需要根据具体需求选择\n\n### 实践建议\n- 在资源受限场景优先考虑深度可分离卷积\n- 可以混合使用标准卷积和深度可分离卷积\n- 始终进行实验验证，确保满足精度要求\n- 结合其他优化技术（如量化、剪枝）可以获得更好的效果\n\n深度可分离卷积是模型优化工具箱中的重要技术，特别适合移动端和边缘计算场景。",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}