{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回调函数(Callbacks)实战指南\n",
    "\n",
    "## 核心概念\n",
    "\n",
    "回调函数是在训练过程的特定阶段自动调用的对象，可用于：\n",
    "\n",
    "1. **模型检查点**: 在训练期间的不同时间点保存模型\n",
    "2. **提前终止**: 当验证指标停止改善时中断训练\n",
    "3. **动态调整**: 在训练期间动态调整参数(如学习率)\n",
    "4. **日志记录**: 记录训练和验证指标用于后续分析\n",
    "5. **自定义行为**: 实现训练过程中的任意自定义操作\n",
    "\n",
    "## 实现原理\n",
    "\n",
    "回调函数通过在训练循环的关键节点插入钩子函数来工作：\n",
    "- `on_epoch_begin/end`: 每个epoch开始/结束时调用\n",
    "- `on_batch_begin/end`: 每个batch开始/结束时调用\n",
    "- `on_train_begin/end`: 训练开始/结束时调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备实验数据\n",
    "\n",
    "使用MNIST数据集进行演示，这是一个手写数字识别任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载MNIST数据集\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# 数据预处理：归一化到[0,1]区间\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# 展平图像：28x28 -> 784\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# 转换标签为one-hot编码\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(f'训练集形状: {x_train.shape}, 标签形状: {y_train.shape}')\n",
    "print(f'测试集形状: {x_test.shape}, 标签形状: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 构建实验模型\n",
    "\n",
    "构建一个简单的多层感知器(MLP)用于演示回调函数的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    创建一个简单的MLP模型\n",
    "    \n",
    "    架构:\n",
    "    - 输入层: 784维(28x28展平)\n",
    "    - 隐藏层1: 128个神经元 + ReLU激活\n",
    "    - Dropout: 0.2防止过拟合\n",
    "    - 隐藏层2: 64个神经元 + ReLU激活\n",
    "    - 输出层: 10个神经元(10类) + Softmax激活\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 自定义回调函数\n",
    "\n",
    "通过继承`keras.callbacks.Callback`类可以创建自定义回调函数，实现任意训练过程监控逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    自定义回调函数示例\n",
    "    \n",
    "    功能:\n",
    "    1. 在训练开始和结束时打印消息\n",
    "    2. 在每个epoch结束时显示损失和准确率\n",
    "    3. 监控验证准确率，达到阈值时自动停止训练\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_accuracy=0.95):\n",
    "        super().__init__()\n",
    "        self.target_accuracy = target_accuracy\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"训练开始时调用\"\"\"\n",
    "        print('\\n开始训练模型...')\n",
    "        print(f'目标验证准确率: {self.target_accuracy:.1%}\\n')\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        \"\"\"训练结束时调用\"\"\"\n",
    "        print('\\n训练完成！')\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"每个epoch结束时调用\"\"\"\n",
    "        logs = logs or {}\n",
    "        \n",
    "        # 提取当前指标\n",
    "        loss = logs.get('loss', 0)\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        val_accuracy = logs.get('val_accuracy', 0)\n",
    "        \n",
    "        # 显示训练进度\n",
    "        print(f'Epoch {epoch + 1}: '\n",
    "              f'loss={loss:.4f}, accuracy={accuracy:.4f}, '\n",
    "              f'val_loss={val_loss:.4f}, val_accuracy={val_accuracy:.4f}')\n",
    "        \n",
    "        # 检查是否达到目标准确率\n",
    "        if val_accuracy >= self.target_accuracy:\n",
    "            print(f'\\n已达到目标准确率 {self.target_accuracy:.1%}，停止训练。')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 使用内置回调函数\n",
    "\n",
    "Keras提供了多种常用的内置回调函数，可以直接使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建用于保存模型的目录\n",
    "checkpoint_dir = 'model_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# 配置回调函数列表\n",
    "callbacks_list = [\n",
    "    # 自定义回调：监控训练进度\n",
    "    CustomCallback(target_accuracy=0.98),\n",
    "    \n",
    "    # ModelCheckpoint: 保存最佳模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(checkpoint_dir, 'best_model.h5'),\n",
    "        monitor='val_accuracy',  # 监控验证准确率\n",
    "        save_best_only=True,     # 仅保存最佳模型\n",
    "        mode='max',              # 监控指标越大越好\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # EarlyStopping: 提前终止训练\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',      # 监控验证损失\n",
    "        patience=3,              # 等待3个epoch无改善后停止\n",
    "        restore_best_weights=True,  # 恢复最佳权重\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # ReduceLROnPlateau: 动态调整学习率\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',      # 监控验证损失\n",
    "        factor=0.5,              # 学习率衰减因子\n",
    "        patience=2,              # 等待2个epoch无改善后降低学习率\n",
    "        min_lr=1e-6,             # 学习率下限\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # CSVLogger: 记录训练日志到CSV文件\n",
    "    keras.callbacks.CSVLogger(\n",
    "        filename='training_log.csv',\n",
    "        separator=',',\n",
    "        append=False\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练模型并应用回调函数\n",
    "\n",
    "将配置好的回调函数传递给`fit()`方法，在训练过程中自动执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型（使用较少的epoch用于快速测试）\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=3,  # 测试用，实际训练可设为20\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=0  # 关闭默认输出，使用自定义回调的输出\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 加载最佳模型并评估\n",
    "\n",
    "训练完成后，加载ModelCheckpoint保存的最佳模型进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载保存的最佳模型\n",
    "best_model_path = os.path.join(checkpoint_dir, 'best_model.h5')\n",
    "if os.path.exists(best_model_path):\n",
    "    best_model = keras.models.load_model(best_model_path)\n",
    "    print(f'\\n成功加载最佳模型: {best_model_path}')\n",
    "    \n",
    "    # 在测试集上评估\n",
    "    test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f'\\n测试集评估结果:')\n",
    "    print(f'Loss: {test_loss:.4f}')\n",
    "    print(f'Accuracy: {test_accuracy:.4f}')\n",
    "else:\n",
    "    print(f'未找到保存的模型: {best_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 分析训练日志\n",
    "\n",
    "读取CSVLogger保存的训练日志，分析训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取训练日志\n",
    "if os.path.exists('training_log.csv'):\n",
    "    log_df = pd.read_csv('training_log.csv')\n",
    "    print('\\n训练日志:')\n",
    "    print(log_df)\n",
    "    \n",
    "    # 可视化训练过程\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # 损失曲线\n",
    "    ax1.plot(log_df['epoch'], log_df['loss'], 'b-', label='训练损失')\n",
    "    ax1.plot(log_df['epoch'], log_df['val_loss'], 'r-', label='验证损失')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('损失曲线')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # 准确率曲线\n",
    "    ax2.plot(log_df['epoch'], log_df['accuracy'], 'b-', label='训练准确率')\n",
    "    ax2.plot(log_df['epoch'], log_df['val_accuracy'], 'r-', label='验证准确率')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('准确率曲线')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('未找到训练日志文件')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 高级回调函数示例\n",
    "\n",
    "实现一个更复杂的回调函数，展示更多高级特性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    高级回调函数示例\n",
    "    \n",
    "    功能:\n",
    "    1. 记录每个batch的训练时间\n",
    "    2. 计算并显示每个epoch的平均batch时间\n",
    "    3. 监控梯度消失/爆炸问题\n",
    "    4. 自适应调整batch大小(仅演示概念)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.batch_times = []\n",
    "        self.epoch_start_time = None\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"记录epoch开始时间\"\"\"\n",
    "        import time\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.batch_times = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"分析epoch训练情况\"\"\"\n",
    "        import time\n",
    "        \n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        avg_batch_time = np.mean(self.batch_times) if self.batch_times else 0\n",
    "        \n",
    "        print(f'\\nEpoch {epoch + 1} 统计:')\n",
    "        print(f'  总耗时: {epoch_time:.2f}秒')\n",
    "        print(f'  平均batch耗时: {avg_batch_time:.4f}秒')\n",
    "        \n",
    "        # 检查梯度问题（通过损失变化判断）\n",
    "        if logs:\n",
    "            loss = logs.get('loss', 0)\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print('  警告: 检测到梯度爆炸！损失值为NaN或Inf')\n",
    "                self.model.stop_training = True\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"记录batch开始时间\"\"\"\n",
    "        import time\n",
    "        self.batch_start_time = time.time()\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        \"\"\"记录batch结束时间\"\"\"\n",
    "        import time\n",
    "        batch_time = time.time() - self.batch_start_time\n",
    "        self.batch_times.append(batch_time)\n",
    "\n",
    "# 演示使用高级回调函数\n",
    "print('\\n演示高级回调函数:')\n",
    "model_advanced = create_model()\n",
    "\n",
    "history_advanced = model_advanced.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=2,  # 仅训练2个epoch进行演示\n",
    "    validation_split=0.2,\n",
    "    callbacks=[AdvancedCallback()],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 回调函数的执行顺序\n",
    "\n",
    "理解回调函数的执行顺序对于调试和优化训练流程很重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderDemoCallback(keras.callbacks.Callback):\n",
    "    \"\"\"演示回调函数执行顺序\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(f'{self.name}: on_train_begin')\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f'{self.name}: on_epoch_begin (epoch {epoch})')\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f'{self.name}: on_epoch_end (epoch {epoch})')\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        print(f'{self.name}: on_train_end')\n",
    "\n",
    "# 创建多个回调函数测试执行顺序\n",
    "print('\\n演示回调函数执行顺序:')\n",
    "model_order = create_model()\n",
    "\n",
    "# 回调函数按列表顺序执行\n",
    "callbacks_order = [\n",
    "    OrderDemoCallback('Callback_1'),\n",
    "    OrderDemoCallback('Callback_2'),\n",
    "    OrderDemoCallback('Callback_3')\n",
    "]\n",
    "\n",
    "# 仅训练1个epoch演示\n",
    "history_order = model_order.fit(\n",
    "    x_train[:1000], y_train[:1000],  # 使用少量数据\n",
    "    batch_size=128,\n",
    "    epochs=1,\n",
    "    callbacks=callbacks_order,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print('\\n结论: 回调函数按照列表中的顺序依次执行')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 清理临时文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# 清理测试产生的文件和目录\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "    print(f'已删除目录: {checkpoint_dir}')\n",
    "\n",
    "if os.path.exists('training_log.csv'):\n",
    "    os.remove('training_log.csv')\n",
    "    print('已删除文件: training_log.csv')\n",
    "\n",
    "print('\\n清理完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 回调函数的优势\n",
    "\n",
    "1. **模块化**: 将训练逻辑与监控逻辑分离\n",
    "2. **可复用**: 一次编写，多处使用\n",
    "3. **灵活性**: 可以组合多个回调函数\n",
    "4. **非侵入式**: 不需要修改训练循环代码\n",
    "\n",
    "### 最佳实践\n",
    "\n",
    "1. **合理使用内置回调**: 优先使用Keras内置的回调函数\n",
    "2. **自定义扩展**: 当内置功能不满足需求时再自定义\n",
    "3. **注意执行顺序**: 回调函数按列表顺序执行，注意依赖关系\n",
    "4. **避免过度使用**: 过多的回调函数会降低训练速度\n",
    "5. **日志记录**: 使用CSVLogger或TensorBoard记录详细训练信息\n",
    "\n",
    "### 常见应用场景\n",
    "\n",
    "- **实验跟踪**: 记录不同超参数配置的训练结果\n",
    "- **资源优化**: 在验证集性能饱和时提前终止训练\n",
    "- **模型选择**: 自动保存验证集上表现最好的模型\n",
    "- **学习率调度**: 根据训练进度动态调整学习率\n",
    "- **异常处理**: 检测并处理训练过程中的异常情况"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
