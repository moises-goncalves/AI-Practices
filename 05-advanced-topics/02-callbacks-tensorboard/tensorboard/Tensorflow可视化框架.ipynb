{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard可视化完全指南\n",
    "\n",
    "## 核心概念\n",
    "\n",
    "TensorBoard是TensorFlow的可视化工具包，提供强大的训练过程监控和分析功能：\n",
    "\n",
    "### 主要功能\n",
    "\n",
    "1. **Scalars**: 标量数据可视化(损失、准确率等)\n",
    "2. **Graphs**: 计算图结构可视化\n",
    "3. **Distributions**: 权重和激活值分布\n",
    "4. **Histograms**: 张量直方图统计\n",
    "5. **Images**: 图像数据展示\n",
    "6. **Embeddings**: 高维数据降维可视化\n",
    "7. **HParams**: 超参数调优实验对比\n",
    "\n",
    "## 应用场景\n",
    "\n",
    "1. **训练监控**: 实时查看训练和验证指标\n",
    "2. **模型调试**: 检查权重更新和梯度流动\n",
    "3. **性能分析**: 定位训练瓶颈\n",
    "4. **超参数优化**: 对比不同配置的效果\n",
    "5. **结果展示**: 生成专业的训练报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备数据集\n",
    "\n",
    "使用IMDB电影评论情感分类数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载IMDB数据集\n",
    "max_features = 10000  # 词汇表大小\n",
    "maxlen = 200          # 序列最大长度\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 填充序列到相同长度\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "print(f'训练集形状: {x_train.shape}, 标签形状: {y_train.shape}')\n",
    "print(f'测试集形状: {x_test.shape}, 标签形状: {y_test.shape}')\n",
    "print(f'\\n训练样本示例:')\n",
    "print(f'序列: {x_train[0][:20]}...')\n",
    "print(f'标签: {y_train[0]} (0=负面, 1=正面)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 构建模型\n",
    "\n",
    "构建一个用于文本分类的神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    创建文本分类模型\n",
    "    \n",
    "    架构:\n",
    "    - Embedding层: 将词索引转换为稠密向量\n",
    "    - Conv1D层: 提取局部特征\n",
    "    - GlobalMaxPooling1D: 池化操作\n",
    "    - Dense层: 全连接分类\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Embedding(max_features, 128, input_length=maxlen, name='embedding'),\n",
    "        layers.Conv1D(32, 7, activation='relu', name='conv1d_1'),\n",
    "        layers.MaxPooling1D(5, name='pool_1'),\n",
    "        layers.Conv1D(32, 7, activation='relu', name='conv1d_2'),\n",
    "        layers.GlobalMaxPooling1D(name='global_pool'),\n",
    "        layers.Dense(64, activation='relu', name='dense_1'),\n",
    "        layers.Dropout(0.5, name='dropout'),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ], name='text_classifier')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 配置TensorBoard回调\n",
    "\n",
    "### TensorBoard关键参数\n",
    "\n",
    "- `log_dir`: 日志保存目录\n",
    "- `histogram_freq`: 记录权重直方图的频率(epoch)\n",
    "- `write_graph`: 是否记录计算图\n",
    "- `write_images`: 是否记录权重为图像\n",
    "- `update_freq`: 更新频率('epoch'或batch数)\n",
    "- `profile_batch`: 性能分析的batch范围\n",
    "- `embeddings_freq`: 记录嵌入层的频率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建基础日志目录\n",
    "base_log_dir = 'tensorboard_logs'\n",
    "os.makedirs(base_log_dir, exist_ok=True)\n",
    "\n",
    "# 使用时间戳创建唯一的日志目录\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(base_log_dir, f'run_{current_time}')\n",
    "\n",
    "print(f'TensorBoard日志目录: {log_dir}')\n",
    "\n",
    "# 配置TensorBoard回调\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,         # 每个epoch记录直方图\n",
    "    write_graph=True,         # 记录计算图\n",
    "    write_images=False,       # 不记录权重图像(节省空间)\n",
    "    update_freq='epoch',      # 按epoch更新\n",
    "    profile_batch='10,20',    # 分析第10-20个batch的性能\n",
    "    embeddings_freq=1         # 每个epoch记录嵌入层\n",
    ")\n",
    "\n",
    "print('TensorBoard回调配置完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练模型并记录日志\n",
    "\n",
    "使用TensorBoard回调训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n开始训练模型...')\n",
    "print(f'日志将保存到: {log_dir}\\n')\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=3,  # 测试用，实际训练可设为20\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'\\n测试结果 - 损失: {test_loss:.4f}, 准确率: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 自定义标量记录\n",
    "\n",
    "除了自动记录的指标外，还可以记录自定义标量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetricsCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    自定义指标记录回调\n",
    "    \n",
    "    记录额外的训练指标到TensorBoard\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_dir):\n",
    "        super().__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.file_writer = tf.summary.create_file_writer(os.path.join(log_dir, 'custom_metrics'))\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        \n",
    "        # 计算训练-验证差距(过拟合指标)\n",
    "        train_val_gap = logs.get('accuracy', 0) - logs.get('val_accuracy', 0)\n",
    "        \n",
    "        # 计算相对改善率\n",
    "        if epoch > 0 and hasattr(self, 'prev_val_loss'):\n",
    "            val_loss = logs.get('val_loss', 0)\n",
    "            improvement = (self.prev_val_loss - val_loss) / self.prev_val_loss * 100\n",
    "        else:\n",
    "            improvement = 0\n",
    "        \n",
    "        self.prev_val_loss = logs.get('val_loss', 0)\n",
    "        \n",
    "        # 记录自定义指标\n",
    "        with self.file_writer.as_default():\n",
    "            tf.summary.scalar('train_val_gap', train_val_gap, step=epoch)\n",
    "            tf.summary.scalar('val_loss_improvement_pct', improvement, step=epoch)\n",
    "            \n",
    "            # 记录学习率\n",
    "            lr = float(keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "            tf.summary.scalar('learning_rate', lr, step=epoch)\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.file_writer.close()\n",
    "\n",
    "# 使用自定义回调重新训练\n",
    "print('\\n使用自定义指标重新训练...')\n",
    "custom_log_dir = os.path.join(base_log_dir, f'custom_{current_time}')\n",
    "\n",
    "model_custom = create_model()\n",
    "custom_metrics_callback = CustomMetricsCallback(custom_log_dir)\n",
    "\n",
    "tensorboard_callback_custom = keras.callbacks.TensorBoard(\n",
    "    log_dir=custom_log_dir,\n",
    "    histogram_freq=1,\n",
    "    update_freq='epoch'\n",
    ")\n",
    "\n",
    "history_custom = model_custom.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=3,  # 测试用\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback_custom, custom_metrics_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f'\\n自定义指标日志保存到: {custom_log_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 对比多个实验\n",
    "\n",
    "训练多个模型并在TensorBoard中对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_config(config_name, learning_rate, batch_size, epochs=3):\n",
    "    \"\"\"\n",
    "    使用指定配置训练模型\n",
    "    \"\"\"\n",
    "    print(f'\\n训练配置: {config_name}')\n",
    "    print(f'  学习率: {learning_rate}')\n",
    "    print(f'  批次大小: {batch_size}\\n')\n",
    "    \n",
    "    # 创建模型\n",
    "    model = create_model()\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # 配置日志目录\n",
    "    exp_log_dir = os.path.join(base_log_dir, 'experiments', config_name)\n",
    "    \n",
    "    # 训练模型\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=exp_log_dir,\n",
    "                histogram_freq=1\n",
    "            )\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 评估\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f'测试准确率: {test_acc:.4f}')\n",
    "    \n",
    "    return history, test_acc\n",
    "\n",
    "# 进行对比实验\n",
    "print('========== 对比实验 ==========')\n",
    "\n",
    "experiments = [\n",
    "    ('lr_0.001_bs_128', 0.001, 128),\n",
    "    ('lr_0.0001_bs_128', 0.0001, 128),\n",
    "    ('lr_0.001_bs_64', 0.001, 64)\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for config_name, lr, bs in experiments:\n",
    "    history, test_acc = train_with_config(config_name, lr, bs, epochs=3)\n",
    "    results[config_name] = test_acc\n",
    "\n",
    "# 显示对比结果\n",
    "print('\\n========== 实验结果对比 ==========')\n",
    "for config_name, test_acc in results.items():\n",
    "    print(f'{config_name}: {test_acc:.4f}')\n",
    "\n",
    "best_config = max(results, key=results.get)\n",
    "print(f'\\n最佳配置: {best_config} (准确率: {results[best_config]:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 记录图像数据\n",
    "\n",
    "演示如何在TensorBoard中记录图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用MNIST数据集演示图像记录\n",
    "(mnist_train_images, mnist_train_labels), _ = keras.datasets.mnist.load_data()\n",
    "\n",
    "# 归一化并添加通道维度\n",
    "mnist_train_images = mnist_train_images[:100].astype('float32') / 255.0\n",
    "mnist_train_images = np.expand_dims(mnist_train_images, -1)\n",
    "\n",
    "# 创建图像日志\n",
    "image_log_dir = os.path.join(base_log_dir, f'images_{current_time}')\n",
    "file_writer = tf.summary.create_file_writer(image_log_dir)\n",
    "\n",
    "# 记录前25张图像\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\n",
    "        'MNIST训练样本',\n",
    "        mnist_train_images[:25],\n",
    "        max_outputs=25,\n",
    "        step=0\n",
    "    )\n",
    "\n",
    "file_writer.close()\n",
    "print(f'图像已记录到: {image_log_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 超参数调优可视化\n",
    "\n",
    "使用HParams插件进行超参数实验对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# 定义超参数空间\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([0.001, 0.0001]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.3, 0.5]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'rmsprop']))\n",
    "\n",
    "# 定义评估指标\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "hparams_log_dir = os.path.join(base_log_dir, 'hparams_tuning')\n",
    "\n",
    "with tf.summary.create_file_writer(hparams_log_dir).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LEARNING_RATE, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
    "    )\n",
    "\n",
    "def train_hparams(hparams, run_dir):\n",
    "    \"\"\"\n",
    "    使用指定超参数训练模型\n",
    "    \"\"\"\n",
    "    # 构建模型\n",
    "    model = keras.Sequential([\n",
    "        layers.Embedding(max_features, 128, input_length=maxlen),\n",
    "        layers.Conv1D(32, 7, activation='relu'),\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # 编译模型\n",
    "    model.compile(\n",
    "        optimizer=hparams[HP_OPTIMIZER],\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # 训练\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=2,  # 快速测试\n",
    "        batch_size=128,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 评估\n",
    "    _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# 运行超参数搜索\n",
    "print('\\n========== 超参数调优 ==========')\n",
    "session_num = 0\n",
    "\n",
    "for learning_rate in HP_LEARNING_RATE.domain.values:\n",
    "    for dropout_rate in HP_DROPOUT.domain.values:\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_LEARNING_RATE: learning_rate,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer\n",
    "            }\n",
    "            \n",
    "            run_name = f'run-{session_num}'\n",
    "            print(f'{run_name}: {hparams}')\n",
    "            \n",
    "            run_dir = os.path.join(hparams_log_dir, run_name)\n",
    "            \n",
    "            # 训练并记录结果\n",
    "            with tf.summary.create_file_writer(run_dir).as_default():\n",
    "                hp.hparams(hparams)  # 记录超参数\n",
    "                accuracy = train_hparams(hparams, run_dir)\n",
    "                tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "                print(f'  准确率: {accuracy:.4f}\\n')\n",
    "            \n",
    "            session_num += 1\n",
    "\n",
    "print(f'超参数调优日志保存到: {hparams_log_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 启动TensorBoard\n",
    "\n",
    "生成启动TensorBoard的命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n========== 启动TensorBoard ==========')\n",
    "print(f'\\n在终端中运行以下命令启动TensorBoard:\\n')\n",
    "print(f'tensorboard --logdir={base_log_dir}\\n')\n",
    "print(f'然后在浏览器中访问: http://localhost:6006/\\n')\n",
    "print('TensorBoard功能说明:')\n",
    "print('  - Scalars: 查看损失和准确率曲线')\n",
    "print('  - Graphs: 查看模型计算图')\n",
    "print('  - Distributions: 查看权重分布')\n",
    "print('  - Histograms: 查看张量直方图')\n",
    "print('  - HParams: 对比超参数实验')\n",
    "print('  - Images: 查看记录的图像')\n",
    "print('  - Time Series: 查看时间序列数据')\n",
    "\n",
    "# 也可以在Jupyter中内嵌TensorBoard\n",
    "print('\\n在Jupyter Notebook中，可以使用以下命令内嵌TensorBoard:')\n",
    "print(f'%load_ext tensorboard')\n",
    "print(f'%tensorboard --logdir {base_log_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 日志目录结构说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_directory_tree(path, prefix='', max_depth=3, current_depth=0):\n",
    "    \"\"\"\n",
    "    打印目录树结构\n",
    "    \"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        entries = sorted(os.listdir(path))\n",
    "        for i, entry in enumerate(entries[:10]):  # 限制显示数量\n",
    "            entry_path = os.path.join(path, entry)\n",
    "            is_last = (i == len(entries) - 1) or (i == 9)\n",
    "            \n",
    "            connector = '└── ' if is_last else '├── '\n",
    "            print(f'{prefix}{connector}{entry}')\n",
    "            \n",
    "            if os.path.isdir(entry_path):\n",
    "                extension = '    ' if is_last else '│   '\n",
    "                print_directory_tree(entry_path, prefix + extension, max_depth, current_depth + 1)\n",
    "        \n",
    "        if len(entries) > 10:\n",
    "            print(f'{prefix}    ... 还有{len(entries) - 10}个文件/目录')\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "print('\\n========== TensorBoard日志目录结构 ==========')\n",
    "print(f'{base_log_dir}/')\n",
    "print_directory_tree(base_log_dir, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 清理日志文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理测试产生的日志\n",
    "if os.path.exists(base_log_dir):\n",
    "    shutil.rmtree(base_log_dir)\n",
    "    print(f'已删除日志目录: {base_log_dir}')\n",
    "\n",
    "print('清理完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### TensorBoard最佳实践\n",
    "\n",
    "1. **日志管理**:\n",
    "   - 使用时间戳或实验名称区分不同运行\n",
    "   - 定期清理旧日志节省空间\n",
    "   - 使用子目录组织多个实验\n",
    "\n",
    "2. **性能优化**:\n",
    "   - `histogram_freq`不要设置太小(建议>=1)\n",
    "   - 大规模训练时考虑降低记录频率\n",
    "   - 使用`profile_batch`限制性能分析范围\n",
    "\n",
    "3. **可视化技巧**:\n",
    "   - 使用平滑功能查看长期趋势\n",
    "   - 对比模式下可同时查看多个实验\n",
    "   - 使用正则表达式过滤显示的图表\n",
    "\n",
    "4. **自定义记录**:\n",
    "   ```python\n",
    "   with file_writer.as_default():\n",
    "       tf.summary.scalar('custom_metric', value, step=epoch)\n",
    "       tf.summary.histogram('layer_weights', weights, step=epoch)\n",
    "       tf.summary.image('predictions', images, step=epoch)\n",
    "   ```\n",
    "\n",
    "### 常见问题\n",
    "\n",
    "1. **TensorBoard不更新**:\n",
    "   - 检查日志目录是否正确\n",
    "   - 刷新浏览器或重启TensorBoard\n",
    "   - 确认回调函数已添加到训练中\n",
    "\n",
    "2. **日志文件过大**:\n",
    "   - 降低`histogram_freq`\n",
    "   - 禁用`write_images`\n",
    "   - 减少`embeddings_freq`\n",
    "\n",
    "3. **性能分析失败**:\n",
    "   - 检查`profile_batch`设置\n",
    "   - 确保GPU驱动支持性能分析\n",
    "   - 尝试减小分析的batch范围\n",
    "\n",
    "### 高级功能\n",
    "\n",
    "1. **Profiler性能分析**:\n",
    "   - 识别训练瓶颈\n",
    "   - 优化数据管道\n",
    "   - GPU利用率分析\n",
    "\n",
    "2. **What-If Tool**:\n",
    "   - 可视化模型预测\n",
    "   - 分析模型公平性\n",
    "   - 交互式探索特征影响\n",
    "\n",
    "3. **Embedding Projector**:\n",
    "   - 高维向量可视化\n",
    "   - 支持PCA、t-SNE、UMAP降维\n",
    "   - 交互式搜索相似向量\n",
    "\n",
    "### 命令行技巧\n",
    "\n",
    "```bash\n",
    "# 基础启动\n",
    "tensorboard --logdir=logs\n",
    "\n",
    "# 指定端口\n",
    "tensorboard --logdir=logs --port=6007\n",
    "\n",
    "# 绑定所有网络接口(允许远程访问)\n",
    "tensorboard --logdir=logs --host=0.0.0.0\n",
    "\n",
    "# 启用调试模式\n",
    "tensorboard --logdir=logs --debugger_port=6064\n",
    "\n",
    "# 限制缓存大小\n",
    "tensorboard --logdir=logs --max_reload_threads=1\n",
    "```\n",
    "\n",
    "### 集成其他工具\n",
    "\n",
    "- **Weights & Biases**: 云端训练监控\n",
    "- **MLflow**: 实验跟踪和模型管理\n",
    "- **Neptune.ai**: 协作实验管理\n",
    "- **Comet.ml**: 自动实验跟踪\n",
    "\n",
    "### 参考资源\n",
    "\n",
    "- TensorBoard官方文档: https://www.tensorflow.org/tensorboard\n",
    "- GitHub仓库: https://github.com/tensorflow/tensorboard\n",
    "- 教程和示例: https://www.tensorflow.org/tensorboard/get_started"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
