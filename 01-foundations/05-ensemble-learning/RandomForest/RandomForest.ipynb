{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# 随机森林 (Random Forest)\n",
    "\n",
    "## 算法原理\n",
    "\n",
    "随机森林是 Bagging 的扩展，在决策树的基础上引入了额外的随机性：\n",
    "\n",
    "1. **样本随机**: 使用 Bootstrap 有放回抽样创建不同的训练子集\n",
    "2. **特征随机**: 在每个节点分裂时，只考虑随机选择的特征子集\n",
    "\n",
    "这两层随机性使得各棵树更加独立，从而更有效地降低集成的方差。\n",
    "\n",
    "## 核心特点\n",
    "\n",
    "| 特性 | 说明 |\n",
    "|------|------|\n",
    "| 集成方式 | Bagging（并行集成） |\n",
    "| 基学习器 | 决策树 |\n",
    "| 样本采样 | Bootstrap（有放回抽样） |\n",
    "| 特征采样 | 每个节点随机选择 $\\sqrt{p}$ 个特征（分类）或 $p/3$ 个（回归） |\n",
    "| 聚合方式 | 投票（分类）/ 平均（回归） |\n",
    "\n",
    "## 优势\n",
    "\n",
    "- 几乎不需要特征缩放\n",
    "- 对异常值和缺失值相对鲁棒\n",
    "- 提供特征重要性估计\n",
    "- 支持 OOB（Out-of-Bag）评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "## 1. 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成月牙形数据集\n",
    "X, y = make_moons(n_samples=1000, noise=0.30, random_state=RANDOM_STATE)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape[0]}\")\n",
    "print(f\"测试集大小: {X_test.shape[0]}\")\n",
    "print(f\"特征维度: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rf-section",
   "metadata": {},
   "source": [
    "## 2. 使用 RandomForestClassifier\n",
    "\n",
    "sklearn 提供了专门的 RandomForestClassifier 实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建随机森林分类器\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=500,          # 树的数量\n",
    "    max_leaf_nodes=16,         # 每棵树的最大叶子节点数\n",
    "    max_features='sqrt',       # 每个节点考虑的特征数（分类问题常用 sqrt）\n",
    "    bootstrap=True,            # 使用 bootstrap 抽样\n",
    "    oob_score=True,            # 计算 OOB 分数\n",
    "    n_jobs=-1,                 # 使用所有 CPU 核心\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# 评估\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"测试集准确率: {rf_accuracy:.4f}\")\n",
    "print(f\"OOB 分数: {rf_clf.oob_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bagging-section",
   "metadata": {},
   "source": [
    "## 3. 使用 BaggingClassifier 实现随机森林\n",
    "\n",
    "随机森林也可以用 BaggingClassifier + 随机特征决策树来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bagging-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 BaggingClassifier 实现类似随机森林的效果\n",
    "# 通过设置 splitter='random' 在决策树中引入随机性\n",
    "bag_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(\n",
    "        splitter='random',       # 随机选择最佳分割\n",
    "        max_leaf_nodes=16,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    n_estimators=500,\n",
    "    max_samples=1.0,             # 使用全部样本（bootstrap 会自动抽样）\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "# 评估\n",
    "bag_accuracy = bag_clf.score(X_test, y_test)\n",
    "\n",
    "print(f\"BaggingClassifier 准确率: {bag_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-section",
   "metadata": {},
   "source": [
    "## 4. 与单棵决策树对比\n",
    "\n",
    "比较随机森林与单棵决策树的性能差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单棵决策树\n",
    "tree_clf = DecisionTreeClassifier(\n",
    "    max_leaf_nodes=16,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "tree_clf.fit(X_train, y_train)\n",
    "tree_accuracy = tree_clf.score(X_test, y_test)\n",
    "\n",
    "# 对比结果\n",
    "print(\"模型性能对比:\")\n",
    "print(f\"{'模型':<25} {'准确率':>10}\")\n",
    "print(\"-\" * 37)\n",
    "print(f\"{'单棵决策树':<25} {tree_accuracy:>10.4f}\")\n",
    "print(f\"{'RandomForestClassifier':<25} {rf_accuracy:>10.4f}\")\n",
    "print(f\"{'BaggingClassifier':<25} {bag_accuracy:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cv-section",
   "metadata": {},
   "source": [
    "## 5. 交叉验证评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉验证\n",
    "cv_scores = cross_val_score(rf_clf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"交叉验证分数: {cv_scores}\")\n",
    "print(f\"平均准确率: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "importance-section",
   "metadata": {},
   "source": [
    "## 6. 特征重要性\n",
    "\n",
    "随机森林可以自动计算特征重要性，基于每个特征在所有树中的不纯度减少量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "importance-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取特征重要性\n",
    "feature_names = ['Feature_1', 'Feature_2']\n",
    "importances = rf_clf.feature_importances_\n",
    "\n",
    "print(\"特征重要性:\")\n",
    "for name, importance in zip(feature_names, importances):\n",
    "    print(f\"  {name}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "param-section",
   "metadata": {},
   "source": [
    "## 7. 参数敏感性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "param-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析树的数量对性能的影响\n",
    "n_estimators_range = [10, 50, 100, 200, 500]\n",
    "\n",
    "print(\"树的数量 vs 性能:\")\n",
    "for n_est in n_estimators_range:\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_leaf_nodes=16,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(f\"  n_estimators={n_est:3d}: 准确率={accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-section",
   "metadata": {},
   "source": [
    "## 8. 单元测试验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_random_forest():\n",
    "    \"\"\"随机森林功能测试\"\"\"\n",
    "    \n",
    "    # 测试1: 模型应该正确训练\n",
    "    assert hasattr(rf_clf, 'estimators_'), \"模型未正确训练\"\n",
    "    \n",
    "    # 测试2: 树的数量应该正确\n",
    "    assert len(rf_clf.estimators_) == 500, \"树的数量不正确\"\n",
    "    \n",
    "    # 测试3: OOB 分数应该存在且在合理范围\n",
    "    assert hasattr(rf_clf, 'oob_score_'), \"OOB 分数未计算\"\n",
    "    assert 0.7 <= rf_clf.oob_score_ <= 1.0, \"OOB 分数不在合理范围\"\n",
    "    \n",
    "    # 测试4: 随机森林应该比单棵树表现更好或相当\n",
    "    assert rf_accuracy >= tree_accuracy * 0.95, \"随机森林性能异常低\"\n",
    "    \n",
    "    # 测试5: 特征重要性应该存在\n",
    "    assert hasattr(rf_clf, 'feature_importances_'), \"特征重要性未计算\"\n",
    "    assert abs(sum(importances) - 1.0) < 0.01, \"特征重要性之和应接近1\"\n",
    "    \n",
    "    # 测试6: 预测结果形状应该正确\n",
    "    assert y_pred.shape == y_test.shape, \"预测结果形状不正确\"\n",
    "    \n",
    "    print(\"所有测试通过!\")\n",
    "\n",
    "test_random_forest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 随机森林的优势\n",
    "\n",
    "1. **开箱即用**: 默认参数通常就能获得不错的性能\n",
    "2. **并行训练**: 各棵树独立训练，可充分利用多核 CPU\n",
    "3. **特征重要性**: 自动计算特征重要性\n",
    "4. **OOB 评估**: 无需额外验证集即可评估性能\n",
    "\n",
    "### 调参建议\n",
    "\n",
    "- `n_estimators`: 越多越好，但收益递减，通常 100-500\n",
    "- `max_features`: 分类问题用 `sqrt`，回归问题用 `log2` 或全部特征\n",
    "- `max_depth`: 默认不限制，可适当限制以减少过拟合\n",
    "- `min_samples_leaf`: 增加可以减少过拟合\n",
    "\n",
    "### 与其他方法的对比\n",
    "\n",
    "- **vs 单棵树**: 更稳定，方差更低\n",
    "- **vs Bagging**: 额外的特征随机性进一步降低方差\n",
    "- **vs Boosting**: 训练更快，但精度可能略低"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
