{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# Bagging 与 Pasting 集成方法\n",
    "\n",
    "## 算法原理\n",
    "\n",
    "Bagging (Bootstrap Aggregating) 和 Pasting 是两种基于并行集成的方法：\n",
    "\n",
    "1. **Bagging**: 使用**有放回抽样**（Bootstrap）从训练集中抽取多个子集\n",
    "2. **Pasting**: 使用**无放回抽样**从训练集中抽取多个子集\n",
    "\n",
    "两者都训练多个基学习器，然后通过投票（分类）或平均（回归）得到最终预测。\n",
    "\n",
    "## 核心优势\n",
    "\n",
    "- **降低方差**: 通过聚合多个模型的预测来减少过拟合\n",
    "- **并行训练**: 各基学习器独立训练，可完全并行化\n",
    "- **样本多样性**: 不同子集产生不同的基学习器\n",
    "\n",
    "## Bagging vs Pasting\n",
    "\n",
    "| 特性 | Bagging | Pasting |\n",
    "|------|---------|----------|\n",
    "| 抽样方式 | 有放回 | 无放回 |\n",
    "| 样本重复 | 允许 | 不允许 |\n",
    "| 多样性 | 更高 | 较低 |\n",
    "| 偏差 | 略高 | 略低 |\n",
    "| 方差 | 更低 | 较高 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "## 1. 数据准备\n",
    "\n",
    "使用 make_moons 生成非线性可分的二分类数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成月牙形数据集\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=RANDOM_STATE)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape[0]}\")\n",
    "print(f\"测试集大小: {X_test.shape[0]}\")\n",
    "print(f\"特征维度: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bagging-section",
   "metadata": {},
   "source": [
    "## 2. Bagging 分类器\n",
    "\n",
    "Bagging 使用有放回抽样，每个基学习器大约使用 63.2% 的独特样本（1 - 1/e）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bagging-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Bagging 分类器\n",
    "bag_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    n_estimators=500,      # 基学习器数量\n",
    "    max_samples=1.0,       # 每个基学习器使用的样本比例\n",
    "    bootstrap=True,        # True = Bagging (有放回抽样)\n",
    "    n_jobs=-1,             # 使用所有CPU核心并行训练\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测和评估\n",
    "y_pred_bag = bag_clf.predict(X_test)\n",
    "bag_accuracy = accuracy_score(y_test, y_pred_bag)\n",
    "\n",
    "print(f\"Bagging 准确率: {bag_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pasting-section",
   "metadata": {},
   "source": [
    "## 3. Pasting 分类器\n",
    "\n",
    "Pasting 使用无放回抽样，设置 `bootstrap=False`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pasting-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Pasting 分类器\n",
    "past_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    n_estimators=500,\n",
    "    max_samples=0.8,       # 无放回抽样时需要小于1.0\n",
    "    bootstrap=False,       # False = Pasting (无放回抽样)\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "past_clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测和评估\n",
    "y_pred_past = past_clf.predict(X_test)\n",
    "past_accuracy = accuracy_score(y_test, y_pred_past)\n",
    "\n",
    "print(f\"Pasting 准确率: {past_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oob-section",
   "metadata": {},
   "source": [
    "## 4. Out-of-Bag (OOB) 评估\n",
    "\n",
    "Bagging 的一个独特优势是可以使用**包外样本**（Out-of-Bag）进行验证：\n",
    "\n",
    "- 由于有放回抽样，每个基学习器平均有 36.8% 的样本未被选中\n",
    "- 这些未选中的样本可以用于评估该基学习器\n",
    "- 聚合所有 OOB 预测可以得到整体模型的 OOB 分数\n",
    "\n",
    "OOB 评估相当于交叉验证，但不需要额外计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oob-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建支持 OOB 评估的 Bagging 分类器\n",
    "bag_clf_oob = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    n_estimators=500,\n",
    "    bootstrap=True,\n",
    "    oob_score=True,        # 启用 OOB 评估\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "bag_clf_oob.fit(X_train, y_train)\n",
    "\n",
    "# OOB 分数（无需单独的验证集）\n",
    "print(f\"OOB 分数: {bag_clf_oob.oob_score_:.4f}\")\n",
    "\n",
    "# 测试集准确率\n",
    "y_pred_oob = bag_clf_oob.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_oob)\n",
    "print(f\"测试集准确率: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-section",
   "metadata": {},
   "source": [
    "## 5. 与单棵决策树对比\n",
    "\n",
    "对比 Bagging 集成与单棵决策树的性能差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单棵决策树\n",
    "tree_clf = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "tree_accuracy = tree_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"模型性能对比:\")\n",
    "print(f\"{'模型':<20} {'准确率':>10}\")\n",
    "print(\"-\" * 32)\n",
    "print(f\"{'单棵决策树':<20} {tree_accuracy:>10.4f}\")\n",
    "print(f\"{'Bagging':<20} {bag_accuracy:>10.4f}\")\n",
    "print(f\"{'Pasting':<20} {past_accuracy:>10.4f}\")\n",
    "print(f\"{'Bagging (OOB)':<20} {test_accuracy:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-section",
   "metadata": {},
   "source": [
    "## 6. 随机补丁与随机子空间\n",
    "\n",
    "- **随机补丁 (Random Patches)**: 同时对样本和特征进行抽样\n",
    "- **随机子空间 (Random Subspaces)**: 只对特征进行抽样，保留全部样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机补丁方法\n",
    "patch_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    n_estimators=500,\n",
    "    max_samples=0.8,           # 样本抽样比例\n",
    "    max_features=0.8,          # 特征抽样比例\n",
    "    bootstrap=True,            # 样本有放回抽样\n",
    "    bootstrap_features=True,   # 特征有放回抽样\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "patch_clf.fit(X_train, y_train)\n",
    "patch_accuracy = patch_clf.score(X_test, y_test)\n",
    "print(f\"随机补丁准确率: {patch_accuracy:.4f}\")\n",
    "\n",
    "# 随机子空间方法\n",
    "subspace_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    n_estimators=500,\n",
    "    max_samples=1.0,           # 使用全部样本\n",
    "    max_features=0.8,          # 特征抽样比例\n",
    "    bootstrap=False,           # 不对样本抽样\n",
    "    bootstrap_features=True,   # 特征有放回抽样\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "subspace_clf.fit(X_train, y_train)\n",
    "subspace_accuracy = subspace_clf.score(X_test, y_test)\n",
    "print(f\"随机子空间准确率: {subspace_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-section",
   "metadata": {},
   "source": [
    "## 7. 单元测试验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bagging_pasting():\n",
    "    \"\"\"Bagging 和 Pasting 功能测试\"\"\"\n",
    "    \n",
    "    # 测试1: 模型应该正确训练\n",
    "    assert hasattr(bag_clf, 'estimators_'), \"Bagging 模型未正确训练\"\n",
    "    assert hasattr(past_clf, 'estimators_'), \"Pasting 模型未正确训练\"\n",
    "    \n",
    "    # 测试2: 基学习器数量应该正确\n",
    "    assert len(bag_clf.estimators_) == 500, \"Bagging 基学习器数量不正确\"\n",
    "    assert len(past_clf.estimators_) == 500, \"Pasting 基学习器数量不正确\"\n",
    "    \n",
    "    # 测试3: OOB 分数应该存在且在合理范围\n",
    "    assert hasattr(bag_clf_oob, 'oob_score_'), \"OOB 分数未计算\"\n",
    "    assert 0.7 <= bag_clf_oob.oob_score_ <= 1.0, \"OOB 分数不在合理范围\"\n",
    "    \n",
    "    # 测试4: Bagging 应该比单棵树表现更好或相当\n",
    "    assert bag_accuracy >= tree_accuracy * 0.95, \"Bagging 性能异常低\"\n",
    "    \n",
    "    # 测试5: 预测结果形状应该正确\n",
    "    assert y_pred_bag.shape == y_test.shape, \"预测结果形状不正确\"\n",
    "    \n",
    "    print(\"所有测试通过!\")\n",
    "\n",
    "test_bagging_pasting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 关键要点\n",
    "\n",
    "1. **Bagging** 通过有放回抽样增加多样性，通常效果更好\n",
    "2. **OOB 评估** 是 Bagging 的"免费"验证方式\n",
    "3. **随机补丁/子空间** 可以进一步增加模型多样性\n",
    "\n",
    "### 参数调优建议\n",
    "\n",
    "- `n_estimators`: 越多越好，但收益递减，通常 100-500 足够\n",
    "- `max_samples`: Bagging 一般用 1.0，Pasting 可以用 0.7-0.9\n",
    "- `max_features`: 对高维数据可以设置为 `sqrt` 或 `log2`\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- 基学习器方差较大（如完全生长的决策树）\n",
    "- 需要并行加速训练\n",
    "- 作为随机森林的基础理解"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
