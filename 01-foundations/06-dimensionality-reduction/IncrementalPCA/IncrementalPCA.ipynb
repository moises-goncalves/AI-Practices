{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 增量 PCA（Incremental PCA）\n",
    "\n",
    "## 概述\n",
    "\n",
    "增量 PCA（Incremental PCA）是一种支持小批量（mini-batch）更新的 PCA 变体，适合处理无法一次性载入内存的大规模数据集。\n",
    "\n",
    "## 核心特点\n",
    "\n",
    "- **内存高效**：逐批处理数据，内存占用恒定\n",
    "- **流式处理**：支持在线学习场景\n",
    "- **增量更新**：可以使用 `partial_fit` 方法逐批训练\n",
    "\n",
    "## 适用场景\n",
    "\n",
    "- 数据集太大无法一次载入内存\n",
    "- 流式数据处理\n",
    "- Out-of-core 计算\n",
    "\n",
    "## 本节内容\n",
    "\n",
    "1. 增量 PCA 基本使用\n",
    "2. 批量处理大数据集\n",
    "3. 使用 NumPy memmap 处理磁盘数据\n",
    "4. 与标准 PCA 的对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## 1. 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tempfile\n",
    "from sklearn.decomposition import IncrementalPCA, PCA\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "## 2. 数据加载\n",
    "\n",
    "使用 MNIST 数据集进行演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 MNIST 数据集\n",
    "print(\"正在加载 MNIST 数据集...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "X = mnist.data.astype(np.float32)\n",
    "y = mnist.target\n",
    "\n",
    "# 使用子集进行演示\n",
    "n_samples = 20000\n",
    "X = X[:n_samples]\n",
    "y = y[:n_samples]\n",
    "\n",
    "# 归一化\n",
    "X = X / 255.0\n",
    "\n",
    "print(f\"数据形状: {X.shape}\")\n",
    "print(f\"数据内存占用: {X.nbytes / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-section",
   "metadata": {},
   "source": [
    "## 3. 增量 PCA 基本使用\n",
    "\n",
    "使用 `partial_fit` 方法逐批训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "n_components = 154\n",
    "n_batches = 100\n",
    "batch_size = n_samples // n_batches\n",
    "\n",
    "print(f\"主成分数: {n_components}\")\n",
    "print(f\"批次数: {n_batches}\")\n",
    "print(f\"每批样本数: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incremental-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建增量 PCA 模型\n",
    "inc_pca = IncrementalPCA(n_components=n_components)\n",
    "\n",
    "# 逐批训练\n",
    "print(\"开始增量训练...\")\n",
    "for i, X_batch in enumerate(np.array_split(X, n_batches)):\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  已处理 {i + 1}/{n_batches} 批次\")\n",
    "\n",
    "print(\"训练完成！\")\n",
    "print(f\"\\n保留的方差比: {inc_pca.explained_variance_ratio_.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transform-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换数据\n",
    "X_reduced = inc_pca.transform(X)\n",
    "\n",
    "print(f\"原始数据形状: {X.shape}\")\n",
    "print(f\"降维后数据形状: {X_reduced.shape}\")\n",
    "print(f\"\\n原始数据内存: {X.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"降维后数据内存: {X_reduced.nbytes / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-section",
   "metadata": {},
   "source": [
    "## 4. 与标准 PCA 对比\n",
    "\n",
    "比较增量 PCA 和标准 PCA 的结果差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-pca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准 PCA（需要将所有数据加载到内存）\n",
    "std_pca = PCA(n_components=n_components)\n",
    "X_std_reduced = std_pca.fit_transform(X)\n",
    "\n",
    "print(\"解释方差对比:\")\n",
    "print(f\"  增量 PCA: {inc_pca.explained_variance_ratio_.sum():.6f}\")\n",
    "print(f\"  标准 PCA: {std_pca.explained_variance_ratio_.sum():.6f}\")\n",
    "print(f\"  差异: {abs(inc_pca.explained_variance_ratio_.sum() - std_pca.explained_variance_ratio_.sum()):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reconstruction-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重构误差对比\n",
    "X_inc_recon = inc_pca.inverse_transform(X_reduced)\n",
    "X_std_recon = std_pca.inverse_transform(X_std_reduced)\n",
    "\n",
    "mse_inc = mean_squared_error(X, X_inc_recon)\n",
    "mse_std = mean_squared_error(X, X_std_recon)\n",
    "\n",
    "print(f\"\\n重构 MSE 对比:\")\n",
    "print(f\"  增量 PCA: {mse_inc:.6f}\")\n",
    "print(f\"  标准 PCA: {mse_std:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variance-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化对比\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 解释方差对比\n",
    "ax1 = axes[0]\n",
    "ax1.plot(range(1, n_components + 1), inc_pca.explained_variance_ratio_, \n",
    "         'o-', label='Incremental PCA', alpha=0.7, markersize=3)\n",
    "ax1.plot(range(1, n_components + 1), std_pca.explained_variance_ratio_, \n",
    "         's--', label='Standard PCA', alpha=0.7, markersize=3)\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Explained Variance Ratio')\n",
    "ax1.set_title('Individual Explained Variance')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 累计方差对比\n",
    "ax2 = axes[1]\n",
    "cumsum_inc = np.cumsum(inc_pca.explained_variance_ratio_)\n",
    "cumsum_std = np.cumsum(std_pca.explained_variance_ratio_)\n",
    "ax2.plot(range(1, n_components + 1), cumsum_inc, 'o-', \n",
    "         label='Incremental PCA', alpha=0.7, markersize=3)\n",
    "ax2.plot(range(1, n_components + 1), cumsum_std, 's--', \n",
    "         label='Standard PCA', alpha=0.7, markersize=3)\n",
    "ax2.axhline(y=0.95, color='red', linestyle='--', alpha=0.5, label='95% threshold')\n",
    "ax2.set_xlabel('Number of Components')\n",
    "ax2.set_ylabel('Cumulative Explained Variance')\n",
    "ax2.set_title('Cumulative Explained Variance')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Incremental PCA vs Standard PCA', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-section",
   "metadata": {},
   "source": [
    "## 5. 重构图像可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择几张图像可视化\n",
    "n_display = 5\n",
    "indices = np.random.choice(n_samples, n_display, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, n_display, figsize=(12, 7))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    # 原始图像\n",
    "    axes[0, i].imshow(X[idx].reshape(28, 28), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Original')\n",
    "    \n",
    "    # 增量 PCA 重构\n",
    "    axes[1, i].imshow(X_inc_recon[idx].reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Incremental PCA')\n",
    "    \n",
    "    # 标准 PCA 重构\n",
    "    axes[2, i].imshow(X_std_recon[idx].reshape(28, 28), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[2, i].set_title('Standard PCA')\n",
    "\n",
    "plt.suptitle(f'Image Reconstruction (n_components={n_components})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memmap-section",
   "metadata": {},
   "source": [
    "## 6. 使用 NumPy memmap 处理磁盘数据\n",
    "\n",
    "当数据太大无法载入内存时，可以使用 `numpy.memmap` 将数据存储在磁盘上，按需加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memmap-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建临时目录\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "memmap_file = os.path.join(temp_dir, 'mnist_memmap.dat')\n",
    "\n",
    "# 将数据写入 memmap 文件\n",
    "m, n = X.shape\n",
    "X_mm = np.memmap(memmap_file, dtype='float32', mode='w+', shape=(m, n))\n",
    "X_mm[:] = X\n",
    "X_mm.flush()  # 确保数据写入磁盘\n",
    "\n",
    "print(f\"Memmap 文件创建完成: {memmap_file}\")\n",
    "print(f\"文件大小: {os.path.getsize(memmap_file) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memmap-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 memmap 进行增量 PCA 训练\n",
    "# 重新打开 memmap 文件（只读模式）\n",
    "X_mm_read = np.memmap(memmap_file, dtype='float32', mode='r', shape=(m, n))\n",
    "\n",
    "# 使用 batch_size 参数自动处理批次\n",
    "batch_size_mm = m // 50\n",
    "inc_pca_mm = IncrementalPCA(n_components=n_components, batch_size=batch_size_mm)\n",
    "\n",
    "# 直接在 memmap 上训练（IncrementalPCA 会自动分批处理）\n",
    "print(\"在 memmap 数据上训练...\")\n",
    "inc_pca_mm.fit(X_mm_read)\n",
    "print(\"训练完成！\")\n",
    "\n",
    "print(f\"\\n保留的方差比: {inc_pca_mm.explained_variance_ratio_.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memmap-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理临时文件\n",
    "del X_mm_read\n",
    "os.remove(memmap_file)\n",
    "os.rmdir(temp_dir)\n",
    "print(\"临时文件已清理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-size-section",
   "metadata": {},
   "source": [
    "## 7. 批次大小的影响\n",
    "\n",
    "批次大小会影响结果的精度和计算效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-size-experiment",
   "metadata": {},
   "outputs": [],
   "source": "# 测试不同的批次大小\nbatch_sizes = [200, 500, 1000, 2000]\nresults_bs = []\n\n# 标准 PCA 作为基准（重新获取）\nstd_variance = std_pca.explained_variance_ratio_.sum()\n\nprint(\"批次大小对结果的影响:\")\nprint(\"-\" * 50)\n\nfor bs in batch_sizes:\n    inc_pca_test = IncrementalPCA(n_components=n_components)\n    \n    for X_batch in np.array_split(X, max(1, n_samples // bs)):\n        inc_pca_test.partial_fit(X_batch)\n    \n    variance = inc_pca_test.explained_variance_ratio_.sum()\n    diff = abs(variance - std_variance)\n    \n    results_bs.append({\n        'batch_size': bs,\n        'variance': variance,\n        'diff': diff\n    })\n    \n    print(f\"批次大小: {bs:5d} | 方差: {variance:.6f} | 与标准 PCA 差异: {diff:.6f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-size-plot",
   "metadata": {},
   "outputs": [],
   "source": "# 可视化批次大小的影响\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nbatch_sizes_plot = [r['batch_size'] for r in results_bs]\nvariances = [r['variance'] for r in results_bs]\ndiffs = [r['diff'] for r in results_bs]\n\n# 解释方差\nax1 = axes[0]\nax1.plot(batch_sizes_plot, variances, 'o-', color='steelblue', linewidth=2, markersize=8)\nax1.axhline(y=std_variance, color='red', linestyle='--', label='Standard PCA')\nax1.set_xlabel('Batch Size')\nax1.set_ylabel('Total Explained Variance')\nax1.set_title('Explained Variance vs Batch Size')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# 与标准 PCA 的差异\nax2 = axes[1]\nax2.bar(range(len(batch_sizes_plot)), diffs, color='coral', alpha=0.7)\nax2.set_xlabel('Batch Size')\nax2.set_ylabel('Difference from Standard PCA')\nax2.set_title('Accuracy Degradation vs Batch Size')\nax2.set_xticks(range(len(batch_sizes_plot)))\nax2.set_xticklabels(batch_sizes_plot)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "components-section",
   "metadata": {},
   "source": [
    "## 8. 主成分可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-components",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化前 20 个主成分\n",
    "n_show = 20\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < n_show:\n",
    "        component = inc_pca.components_[i].reshape(28, 28)\n",
    "        ax.imshow(component, cmap='RdBu_r')\n",
    "        ax.set_title(f'PC{i+1}\\n({inc_pca.explained_variance_ratio_[i]*100:.1f}%)')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Top 20 Principal Components (Incremental PCA)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## 9. 总结\n",
    "\n",
    "### 关键要点\n",
    "\n",
    "1. **使用方法**：\n",
    "   ```python\n",
    "   # 方法一：使用 partial_fit 逐批训练\n",
    "   inc_pca = IncrementalPCA(n_components=k)\n",
    "   for batch in data_batches:\n",
    "       inc_pca.partial_fit(batch)\n",
    "   \n",
    "   # 方法二：使用 batch_size 参数\n",
    "   inc_pca = IncrementalPCA(n_components=k, batch_size=bs)\n",
    "   inc_pca.fit(X)  # 自动分批处理\n",
    "   ```\n",
    "\n",
    "2. **适用场景**：\n",
    "   - 数据无法一次载入内存\n",
    "   - 流式数据处理\n",
    "   - 在线学习\n",
    "   - 需要增量更新模型\n",
    "\n",
    "3. **批次大小选择**：\n",
    "   - 较大的批次 → 更接近标准 PCA 结果\n",
    "   - 较小的批次 → 更省内存，但精度可能降低\n",
    "   - 建议：批次大小 ≥ 5 × n_components\n",
    "\n",
    "4. **与 memmap 结合**：\n",
    "   - 使用 `np.memmap` 存储磁盘数据\n",
    "   - 实现真正的 out-of-core 计算\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 批次顺序可能影响结果（数据应尽量随机打乱）\n",
    "- 首批数据需要足够多的样本来估计初始成分\n",
    "- 结果是近似的，与标准 PCA 有细微差异"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}