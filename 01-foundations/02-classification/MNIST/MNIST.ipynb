{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MNIST 手写数字分类完整实战\n",
    "\n",
    "## 概述\n",
    "\n",
    "本 Notebook 系统性地介绍分类任务的核心概念与实践方法，涵盖：\n",
    "\n",
    "- **二分类器**：使用 SGD 训练单数字识别模型\n",
    "- **性能评估**：交叉验证、混淆矩阵、精确率、召回率、F1 分数\n",
    "- **阈值调整**：Precision-Recall 曲线、ROC 曲线与 AUC\n",
    "- **多分类策略**：OvR (One-vs-Rest)、OvO (One-vs-One)\n",
    "- **多标签分类**：同时预测多个属性\n",
    "\n",
    "## 数据集\n",
    "\n",
    "MNIST (Modified National Institute of Standards and Technology) 是机器学习领域最经典的基准数据集之一：\n",
    "- 70,000 张 28×28 灰度手写数字图像\n",
    "- 训练集 60,000 张，测试集 10,000 张\n",
    "- 10 个类别 (0-9)\n",
    "\n",
    "## 环境要求\n",
    "\n",
    "```\n",
    "scikit-learn >= 1.0\n",
    "numpy >= 1.20\n",
    "matplotlib >= 3.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. 环境配置与数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 标准库与第三方库导入\n",
    "# =============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# scikit-learn 模块\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, \n",
    "    cross_val_score,\n",
    "    cross_val_predict\n",
    ")\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# 设置随机种子确保可复现性\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Matplotlib 中文显示配置\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境配置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 数据加载\n",
    "# =============================================================================\n",
    "# fetch_openml 从 OpenML 仓库获取标准数据集\n",
    "# MNIST 784 表示每张图片被展平为 784 维向量 (28 × 28 = 784)\n",
    "print(\"正在加载 MNIST 数据集...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=True, parser='auto')\n",
    "\n",
    "X, y = mnist['data'], mnist['target']\n",
    "\n",
    "print(f\"数据集键: {mnist.keys()}\")\n",
    "print(f\"特征矩阵形状: {X.shape}\")\n",
    "print(f\"标签向量形状: {y.shape}\")\n",
    "print(f\"标签类型: {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 数据可视化：查看单个样本\n",
    "# =============================================================================\n",
    "def plot_digit(data, label=None, ax=None):\n",
    "    \"\"\"\n",
    "    可视化单个手写数字图像\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like, shape (784,)\n",
    "        展平的图像数据\n",
    "    label : str, optional\n",
    "        图像标签\n",
    "    ax : matplotlib.axes.Axes, optional\n",
    "        绑定的坐标轴对象\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    \n",
    "    image = np.array(data).reshape(28, 28)\n",
    "    ax.imshow(image, cmap='binary', interpolation='nearest')\n",
    "    ax.axis('off')\n",
    "    if label is not None:\n",
    "        ax.set_title(f'Label: {label}', fontsize=12)\n",
    "\n",
    "# 展示第一个样本\n",
    "some_digit = X.iloc[0].values\n",
    "plot_digit(some_digit, label=y.iloc[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 数据可视化：查看多个样本\n",
    "# =============================================================================\n",
    "def plot_digits(instances, labels, images_per_row=10):\n",
    "    \"\"\"\n",
    "    批量可视化手写数字图像\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    instances : array-like\n",
    "        图像数据集\n",
    "    labels : array-like\n",
    "        对应标签\n",
    "    images_per_row : int\n",
    "        每行显示的图像数量\n",
    "    \"\"\"\n",
    "    n_images = len(instances)\n",
    "    n_rows = (n_images + images_per_row - 1) // images_per_row\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, images_per_row, \n",
    "                             figsize=(images_per_row * 1.2, n_rows * 1.4))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 and images_per_row == 1 else axes\n",
    "    \n",
    "    for idx, ax in enumerate(axes):\n",
    "        if idx < n_images:\n",
    "            image = np.array(instances[idx]).reshape(28, 28)\n",
    "            ax.imshow(image, cmap='binary', interpolation='nearest')\n",
    "            ax.set_title(f'{labels[idx]}', fontsize=9)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 展示前 30 个样本\n",
    "sample_indices = range(30)\n",
    "plot_digits(\n",
    "    X.iloc[sample_indices].values, \n",
    "    y.iloc[sample_indices].values,\n",
    "    images_per_row=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 数据预处理与划分\n",
    "# =============================================================================\n",
    "# 将标签转换为整数类型\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "# MNIST 数据集已预先排序：前 60,000 为训练集，后 10,000 为测试集\n",
    "# 注意：在实际项目中应使用 train_test_split 进行随机划分\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "\n",
    "print(f\"训练集: {X_train.shape[0]} 样本\")\n",
    "print(f\"测试集: {X_test.shape[0]} 样本\")\n",
    "print(f\"类别分布 (训练集): \\n{y_train.value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 二分类器训练\n",
    "\n",
    "### 理论背景\n",
    "\n",
    "**二分类 (Binary Classification)** 是最基本的分类任务，将样本划分为两个互斥类别。\n",
    "\n",
    "我们先构建一个简单任务：**识别数字 5**\n",
    "- 正类 (Positive): 数字 5\n",
    "- 负类 (Negative): 非数字 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-labels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 构建二分类标签\n",
    "# =============================================================================\n",
    "# 布尔索引：True 表示正类 (数字5)，False 表示负类 (非数字5)\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "print(f\"训练集正类比例: {y_train_5.sum() / len(y_train_5):.2%}\")\n",
    "print(f\"测试集正类比例: {y_test_5.sum() / len(y_test_5):.2%}\")\n",
    "print(\"\\n注意：这是一个典型的类别不平衡问题，正类仅占约 10%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sgd-intro",
   "metadata": {},
   "source": [
    "### 2.1 随机梯度下降分类器 (SGDClassifier)\n",
    "\n",
    "**SGD (Stochastic Gradient Descent)** 是一种高效的优化算法：\n",
    "\n",
    "- 每次只使用一个样本（或小批量）更新模型参数\n",
    "- 适合处理大规模数据集\n",
    "- 默认使用 Hinge Loss（等价于线性 SVM）\n",
    "\n",
    "**关键超参数**：\n",
    "- `max_iter`: 最大迭代次数\n",
    "- `tol`: 收敛容忍度\n",
    "- `random_state`: 随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-sgd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 训练 SGD 分类器\n",
    "# =============================================================================\n",
    "sgd_clf = SGDClassifier(\n",
    "    max_iter=1000,      # 最大迭代次数\n",
    "    tol=1e-3,           # 收敛容忍度\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "# 对单个样本进行预测\n",
    "prediction = sgd_clf.predict([some_digit])\n",
    "print(f\"样本真实标签: {y.iloc[0]}\")\n",
    "print(f\"模型预测 (是否为5): {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 模型性能评估\n",
    "\n",
    "### 3.1 交叉验证\n",
    "\n",
    "**K 折交叉验证** 是评估模型泛化能力的标准方法：\n",
    "\n",
    "1. 将数据划分为 K 个子集\n",
    "2. 每次用 K-1 个子集训练，1 个子集验证\n",
    "3. 重复 K 次，取平均性能\n",
    "\n",
    "**分层抽样 (Stratified)**: 保持每折中类别比例与整体一致，对不平衡数据尤为重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 手动实现 K 折交叉验证（用于理解原理）\n",
    "# =============================================================================\n",
    "def manual_cross_validation(clf, X, y, n_splits=3):\n",
    "    \"\"\"\n",
    "    手动实现分层 K 折交叉验证\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : estimator\n",
    "        scikit-learn 分类器\n",
    "    X : array-like\n",
    "        特征矩阵\n",
    "    y : array-like\n",
    "        标签向量\n",
    "    n_splits : int\n",
    "        折数\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list : 每折的准确率\n",
    "    \"\"\"\n",
    "    skfolds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skfolds.split(X, y), 1):\n",
    "        # 克隆分类器，避免使用已训练的模型\n",
    "        clf_clone = clone(clf)\n",
    "        \n",
    "        # 使用 iloc 进行索引（适配 DataFrame）\n",
    "        X_train_fold = X.iloc[train_idx] if hasattr(X, 'iloc') else X[train_idx]\n",
    "        y_train_fold = y.iloc[train_idx] if hasattr(y, 'iloc') else y[train_idx]\n",
    "        X_val_fold = X.iloc[val_idx] if hasattr(X, 'iloc') else X[val_idx]\n",
    "        y_val_fold = y.iloc[val_idx] if hasattr(y, 'iloc') else y[val_idx]\n",
    "        \n",
    "        # 训练与预测\n",
    "        clf_clone.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = clf_clone.predict(X_val_fold)\n",
    "        \n",
    "        # 计算准确率\n",
    "        accuracy = (y_pred == y_val_fold).sum() / len(y_val_fold)\n",
    "        scores.append(accuracy)\n",
    "        print(f\"Fold {fold_idx}: Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "print(\"手动交叉验证结果:\")\n",
    "manual_scores = manual_cross_validation(sgd_clf, X_train, y_train_5, n_splits=3)\n",
    "print(f\"\\n平均准确率: {np.mean(manual_scores):.4f} (+/- {np.std(manual_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv-sklearn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 使用 scikit-learn 的 cross_val_score（推荐方式）\n",
    "# =============================================================================\n",
    "cv_scores = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')\n",
    "print(f\"cross_val_score 结果: {cv_scores}\")\n",
    "print(f\"平均准确率: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dummy-clf",
   "metadata": {},
   "source": [
    "### 3.2 基准分类器：为什么准确率不够？\n",
    "\n",
    "一个\"永远预测为非5\"的分类器也能达到 ~90% 准确率，因为只有约 10% 的样本是数字 5。\n",
    "\n",
    "**结论**: 对于不平衡数据集，**准确率 (Accuracy)** 不是可靠的评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dummy-classifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 构建基准分类器（永远预测为 False）\n",
    "# =============================================================================\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    \"\"\"\n",
    "    一个永远预测为负类的基准分类器\n",
    "    \n",
    "    用于演示：在类别不平衡时，准确率是一个误导性指标\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),), dtype=bool)\n",
    "\n",
    "# 评估基准分类器\n",
    "never_5_clf = Never5Classifier()\n",
    "dummy_scores = cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring='accuracy')\n",
    "\n",
    "print(f\"基准分类器准确率: {dummy_scores}\")\n",
    "print(f\"平均: {dummy_scores.mean():.4f}\")\n",
    "print(\"\\n结论: 一个什么都不做的分类器也能达到 ~90% 准确率！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confusion-matrix-intro",
   "metadata": {},
   "source": [
    "### 3.3 混淆矩阵 (Confusion Matrix)\n",
    "\n",
    "混淆矩阵是评估分类器性能的基础工具：\n",
    "\n",
    "```\n",
    "                    预测\n",
    "                Positive  Negative\n",
    "实际  Positive    TP        FN\n",
    "      Negative    FP        TN\n",
    "```\n",
    "\n",
    "- **TP (True Positive)**: 正确识别的正类\n",
    "- **TN (True Negative)**: 正确识别的负类\n",
    "- **FP (False Positive)**: 误报（Type I Error）\n",
    "- **FN (False Negative)**: 漏报（Type II Error）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 计算混淆矩阵\n",
    "# =============================================================================\n",
    "# cross_val_predict 返回每个样本在作为验证集时的预测结果\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "\n",
    "# 生成混淆矩阵\n",
    "conf_mat = confusion_matrix(y_train_5, y_train_pred)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_mat)\n",
    "print(f\"\\n解读:\")\n",
    "print(f\"  TN (真负): {conf_mat[0, 0]:,} - 正确识别的非5\")\n",
    "print(f\"  FP (假正): {conf_mat[0, 1]:,} - 误判为5的非5\")\n",
    "print(f\"  FN (假负): {conf_mat[1, 0]:,} - 误判为非5的5\")\n",
    "print(f\"  TP (真正): {conf_mat[1, 1]:,} - 正确识别的5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 完美分类器的混淆矩阵（用于对比）\n",
    "# =============================================================================\n",
    "perfect_conf_mat = confusion_matrix(y_train_5, y_train_5)  # 预测 = 真实\n",
    "print(\"完美分类器的混淆矩阵:\")\n",
    "print(perfect_conf_mat)\n",
    "print(\"\\n特点: FP = 0, FN = 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precision-recall-intro",
   "metadata": {},
   "source": [
    "### 3.4 精确率与召回率\n",
    "\n",
    "**精确率 (Precision)**: 预测为正类的样本中，真正为正类的比例\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**召回率 (Recall / Sensitivity / TPR)**: 实际为正类的样本中，被正确识别的比例\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**权衡**:\n",
    "- 高精确率 → 减少误报（宁可漏掉，不可误判）\n",
    "- 高召回率 → 减少漏报（宁可误判，不可漏掉）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precision-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 计算精确率与召回率\n",
    "# =============================================================================\n",
    "precision = precision_score(y_train_5, y_train_pred)\n",
    "recall = recall_score(y_train_5, y_train_pred)\n",
    "\n",
    "print(f\"精确率 (Precision): {precision:.4f}\")\n",
    "print(f\"召回率 (Recall): {recall:.4f}\")\n",
    "\n",
    "# 手动验证计算\n",
    "tp = conf_mat[1, 1]\n",
    "fp = conf_mat[0, 1]\n",
    "fn = conf_mat[1, 0]\n",
    "print(f\"\\n手动计算:\")\n",
    "print(f\"  Precision = TP/(TP+FP) = {tp}/({tp}+{fp}) = {tp/(tp+fp):.4f}\")\n",
    "print(f\"  Recall = TP/(TP+FN) = {tp}/({tp}+{fn}) = {tp/(tp+fn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1-intro",
   "metadata": {},
   "source": [
    "### 3.5 F1 分数\n",
    "\n",
    "**F1 分数**是精确率与召回率的调和平均：\n",
    "$$F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "**特点**:\n",
    "- 只有当精确率和召回率都较高时，F1 才会高\n",
    "- 适用于需要同时关注精确率和召回率的场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 计算 F1 分数\n",
    "# =============================================================================\n",
    "f1 = f1_score(y_train_5, y_train_pred)\n",
    "print(f\"F1 分数: {f1:.4f}\")\n",
    "\n",
    "# 手动计算验证\n",
    "f1_manual = 2 * (precision * recall) / (precision + recall)\n",
    "print(f\"手动计算: 2 × ({precision:.4f} × {recall:.4f}) / ({precision:.4f} + {recall:.4f}) = {f1_manual:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 精确率/召回率权衡与阈值调整\n",
    "\n",
    "SGDClassifier 使用决策函数计算分数：\n",
    "- 分数 > 阈值 → 预测为正类\n",
    "- 分数 ≤ 阈值 → 预测为负类\n",
    "\n",
    "调整阈值可以控制精确率与召回率的权衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decision-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 决策函数与阈值\n",
    "# =============================================================================\n",
    "# 获取单个样本的决策分数\n",
    "score = sgd_clf.decision_function([some_digit])\n",
    "print(f\"样本决策分数: {score[0]:.4f}\")\n",
    "print(f\"默认阈值 (0) 下的预测: {score[0] > 0}\")\n",
    "\n",
    "# 使用不同阈值\n",
    "thresholds_demo = [-10000, 0, 10000, 50000]\n",
    "print(\"\\n不同阈值下的预测:\")\n",
    "for t in thresholds_demo:\n",
    "    print(f\"  阈值 {t:>6}: {score[0] > t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pr-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 精确率-召回率曲线 (Precision-Recall Curve)\n",
    "# =============================================================================\n",
    "# 获取所有训练样本的决策分数\n",
    "y_scores = cross_val_predict(\n",
    "    sgd_clf, X_train, y_train_5, cv=3, method='decision_function'\n",
    ")\n",
    "\n",
    "# 计算不同阈值下的精确率和召回率\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\n",
    "# 绘制精确率/召回率 vs 阈值\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 左图：指标随阈值变化\n",
    "axes[0].plot(thresholds, precisions[:-1], 'b-', label='Precision', linewidth=2)\n",
    "axes[0].plot(thresholds, recalls[:-1], 'g-', label='Recall', linewidth=2)\n",
    "axes[0].set_xlabel('Threshold', fontsize=12)\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "axes[0].set_title('Precision & Recall vs Threshold', fontsize=14)\n",
    "axes[0].legend(loc='center right', fontsize=11)\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 右图：Precision-Recall 曲线\n",
    "axes[1].plot(recalls, precisions, 'b-', linewidth=2)\n",
    "axes[1].set_xlabel('Recall', fontsize=12)\n",
    "axes[1].set_ylabel('Precision', fontsize=12)\n",
    "axes[1].set_title('Precision-Recall Curve', fontsize=14)\n",
    "axes[1].set_xlim([0, 1])\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threshold-90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 设定目标精确率，计算对应阈值\n",
    "# =============================================================================\n",
    "target_precision = 0.90\n",
    "\n",
    "# 找到第一个达到目标精确率的阈值\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= target_precision)]\n",
    "print(f\"达到 {target_precision:.0%} 精确率所需的阈值: {threshold_90_precision:.2f}\")\n",
    "\n",
    "# 使用新阈值进行预测\n",
    "y_train_pred_90 = (y_scores >= threshold_90_precision)\n",
    "\n",
    "# 评估新预测的指标\n",
    "precision_90 = precision_score(y_train_5, y_train_pred_90)\n",
    "recall_90 = recall_score(y_train_5, y_train_pred_90)\n",
    "\n",
    "print(f\"\\n调整阈值后的性能:\")\n",
    "print(f\"  精确率: {precision_90:.4f}\")\n",
    "print(f\"  召回率: {recall_90:.4f}\")\n",
    "print(f\"\\n结论: 提高精确率会降低召回率，这是精确率-召回率权衡的体现\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roc-intro",
   "metadata": {},
   "source": [
    "### 4.1 ROC 曲线与 AUC\n",
    "\n",
    "**ROC (Receiver Operating Characteristic) 曲线**:\n",
    "- 横轴：假正例率 (FPR) = FP / (FP + TN)\n",
    "- 纵轴：真正例率 (TPR) = TP / (TP + FN) = Recall\n",
    "\n",
    "**AUC (Area Under Curve)**:\n",
    "- AUC = 1.0: 完美分类器\n",
    "- AUC = 0.5: 随机猜测\n",
    "- AUC < 0.5: 比随机还差（通常意味着标签反了）\n",
    "\n",
    "**PR 曲线 vs ROC 曲线**:\n",
    "- 正类稀少 → 使用 PR 曲线\n",
    "- 类别平衡 → 使用 ROC 曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roc-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 绘制 ROC 曲线\n",
    "# =============================================================================\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_train_5, y_scores)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, 'b-', linewidth=2, label='SGD Classifier')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=12)\n",
    "plt.title('ROC Curve', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.show()\n",
    "\n",
    "# 计算 AUC\n",
    "auc_score = roc_auc_score(y_train_5, y_scores)\n",
    "print(f\"ROC-AUC 分数: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 模型对比：随机森林 vs SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 随机森林分类器\n",
    "# =============================================================================\n",
    "# 注意：随机森林使用 predict_proba 输出概率，而非 decision_function\n",
    "forest_clf = RandomForestClassifier(\n",
    "    n_estimators=100,      # 树的数量\n",
    "    n_jobs=-1,             # 使用所有 CPU 核心\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 获取预测概率\n",
    "y_probas_forest = cross_val_predict(\n",
    "    forest_clf, X_train, y_train_5, cv=3, method='predict_proba'\n",
    ")\n",
    "\n",
    "# 使用正类概率作为分数\n",
    "y_scores_forest = y_probas_forest[:, 1]\n",
    "\n",
    "# 计算 ROC 曲线\n",
    "fpr_forest, tpr_forest, _ = roc_curve(y_train_5, y_scores_forest)\n",
    "\n",
    "# 绘制对比图\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, 'b:', linewidth=2, label=f'SGD (AUC={auc_score:.3f})')\n",
    "plt.plot(fpr_forest, tpr_forest, 'g-', linewidth=2, \n",
    "         label=f'Random Forest (AUC={roc_auc_score(y_train_5, y_scores_forest):.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve Comparison', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"SGD AUC: {auc_score:.4f}\")\n",
    "print(f\"Random Forest AUC: {roc_auc_score(y_train_5, y_scores_forest):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. 多分类器\n",
    "\n",
    "将二分类扩展到多分类的两种主要策略：\n",
    "\n",
    "1. **OvR (One-vs-Rest)**: 训练 K 个二分类器，每个区分\"类别 k vs 其他\"\n",
    "2. **OvO (One-vs-One)**: 训练 K(K-1)/2 个二分类器，每个区分两个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "svm-multiclass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SVM 多分类器\n",
    "# =============================================================================\n",
    "# 使用小批量数据进行快速演示\n",
    "sample_size = 5000\n",
    "X_train_small = X_train[:sample_size]\n",
    "y_train_small = y_train[:sample_size]\n",
    "\n",
    "print(f\"使用 {sample_size} 个样本进行 SVM 训练演示\")\n",
    "\n",
    "# SVC 默认使用 OvO 策略\n",
    "svm_clf = SVC(kernel='rbf', random_state=RANDOM_STATE)\n",
    "svm_clf.fit(X_train_small, y_train_small)\n",
    "\n",
    "# 预测\n",
    "prediction = svm_clf.predict([some_digit])\n",
    "print(f\"\\n样本真实标签: {y.iloc[0]}\")\n",
    "print(f\"SVM 预测结果: {prediction[0]}\")\n",
    "\n",
    "# 查看决策分数\n",
    "scores = svm_clf.decision_function([some_digit])\n",
    "print(f\"\\n各类别决策分数:\")\n",
    "for i, score in enumerate(scores[0]):\n",
    "    print(f\"  类别 {i}: {score:.4f}\")\n",
    "print(f\"\\n最高分类别: {np.argmax(scores)} (与预测一致)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ovo-classifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 显式使用 OvO 策略\n",
    "# =============================================================================\n",
    "ovo_clf = OneVsOneClassifier(SVC(kernel='rbf', random_state=RANDOM_STATE))\n",
    "ovo_clf.fit(X_train_small, y_train_small)\n",
    "\n",
    "prediction = ovo_clf.predict([some_digit])\n",
    "print(f\"OvO 分类器预测: {prediction[0]}\")\n",
    "print(f\"分类器数量: {len(ovo_clf.estimators_)} (10 个类别需要 45 个分类器)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sgd-multiclass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SGD 多分类（使用 OvR）\n",
    "# =============================================================================\n",
    "# 重新训练 SGD 分类器用于多分类\n",
    "sgd_clf_multi = SGDClassifier(max_iter=1000, tol=1e-3, random_state=RANDOM_STATE)\n",
    "sgd_clf_multi.fit(X_train, y_train)\n",
    "\n",
    "# 查看决策分数\n",
    "scores = sgd_clf_multi.decision_function([some_digit])\n",
    "print(\"SGD 多分类决策分数:\")\n",
    "for i, score in enumerate(scores[0]):\n",
    "    print(f\"  类别 {i}: {score:>10.4f}\")\n",
    "print(f\"\\n预测类别: {np.argmax(scores[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-scaling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 特征缩放对性能的影响\n",
    "# =============================================================================\n",
    "# 标准化：将特征缩放到均值为 0，标准差为 1\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "\n",
    "# 比较缩放前后的性能\n",
    "print(\"特征缩放对 SGD 分类器的影响:\")\n",
    "scores_unscaled = cross_val_score(sgd_clf_multi, X_train, y_train, cv=3)\n",
    "print(f\"  未缩放: {scores_unscaled.mean():.4f} (+/- {scores_unscaled.std():.4f})\")\n",
    "\n",
    "scores_scaled = cross_val_score(sgd_clf_multi, X_train_scaled, y_train, cv=3)\n",
    "print(f\"  已缩放: {scores_scaled.mean():.4f} (+/- {scores_scaled.std():.4f})\")\n",
    "print(\"\\n结论: 特征缩放显著提升了 SGD 分类器的性能\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 误差分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "error-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 多分类混淆矩阵可视化\n",
    "# =============================================================================\n",
    "# 使用缩放后的数据进行预测\n",
    "y_train_pred_multi = cross_val_predict(sgd_clf_multi, X_train_scaled, y_train, cv=3)\n",
    "conf_mx_multi = confusion_matrix(y_train, y_train_pred_multi)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 左图：原始混淆矩阵\n",
    "im1 = axes[0].matshow(conf_mx_multi, cmap=plt.cm.Blues)\n",
    "axes[0].set_title('Confusion Matrix (Raw Counts)', fontsize=14, pad=20)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# 右图：归一化后的错误率矩阵\n",
    "# 按行归一化（每行代表一个真实类别）\n",
    "row_sums = conf_mx_multi.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx_multi / row_sums\n",
    "\n",
    "# 将对角线置零，只显示错误\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "\n",
    "im2 = axes[1].matshow(norm_conf_mx, cmap=plt.cm.Reds)\n",
    "axes[1].set_title('Error Rate Matrix (Diagonal Zeroed)', fontsize=14, pad=20)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 分析最常见的错误\n",
    "print(\"最常见的分类错误 (错误率 > 5%):\")\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and norm_conf_mx[i, j] > 0.05:\n",
    "            print(f\"  {i} 被误判为 {j}: {norm_conf_mx[i, j]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. 多标签分类\n",
    "\n",
    "**多标签分类**: 每个样本可以同时属于多个类别\n",
    "\n",
    "示例任务：\n",
    "1. 该数字是否 ≥ 7？（大数字）\n",
    "2. 该数字是否为奇数？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multilabel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 多标签分类\n",
    "# =============================================================================\n",
    "# 构建多标签目标\n",
    "y_train_large = (y_train >= 7)  # 大数字: 7, 8, 9\n",
    "y_train_odd = (y_train % 2 == 1)  # 奇数: 1, 3, 5, 7, 9\n",
    "\n",
    "# 合并为多标签矩阵\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "\n",
    "print(\"多标签数据形状:\", y_multilabel.shape)\n",
    "print(f\"\\n样本 0 (数字 {y_train.iloc[0]}):\")\n",
    "print(f\"  是否 >= 7: {y_train_large.iloc[0]}\")\n",
    "print(f\"  是否为奇数: {y_train_odd.iloc[0]}\")\n",
    "\n",
    "# 使用 KNN 进行多标签分类\n",
    "# KNN 天然支持多标签输出\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "knn_clf.fit(X_train, y_multilabel)\n",
    "\n",
    "# 预测\n",
    "prediction = knn_clf.predict([some_digit])\n",
    "print(f\"\\n对样本 0 的多标签预测: {prediction[0]}\")\n",
    "print(f\"  [是否>=7, 是否为奇数]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multilabel-eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 多标签分类评估\n",
    "# =============================================================================\n",
    "# 使用小样本进行演示（KNN 预测较慢）\n",
    "sample_size = 10000\n",
    "\n",
    "y_train_knn_pred = cross_val_predict(\n",
    "    knn_clf, \n",
    "    X_train[:sample_size], \n",
    "    y_multilabel[:sample_size], \n",
    "    cv=3\n",
    ")\n",
    "\n",
    "# 计算加权 F1 分数\n",
    "f1_weighted = f1_score(\n",
    "    y_multilabel[:sample_size], \n",
    "    y_train_knn_pred, \n",
    "    average='weighted'\n",
    ")\n",
    "\n",
    "print(f\"多标签分类 F1 分数 (weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "# 分别评估每个标签\n",
    "for i, label_name in enumerate(['large (>=7)', 'odd']):\n",
    "    f1_label = f1_score(\n",
    "        y_multilabel[:sample_size, i], \n",
    "        y_train_knn_pred[:, i]\n",
    "    )\n",
    "    print(f\"  {label_name}: F1 = {f1_label:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 总结\n",
    "\n",
    "### 核心知识点\n",
    "\n",
    "1. **二分类器**\n",
    "   - SGDClassifier 适合大规模数据\n",
    "   - 决策边界由阈值控制\n",
    "\n",
    "2. **性能评估**\n",
    "   - 准确率在不平衡数据上具有误导性\n",
    "   - 混淆矩阵揭示具体错误类型\n",
    "   - 精确率/召回率适合不同业务场景\n",
    "   - F1 分数是精确率与召回率的平衡\n",
    "\n",
    "3. **阈值调整**\n",
    "   - PR 曲线适合正类稀少的场景\n",
    "   - ROC-AUC 适合类别平衡的场景\n",
    "\n",
    "4. **多分类策略**\n",
    "   - OvR: 训练 K 个分类器\n",
    "   - OvO: 训练 K(K-1)/2 个分类器\n",
    "\n",
    "5. **工程实践**\n",
    "   - 特征缩放对某些算法至关重要\n",
    "   - 误差分析帮助定向改进模型\n",
    "\n",
    "### 下一步\n",
    "\n",
    "- 尝试其他算法（LogisticRegression, GradientBoosting）\n",
    "- 超参数调优（GridSearchCV, RandomizedSearchCV）\n",
    "- 特征工程（PCA, 数据增强）\n",
    "- 深度学习方法（CNN）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
