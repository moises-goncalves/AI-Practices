{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Mini-Batch K-Means 算法\n",
    "\n",
    "**核心概念**: Mini-Batch K-Means 是标准 K-Means 的优化变体，通过在小批量数据上迭代更新质心来加速聚类过程\n",
    "\n",
    "## 算法原理\n",
    "\n",
    "与标准 K-Means 每次迭代使用全部数据不同，Mini-Batch K-Means 每次迭代仅使用一个随机采样的小批量:\n",
    "\n",
    "### 算法步骤\n",
    "\n",
    "1. **初始化**: 随机选择 K 个质心\n",
    "2. **采样**: 从数据集中随机采样一个小批量 (batch)\n",
    "3. **分配**: 将小批量中的样本分配给最近的质心\n",
    "4. **更新**: 使用流式平均更新质心 (考虑历史更新次数)\n",
    "5. **迭代**: 重复步骤 2-4 直到收敛\n",
    "\n",
    "### 质心更新公式\n",
    "\n",
    "$$\\mu_i^{(t+1)} = \\mu_i^{(t)} + \\frac{1}{n_i}(x - \\mu_i^{(t)})$$\n",
    "\n",
    "其中 $n_i$ 是质心 $\\mu_i$ 的累计更新次数。\n",
    "\n",
    "## 优势与适用场景\n",
    "\n",
    "- **计算效率**: 时间复杂度显著降低，适合大规模数据集\n",
    "- **内存友好**: 不需要同时加载所有数据到内存\n",
    "- **在线学习**: 支持增量式学习，可处理流式数据\n",
    "- **代价**: 结果质量略有损失，但通常可接受"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.datasets import load_iris, make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# 配置 matplotlib 支持中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-md",
   "metadata": {},
   "source": [
    "## 1. 基础用法\n",
    "\n",
    "使用鸢尾花数据集进行演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y_true = iris.target\n",
    "\n",
    "print(f\"数据集形状: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mini-batch-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Mini-Batch K-Means 模型\n",
    "minibatch_kmeans = MiniBatchKMeans(\n",
    "    n_clusters=3,\n",
    "    batch_size=32,       # 每批次样本数\n",
    "    n_init=10,           # 运行次数\n",
    "    max_iter=100,        # 最大迭代次数\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 拟合并预测\n",
    "y_pred = minibatch_kmeans.fit_predict(X)\n",
    "\n",
    "print(f\"惯性 (Inertia): {minibatch_kmeans.inertia_:.4f}\")\n",
    "print(f\"迭代次数: {minibatch_kmeans.n_iter_}\")\n",
    "print(f\"轮廓系数: {silhouette_score(X, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "params-md",
   "metadata": {},
   "source": [
    "## 2. 关键参数说明\n",
    "\n",
    "| 参数 | 说明 | 建议值 |\n",
    "|------|------|--------|\n",
    "| `n_clusters` | 簇的数量 | 根据业务需求或评估指标确定 |\n",
    "| `batch_size` | 每批样本数 | 通常 100-1000，越大越接近标准 K-Means |\n",
    "| `n_init` | 独立运行次数 | 3-10 |\n",
    "| `max_iter` | 最大迭代次数 | 100-300 |\n",
    "| `max_no_improvement` | 早停容忍度 | 10-100 |\n",
    "| `reassignment_ratio` | 质心重分配阈值 | 0.01 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-size-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索 batch_size 对结果的影响\n",
    "batch_sizes = [8, 16, 32, 64, 128]\n",
    "results = []\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    mbk = MiniBatchKMeans(n_clusters=3, batch_size=bs, n_init=10, random_state=42)\n",
    "    mbk.fit(X)\n",
    "    score = silhouette_score(X, mbk.labels_)\n",
    "    results.append({\n",
    "        'batch_size': bs,\n",
    "        'inertia': mbk.inertia_,\n",
    "        'silhouette': score\n",
    "    })\n",
    "    print(f\"batch_size={bs:3d}: Inertia={mbk.inertia_:.2f}, Silhouette={score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-md",
   "metadata": {},
   "source": [
    "## 3. K-Means vs Mini-Batch K-Means 性能对比\n",
    "\n",
    "在大规模数据集上比较两种算法的性能差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-large-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成大规模合成数据\n",
    "n_samples = 10000\n",
    "X_large, y_large = make_blobs(\n",
    "    n_samples=n_samples,\n",
    "    centers=5,\n",
    "    cluster_std=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"大规模数据集形状: {X_large.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准 K-Means\n",
    "start_time = time.time()\n",
    "kmeans = KMeans(n_clusters=5, n_init=10, random_state=42)\n",
    "kmeans.fit(X_large)\n",
    "kmeans_time = time.time() - start_time\n",
    "kmeans_silhouette = silhouette_score(X_large, kmeans.labels_)\n",
    "\n",
    "print(\"标准 K-Means:\")\n",
    "print(f\"  运行时间: {kmeans_time:.4f} 秒\")\n",
    "print(f\"  惯性: {kmeans.inertia_:.2f}\")\n",
    "print(f\"  轮廓系数: {kmeans_silhouette:.4f}\")\n",
    "\n",
    "# Mini-Batch K-Means\n",
    "start_time = time.time()\n",
    "mbkmeans = MiniBatchKMeans(n_clusters=5, batch_size=256, n_init=10, random_state=42)\n",
    "mbkmeans.fit(X_large)\n",
    "mbkmeans_time = time.time() - start_time\n",
    "mbkmeans_silhouette = silhouette_score(X_large, mbkmeans.labels_)\n",
    "\n",
    "print(\"\\nMini-Batch K-Means:\")\n",
    "print(f\"  运行时间: {mbkmeans_time:.4f} 秒\")\n",
    "print(f\"  惯性: {mbkmeans.inertia_:.2f}\")\n",
    "print(f\"  轮廓系数: {mbkmeans_silhouette:.4f}\")\n",
    "\n",
    "print(f\"\\n加速比: {kmeans_time / mbkmeans_time:.2f}x\")\n",
    "print(f\"质量损失: {(kmeans_silhouette - mbkmeans_silhouette) / kmeans_silhouette * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scalability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可扩展性测试: 不同数据规模下的性能\n",
    "sample_sizes = [1000, 5000, 10000, 20000, 50000]\n",
    "kmeans_times = []\n",
    "mbkmeans_times = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    X_test, _ = make_blobs(n_samples=n, centers=5, random_state=42)\n",
    "    \n",
    "    # 标准 K-Means\n",
    "    start = time.time()\n",
    "    KMeans(n_clusters=5, n_init=3, random_state=42).fit(X_test)\n",
    "    kmeans_times.append(time.time() - start)\n",
    "    \n",
    "    # Mini-Batch K-Means\n",
    "    start = time.time()\n",
    "    MiniBatchKMeans(n_clusters=5, batch_size=256, n_init=3, random_state=42).fit(X_test)\n",
    "    mbkmeans_times.append(time.time() - start)\n",
    "    \n",
    "    print(f\"n={n:5d}: K-Means={kmeans_times[-1]:.3f}s, Mini-Batch={mbkmeans_times[-1]:.3f}s\")\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sample_sizes, kmeans_times, 'o-', label='K-Means', linewidth=2, markersize=8)\n",
    "plt.plot(sample_sizes, mbkmeans_times, 's-', label='Mini-Batch K-Means', linewidth=2, markersize=8)\n",
    "plt.xlabel('样本数量', fontsize=12)\n",
    "plt.ylabel('运行时间 (秒)', fontsize=12)\n",
    "plt.title('K-Means vs Mini-Batch K-Means 可扩展性对比', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-md",
   "metadata": {},
   "source": [
    "## 4. 聚类结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成二维数据用于可视化\n",
    "X_2d, y_2d = make_blobs(n_samples=1000, centers=4, cluster_std=0.8, random_state=42)\n",
    "\n",
    "# K-Means 和 Mini-Batch K-Means 聚类\n",
    "km = KMeans(n_clusters=4, n_init=10, random_state=42)\n",
    "mbkm = MiniBatchKMeans(n_clusters=4, batch_size=64, n_init=10, random_state=42)\n",
    "\n",
    "km_labels = km.fit_predict(X_2d)\n",
    "mbkm_labels = mbkm.fit_predict(X_2d)\n",
    "\n",
    "# 可视化对比\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 真实标签\n",
    "axes[0].scatter(X_2d[:, 0], X_2d[:, 1], c=y_2d, cmap='viridis', s=20, alpha=0.7)\n",
    "axes[0].set_title('真实标签')\n",
    "axes[0].set_xlabel('特征 1')\n",
    "axes[0].set_ylabel('特征 2')\n",
    "\n",
    "# K-Means\n",
    "axes[1].scatter(X_2d[:, 0], X_2d[:, 1], c=km_labels, cmap='viridis', s=20, alpha=0.7)\n",
    "axes[1].scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n",
    "                c='red', marker='X', s=200, edgecolors='k', linewidths=2)\n",
    "axes[1].set_title(f'K-Means (Silhouette: {silhouette_score(X_2d, km_labels):.3f})')\n",
    "axes[1].set_xlabel('特征 1')\n",
    "axes[1].set_ylabel('特征 2')\n",
    "\n",
    "# Mini-Batch K-Means\n",
    "axes[2].scatter(X_2d[:, 0], X_2d[:, 1], c=mbkm_labels, cmap='viridis', s=20, alpha=0.7)\n",
    "axes[2].scatter(mbkm.cluster_centers_[:, 0], mbkm.cluster_centers_[:, 1],\n",
    "                c='red', marker='X', s=200, edgecolors='k', linewidths=2)\n",
    "axes[2].set_title(f'Mini-Batch K-Means (Silhouette: {silhouette_score(X_2d, mbkm_labels):.3f})')\n",
    "axes[2].set_xlabel('特征 1')\n",
    "axes[2].set_ylabel('特征 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incremental-md",
   "metadata": {},
   "source": [
    "## 5. 增量学习 (partial_fit)\n",
    "\n",
    "Mini-Batch K-Means 支持增量学习，可以分批次处理数据，适合流式数据场景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incremental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟流式数据场景\n",
    "X_stream, _ = make_blobs(n_samples=5000, centers=5, random_state=42)\n",
    "\n",
    "# 创建增量学习模型\n",
    "mbkm_partial = MiniBatchKMeans(n_clusters=5, random_state=42)\n",
    "\n",
    "# 分批次训练\n",
    "batch_size = 500\n",
    "n_batches = len(X_stream) // batch_size\n",
    "\n",
    "for i in range(n_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    batch = X_stream[start_idx:end_idx]\n",
    "    \n",
    "    # 增量更新\n",
    "    mbkm_partial.partial_fit(batch)\n",
    "    \n",
    "    if (i + 1) % 2 == 0:\n",
    "        # 评估当前模型质量\n",
    "        labels = mbkm_partial.predict(X_stream)\n",
    "        score = silhouette_score(X_stream, labels)\n",
    "        print(f\"批次 {i+1}/{n_batches}: 轮廓系数 = {score:.4f}\")\n",
    "\n",
    "# 最终结果\n",
    "final_labels = mbkm_partial.predict(X_stream)\n",
    "print(f\"\\n最终轮廓系数: {silhouette_score(X_stream, final_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-md",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### Mini-Batch K-Means 优点\n",
    "\n",
    "1. **高效性**: 在大规模数据上比标准 K-Means 快数倍至数十倍\n",
    "2. **内存效率**: 每次仅加载一小批数据，内存占用低\n",
    "3. **增量学习**: 支持 `partial_fit`，适合流式数据和在线学习场景\n",
    "4. **质量可接受**: 聚类质量通常与标准 K-Means 相差不大\n",
    "\n",
    "### 使用建议\n",
    "\n",
    "- 当数据量超过 10,000 样本时，考虑使用 Mini-Batch K-Means\n",
    "- `batch_size` 通常设置为 100-1000，需要在速度和质量间权衡\n",
    "- 对于流式数据，使用 `partial_fit` 进行增量更新\n",
    "- 如果对聚类质量要求极高，仍应使用标准 K-Means\n",
    "\n",
    "### 与标准 K-Means 的选择\n",
    "\n",
    "| 场景 | 推荐算法 |\n",
    "|------|----------|\n",
    "| 小数据集 (< 10K) | 标准 K-Means |\n",
    "| 大数据集 (> 10K) | Mini-Batch K-Means |\n",
    "| 流式数据 | Mini-Batch K-Means (partial_fit) |\n",
    "| 质量优先 | 标准 K-Means |\n",
    "| 速度优先 | Mini-Batch K-Means |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
