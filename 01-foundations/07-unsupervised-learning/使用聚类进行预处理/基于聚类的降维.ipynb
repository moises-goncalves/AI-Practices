{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# 使用聚类进行特征工程与预处理\n",
    "\n",
    "**核心概念**: 聚类不仅可以作为最终目标，还可以作为特征工程和预处理的工具，用于降维、特征变换和分类器性能提升\n",
    "\n",
    "## 应用场景\n",
    "\n",
    "1. **特征降维**: 用簇标签或到质心距离替代原始特征\n",
    "2. **半监督学习**: 利用聚类结构传播标签\n",
    "3. **分类器预处理**: 通过聚类转换提升分类性能\n",
    "4. **特征增强**: 将聚类特征作为额外输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits, load_iris, make_blobs\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# 配置 matplotlib\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-md",
   "metadata": {},
   "source": [
    "## 1. 数据准备\n",
    "\n",
    "使用鸢尾花数据集演示聚类作为预处理的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"训练集形状: {X_train.shape}\")\n",
    "print(f\"测试集形状: {X_test.shape}\")\n",
    "print(f\"特征名称: {iris.feature_names}\")\n",
    "print(f\"类别数: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline-md",
   "metadata": {},
   "source": [
    "## 2. 基线模型: 直接使用逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基线: 直接使用逻辑回归\n",
    "log_reg_baseline = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_baseline.fit(X_train, y_train)\n",
    "\n",
    "baseline_train_score = log_reg_baseline.score(X_train, y_train)\n",
    "baseline_test_score = log_reg_baseline.score(X_test, y_test)\n",
    "\n",
    "print(\"基线模型 (直接逻辑回归):\")\n",
    "print(f\"  训练集准确率: {baseline_train_score:.4f}\")\n",
    "print(f\"  测试集准确率: {baseline_test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kmeans-transform-md",
   "metadata": {},
   "source": [
    "## 3. 聚类特征变换\n",
    "\n",
    "### 方法 1: 用到质心的距离作为特征\n",
    "\n",
    "K-Means 的 `transform()` 方法返回每个样本到各个质心的距离，这些距离可以作为新的特征表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kmeans-transform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 K-Means 进行特征变换\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# 变换: 原始特征 -> 到各质心的距离\n",
    "X_train_dist = kmeans.transform(X_train)\n",
    "X_test_dist = kmeans.transform(X_test)\n",
    "\n",
    "print(f\"原始特征维度: {X_train.shape[1]}\")\n",
    "print(f\"变换后特征维度: {X_train_dist.shape[1]}\")\n",
    "\n",
    "# 使用变换后的特征训练逻辑回归\n",
    "log_reg_dist = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_dist.fit(X_train_dist, y_train)\n",
    "\n",
    "dist_train_score = log_reg_dist.score(X_train_dist, y_train)\n",
    "dist_test_score = log_reg_dist.score(X_test_dist, y_test)\n",
    "\n",
    "print(f\"\\n距离特征模型 (K={n_clusters}):\")\n",
    "print(f\"  训练集准确率: {dist_train_score:.4f}\")\n",
    "print(f\"  测试集准确率: {dist_test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-md",
   "metadata": {},
   "source": [
    "## 4. 构建聚类预处理流水线\n",
    "\n",
    "使用 sklearn Pipeline 将聚类变换和分类器组合起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建流水线: K-Means 特征变换 + 逻辑回归\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),           # 标准化\n",
    "    ('kmeans', KMeans(n_clusters=50, n_init=10, random_state=42)),  # 聚类变换\n",
    "    ('log_reg', LogisticRegression(max_iter=1000, random_state=42)) # 分类器\n",
    "])\n",
    "\n",
    "# 训练流水线\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "pipeline_train_score = pipeline.score(X_train, y_train)\n",
    "pipeline_test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(\"流水线模型 (StandardScaler + KMeans + LogisticRegression):\")\n",
    "print(f\"  训练集准确率: {pipeline_train_score:.4f}\")\n",
    "print(f\"  测试集准确率: {pipeline_test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gridsearch-md",
   "metadata": {},
   "source": [
    "## 5. 使用网格搜索优化聚类数\n",
    "\n",
    "通过交叉验证找到最佳的聚类数量。\n",
    "\n",
    "**注意**: Pipeline 中参数命名使用双下划线 `__` 连接步骤名和参数名，如 `kmeans__n_clusters`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gridsearch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'kmeans__n_clusters': range(5, 51, 5)  # 测试 5, 10, 15, ..., 50\n",
    "}\n",
    "\n",
    "# 网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n最佳参数: {grid_search.best_params_}\")\n",
    "print(f\"最佳交叉验证分数: {grid_search.best_score_:.4f}\")\n",
    "print(f\"测试集准确率: {grid_search.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-gridsearch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化网格搜索结果\n",
    "results = grid_search.cv_results_\n",
    "n_clusters_range = param_grid['kmeans__n_clusters']\n",
    "mean_scores = results['mean_test_score']\n",
    "std_scores = results['std_test_score']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(n_clusters_range, mean_scores, 'bo-', linewidth=2, markersize=8)\n",
    "plt.fill_between(n_clusters_range, \n",
    "                 mean_scores - std_scores, \n",
    "                 mean_scores + std_scores, \n",
    "                 alpha=0.2)\n",
    "plt.axvline(x=grid_search.best_params_['kmeans__n_clusters'], \n",
    "            color='r', linestyle='--', label=f\"最佳 K={grid_search.best_params_['kmeans__n_clusters']}\")\n",
    "plt.xlabel('聚类数量 K', fontsize=12)\n",
    "plt.ylabel('交叉验证准确率', fontsize=12)\n",
    "plt.title('聚类数量对分类性能的影响', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-md",
   "metadata": {},
   "source": [
    "## 6. 方法对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比不同方法的性能\n",
    "methods = {\n",
    "    '基线 (直接逻辑回归)': baseline_test_score,\n",
    "    f'距离特征 (K={n_clusters})': dist_test_score,\n",
    "    '流水线 (K=50)': pipeline_test_score,\n",
    "    f'优化后 (K={grid_search.best_params_[\"kmeans__n_clusters\"]})': grid_search.score(X_test, y_test)\n",
    "}\n",
    "\n",
    "print(\"各方法测试集准确率对比:\")\n",
    "print(\"-\" * 50)\n",
    "for method, score in methods.items():\n",
    "    print(f\"{method:40s}: {score:.4f}\")\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(methods.keys(), methods.values(), color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "plt.ylabel('测试集准确率', fontsize=12)\n",
    "plt.title('不同预处理方法的分类性能对比', fontsize=14)\n",
    "plt.ylim(0.9, 1.02)\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "\n",
    "# 添加数值标签\n",
    "for bar, score in zip(bars, methods.values()):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "             f'{score:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digits-md",
   "metadata": {},
   "source": [
    "## 7. 更复杂的示例: 手写数字识别\n",
    "\n",
    "在手写数字数据集上展示聚类预处理的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载手写数字数据集\n",
    "digits = load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "print(f\"数据集形状: {X_digits.shape}\")\n",
    "print(f\"特征数 (像素): {X_digits.shape[1]}\")\n",
    "print(f\"类别数: {len(np.unique(y_digits))}\")\n",
    "\n",
    "# 划分数据\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(\n",
    "    X_digits, y_digits, test_size=0.2, random_state=42, stratify=y_digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digits-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基线模型\n",
    "log_reg_digits_baseline = LogisticRegression(max_iter=5000, random_state=42)\n",
    "log_reg_digits_baseline.fit(X_train_d, y_train_d)\n",
    "\n",
    "baseline_digits_score = log_reg_digits_baseline.score(X_test_d, y_test_d)\n",
    "print(f\"基线模型准确率: {baseline_digits_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digits-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 聚类预处理流水线\n",
    "pipeline_digits = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('kmeans', KMeans(n_init=10, random_state=42)),\n",
    "    ('log_reg', LogisticRegression(max_iter=5000, random_state=42))\n",
    "])\n",
    "\n",
    "# 快速网格搜索 (简化参数范围以加速)\n",
    "param_grid_digits = {\n",
    "    'kmeans__n_clusters': [50, 100, 150, 200]\n",
    "}\n",
    "\n",
    "grid_digits = GridSearchCV(\n",
    "    pipeline_digits, \n",
    "    param_grid_digits, \n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_digits.fit(X_train_d, y_train_d)\n",
    "\n",
    "print(f\"\\n最佳参数: {grid_digits.best_params_}\")\n",
    "print(f\"最佳交叉验证分数: {grid_digits.best_score_:.4f}\")\n",
    "print(f\"测试集准确率: {grid_digits.score(X_test_d, y_test_d):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digits-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手写数字数据集结果对比\n",
    "print(\"\\n手写数字数据集结果:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"基线 (直接逻辑回归, 64特征): {baseline_digits_score:.4f}\")\n",
    "print(f\"聚类预处理 (K={grid_digits.best_params_['kmeans__n_clusters']}, {grid_digits.best_params_['kmeans__n_clusters']}特征): {grid_digits.score(X_test_d, y_test_d):.4f}\")\n",
    "print(f\"\\n特征维度变化: 64 -> {grid_digits.best_params_['kmeans__n_clusters']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "augment-md",
   "metadata": {},
   "source": [
    "## 8. 特征增强: 组合原始特征和聚类特征\n",
    "\n",
    "将聚类得到的距离特征与原始特征组合，可能进一步提升性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "augment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class KMeansFeatureAugmenter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    将 K-Means 距离特征与原始特征组合的自定义转换器\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters=10, random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.kmeans = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.kmeans = KMeans(\n",
    "            n_clusters=self.n_clusters, \n",
    "            n_init=10, \n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        self.kmeans.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # 计算到各质心的距离\n",
    "        distances = self.kmeans.transform(X)\n",
    "        # 组合原始特征和距离特征\n",
    "        return np.hstack([X, distances])\n",
    "\n",
    "# 测试特征增强\n",
    "augmenter = KMeansFeatureAugmenter(n_clusters=20)\n",
    "X_train_aug = augmenter.fit_transform(X_train)\n",
    "X_test_aug = augmenter.transform(X_test)\n",
    "\n",
    "print(f\"原始特征维度: {X_train.shape[1]}\")\n",
    "print(f\"增强后特征维度: {X_train_aug.shape[1]}\")\n",
    "\n",
    "# 训练分类器\n",
    "log_reg_aug = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_aug.fit(X_train_aug, y_train)\n",
    "\n",
    "aug_test_score = log_reg_aug.score(X_test_aug, y_test)\n",
    "print(f\"\\n特征增强模型准确率: {aug_test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-md",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 聚类作为预处理的优点\n",
    "\n",
    "1. **非线性特征变换**: 到质心的距离可以捕获非线性结构\n",
    "2. **降维**: 用少量质心表示高维数据\n",
    "3. **特征增强**: 为分类器提供额外的结构信息\n",
    "4. **可解释性**: 质心具有物理意义\n",
    "\n",
    "### 使用建议\n",
    "\n",
    "| 场景 | 建议 |\n",
    "|------|------|\n",
    "| 高维数据 | 使用聚类降维 (K < 原始维度) |\n",
    "| 数据量大 | 考虑 Mini-Batch K-Means |\n",
    "| 分类性能不足 | 尝试特征增强 |\n",
    "| 参数选择 | 使用网格搜索交叉验证 |\n",
    "\n",
    "### Pipeline 参数语法\n",
    "\n",
    "在 sklearn Pipeline 中，使用双下划线 `__` 访问嵌套组件的参数:\n",
    "\n",
    "```python\n",
    "# 格式: 步骤名__参数名\n",
    "param_grid = {\n",
    "    'kmeans__n_clusters': [10, 50, 100],\n",
    "    'log_reg__C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "```\n",
    "\n",
    "### 关键要点\n",
    "\n",
    "- 聚类预处理是一种无监督特征工程方法\n",
    "- 最佳聚类数需要通过交叉验证确定\n",
    "- 特征增强 (原始+聚类) 有时比单独使用效果更好\n",
    "- 始终使用流水线确保正确的数据泄露预防"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
