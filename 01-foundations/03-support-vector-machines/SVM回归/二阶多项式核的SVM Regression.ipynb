{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 多项式核 SVR (Polynomial Kernel SVR)\n",
    "\n",
    "## 理论背景\n",
    "\n",
    "当数据具有非线性关系时，线性 SVR 无法很好地拟合。多项式核 SVR 通过核技巧将数据隐式映射到高维特征空间，在该空间中进行线性回归，从而实现非线性拟合。\n",
    "\n",
    "### 多项式核函数\n",
    "\n",
    "多项式核的数学形式为：\n",
    "\n",
    "$$K(x, x') = (\\gamma \\cdot x^\\top x' + r)^d$$\n",
    "\n",
    "其中：\n",
    "- $d$: 多项式阶数 (degree)\n",
    "- $\\gamma$: 缩放参数 (gamma)\n",
    "- $r$: 独立项系数 (coef0)，控制高阶项与低阶项的权重\n",
    "\n",
    "### 隐式特征映射\n",
    "\n",
    "以二阶多项式核为例 ($d=2$, $\\gamma=1$, $r=0$)，对于 $x = (x_1, x_2)$：\n",
    "\n",
    "$$\\phi(x) = (x_1^2, x_2^2, \\sqrt{2}x_1 x_2)$$\n",
    "\n",
    "核技巧的关键在于：我们无需显式计算 $\\phi(x)$，只需通过核函数计算内积 $K(x, x') = \\langle\\phi(x), \\phi(x')\\rangle$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_section",
   "metadata": {},
   "source": [
    "## 1. 环境配置与数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 导入必要的库\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# matplotlib 配置\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 生成具有多项式关系的数据\n",
    "# =============================================================================\n",
    "\n",
    "def generate_polynomial_data(n_samples=150, noise_level=0.5, polynomial_degree=2):\n",
    "    \"\"\"\n",
    "    生成具有多项式关系的回归数据\n",
    "    \n",
    "    真实函数: y = 0.5*x^2 - 2*x + 1 + noise\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        样本数量\n",
    "    noise_level : float\n",
    "        噪声标准差\n",
    "    polynomial_degree : int\n",
    "        数据生成的多项式阶数\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : ndarray, shape (n_samples, 1)\n",
    "        特征矩阵\n",
    "    y : ndarray, shape (n_samples,)\n",
    "        目标值\n",
    "    y_true : ndarray, shape (n_samples,)\n",
    "        无噪声的真实值\n",
    "    \"\"\"\n",
    "    X = np.sort(np.random.uniform(-3, 3, n_samples))\n",
    "    \n",
    "    # 生成多项式关系: y = 0.5*x^2 - 2*x + 1\n",
    "    y_true = 0.5 * X**2 - 2 * X + 1\n",
    "    y = y_true + np.random.normal(0, noise_level, n_samples)\n",
    "    \n",
    "    return X.reshape(-1, 1), y, y_true\n",
    "\n",
    "# 生成数据\n",
    "X, y, y_true = generate_polynomial_data(n_samples=150, noise_level=0.5)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape[0]}\")\n",
    "print(f\"测试集大小: {X_test.shape[0]}\")\n",
    "print(f\"数据范围: X ∈ [{X.min():.2f}, {X.max():.2f}]\")\n",
    "print(f\"目标范围: y ∈ [{y.min():.2f}, {y.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization_section",
   "metadata": {},
   "source": [
    "## 2. 数据可视化与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化原始数据和真实多项式函数\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 左图: 散点图与真实曲线\n",
    "ax = axes[0]\n",
    "ax.scatter(X_train, y_train, c='steelblue', alpha=0.6, s=40, \n",
    "           edgecolors='white', label='训练数据')\n",
    "ax.scatter(X_test, y_test, c='coral', alpha=0.6, s=40, \n",
    "           edgecolors='white', label='测试数据')\n",
    "\n",
    "# 绘制真实函数\n",
    "X_line = np.linspace(-3.5, 3.5, 200).reshape(-1, 1)\n",
    "y_true_line = 0.5 * X_line**2 - 2 * X_line + 1\n",
    "ax.plot(X_line, y_true_line, 'g--', linewidth=2, label='真实函数: $0.5x^2 - 2x + 1$')\n",
    "\n",
    "ax.set_xlabel('X', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('多项式回归数据', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 右图: 残差分布\n",
    "ax = axes[1]\n",
    "# 对于原始数据，残差就是噪声\n",
    "X_flat = X.flatten()\n",
    "residuals = y - (0.5 * X_flat**2 - 2 * X_flat + 1)\n",
    "ax.hist(residuals, bins=25, color='steelblue', alpha=0.7, edgecolor='white')\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('残差 (噪声)', fontsize=12)\n",
    "ax.set_ylabel('频数', fontsize=12)\n",
    "ax.set_title(f'噪声分布 (std={residuals.std():.3f})', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_section",
   "metadata": {},
   "source": [
    "## 3. 多项式核 SVR 训练\n",
    "\n",
    "### 核心参数说明\n",
    "\n",
    "| 参数 | 作用 | 典型值范围 |\n",
    "|------|------|------------|\n",
    "| `kernel` | 核函数类型 | 'poly' |\n",
    "| `degree` | 多项式阶数 | 2, 3, 4, 5 |\n",
    "| `C` | 正则化参数 | 0.1 ~ 1000 |\n",
    "| `epsilon` | ε-tube 宽度 | 0.01 ~ 1.0 |\n",
    "| `gamma` | 核系数 | 'scale', 'auto', 或数值 |\n",
    "| `coef0` | 独立项系数 | 0 ~ 10 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 训练二阶多项式核 SVR\n",
    "# =============================================================================\n",
    "\n",
    "# 构建 Pipeline\n",
    "poly_svr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR(\n",
    "        kernel='poly',\n",
    "        degree=2,           # 二阶多项式\n",
    "        C=100,              # 正则化参数\n",
    "        epsilon=0.1,        # ε-tube 宽度\n",
    "        gamma='scale',      # 自动缩放\n",
    "        coef0=1             # 独立项系数\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 训练模型\n",
    "poly_svr.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred_train = poly_svr.predict(X_train)\n",
    "y_pred_test = poly_svr.predict(X_test)\n",
    "\n",
    "# 评估\n",
    "print(\"=\" * 50)\n",
    "print(\"二阶多项式核 SVR 性能评估\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n训练集:\")\n",
    "print(f\"  R² Score: {r2_score(y_train, y_pred_train):.4f}\")\n",
    "print(f\"  MSE: {mean_squared_error(y_train, y_pred_train):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_train, y_pred_train):.4f}\")\n",
    "\n",
    "print(f\"\\n测试集:\")\n",
    "print(f\"  R² Score: {r2_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  MSE: {mean_squared_error(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test, y_pred_test):.4f}\")\n",
    "\n",
    "# 获取支持向量信息\n",
    "n_sv = poly_svr.named_steps['svr'].n_support_\n",
    "print(f\"\\n支持向量数量: {n_sv[0]}\")\n",
    "print(f\"支持向量占比: {n_sv[0] / len(X_train) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_fit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化拟合结果\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 左图: 拟合曲线\n",
    "ax = axes[0]\n",
    "ax.scatter(X_train, y_train, c='steelblue', alpha=0.5, s=30, label='训练数据')\n",
    "ax.scatter(X_test, y_test, c='coral', alpha=0.5, s=30, label='测试数据')\n",
    "\n",
    "# 预测曲线\n",
    "X_plot = np.linspace(X.min() - 0.5, X.max() + 0.5, 300).reshape(-1, 1)\n",
    "y_plot = poly_svr.predict(X_plot)\n",
    "\n",
    "ax.plot(X_plot, y_plot, 'r-', linewidth=2, label='Poly SVR 预测')\n",
    "ax.plot(X_line, y_true_line, 'g--', linewidth=2, alpha=0.7, label='真实函数')\n",
    "\n",
    "# 标记支持向量\n",
    "svr_model = poly_svr.named_steps['svr']\n",
    "scaler = poly_svr.named_steps['scaler']\n",
    "sv_indices = svr_model.support_\n",
    "ax.scatter(X_train[sv_indices], y_train[sv_indices], \n",
    "           s=100, facecolors='none', edgecolors='purple', \n",
    "           linewidths=2, label='支持向量')\n",
    "\n",
    "ax.set_xlabel('X', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('二阶多项式核 SVR 拟合结果', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 右图: 预测值 vs 真实值\n",
    "ax = axes[1]\n",
    "ax.scatter(y_train, y_pred_train, c='steelblue', alpha=0.6, label='训练集')\n",
    "ax.scatter(y_test, y_pred_test, c='coral', alpha=0.6, label='测试集')\n",
    "\n",
    "# 理想线\n",
    "lims = [min(y.min(), y_pred_test.min()) - 0.5, max(y.max(), y_pred_test.max()) + 0.5]\n",
    "ax.plot(lims, lims, 'k--', alpha=0.7, label='理想线 (y=x)')\n",
    "\n",
    "ax.set_xlabel('真实值', fontsize=12)\n",
    "ax.set_ylabel('预测值', fontsize=12)\n",
    "ax.set_title(f'预测值 vs 真实值 (R² = {r2_score(y_test, y_pred_test):.3f})', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "degree_section",
   "metadata": {},
   "source": [
    "## 4. 多项式阶数对比分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "degree_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 比较不同多项式阶数的效果\n",
    "# =============================================================================\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "results = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, degree in enumerate(degrees):\n",
    "    # 训练模型\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svr', SVR(kernel='poly', degree=degree, C=100, epsilon=0.1, coef0=1))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 预测和评估\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    n_sv = model.named_steps['svr'].n_support_[0]\n",
    "    \n",
    "    results.append({\n",
    "        'degree': degree,\n",
    "        'r2': r2,\n",
    "        'mse': mse,\n",
    "        'n_sv': n_sv\n",
    "    })\n",
    "    \n",
    "    # 可视化\n",
    "    ax = axes[idx]\n",
    "    ax.scatter(X_train, y_train, c='steelblue', alpha=0.4, s=20)\n",
    "    y_plot = model.predict(X_plot)\n",
    "    ax.plot(X_plot, y_plot, 'r-', linewidth=2)\n",
    "    ax.plot(X_line, y_true_line, 'g--', linewidth=1.5, alpha=0.7)\n",
    "    ax.set_title(f'Degree = {degree}\\nR² = {r2:.3f}, SV = {n_sv}', fontsize=11)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 最后一个子图: 性能对比\n",
    "ax = axes[-1]\n",
    "degrees_list = [r['degree'] for r in results]\n",
    "r2_list = [r['r2'] for r in results]\n",
    "ax.bar(degrees_list, r2_list, color='steelblue', alpha=0.7, edgecolor='white')\n",
    "ax.set_xlabel('多项式阶数')\n",
    "ax.set_ylabel('R² Score')\n",
    "ax.set_title('不同阶数的测试集 R²', fontsize=11)\n",
    "ax.set_xticks(degrees_list)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('多项式核 SVR: 不同阶数对比', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印结果表格\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"不同多项式阶数的性能对比\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'阶数':<8} {'R²':<12} {'MSE':<12} {'支持向量数':<12}\")\n",
    "print(\"-\"*60)\n",
    "for r in results:\n",
    "    print(f\"{r['degree']:<8} {r['r2']:<12.4f} {r['mse']:<12.4f} {r['n_sv']:<12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparameter_section",
   "metadata": {},
   "source": [
    "## 5. 超参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grid_search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 网格搜索调优\n",
    "# =============================================================================\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'svr__degree': [2, 3],\n",
    "    'svr__C': [10, 100],\n",
    "    'svr__epsilon': [0.05, 0.1],\n",
    "    'svr__coef0': [0, 1]\n",
    "}\n",
    "\n",
    "# 创建基础模型\n",
    "base_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR(kernel='poly', gamma='scale'))\n",
    "])\n",
    "\n",
    "# 网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    base_model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"最佳参数:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\n最佳交叉验证 MSE: {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 使用最佳模型评估\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(f\"\\n测试集性能:\")\n",
    "print(f\"  R² Score: {r2_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"  MSE: {mean_squared_error(y_test, y_pred_best):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test, y_pred_best):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "learning_curve_section",
   "metadata": {},
   "source": [
    "## 6. 学习曲线分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning_curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 绘制学习曲线\n",
    "# =============================================================================\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_model, X_train, y_train,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 转换为正值 MSE\n",
    "train_scores_mean = -train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "test_scores_mean = -test_scores.mean(axis=1)\n",
    "test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 绘制学习曲线\n",
    "ax.fill_between(train_sizes, \n",
    "                train_scores_mean - train_scores_std,\n",
    "                train_scores_mean + train_scores_std, \n",
    "                alpha=0.2, color='steelblue')\n",
    "ax.fill_between(train_sizes, \n",
    "                test_scores_mean - test_scores_std,\n",
    "                test_scores_mean + test_scores_std, \n",
    "                alpha=0.2, color='coral')\n",
    "\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', color='steelblue', \n",
    "        linewidth=2, label='训练集 MSE')\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', color='coral', \n",
    "        linewidth=2, label='验证集 MSE')\n",
    "\n",
    "ax.set_xlabel('训练样本数', fontsize=12)\n",
    "ax.set_ylabel('MSE', fontsize=12)\n",
    "ax.set_title('学习曲线 - 多项式核 SVR', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n学习曲线分析:\")\n",
    "print(\"- 如果训练误差和验证误差都高且接近: 模型欠拟合\")\n",
    "print(\"- 如果训练误差低但验证误差高: 模型过拟合\")\n",
    "print(\"- 如果两者都低且接近: 模型拟合良好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unit_test_section",
   "metadata": {},
   "source": [
    "## 7. 单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unit_tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 单元测试\n",
    "# =============================================================================\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"运行所有单元测试\"\"\"\n",
    "    test_results = []\n",
    "    \n",
    "    # 测试 1: 数据生成函数\n",
    "    try:\n",
    "        X_t, y_t, y_true_t = generate_polynomial_data(n_samples=50)\n",
    "        assert X_t.shape == (50, 1), \"特征维度错误\"\n",
    "        assert y_t.shape == (50,), \"目标维度错误\"\n",
    "        assert y_true_t.shape == (50,), \"真实值维度错误\"\n",
    "        test_results.append((\"数据生成函数\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"数据生成函数\", False, str(e)))\n",
    "    \n",
    "    # 测试 2: 多项式核 SVR 可训练\n",
    "    try:\n",
    "        test_model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svr', SVR(kernel='poly', degree=2, C=10))\n",
    "        ])\n",
    "        test_model.fit(X_train, y_train)\n",
    "        assert hasattr(test_model.named_steps['svr'], 'support_'), \"模型未正确训练\"\n",
    "        test_results.append((\"模型训练\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"模型训练\", False, str(e)))\n",
    "    \n",
    "    # 测试 3: 预测输出\n",
    "    try:\n",
    "        predictions = test_model.predict(X_test)\n",
    "        assert predictions.shape == y_test.shape, \"预测维度不匹配\"\n",
    "        assert not np.any(np.isnan(predictions)), \"预测包含 NaN\"\n",
    "        test_results.append((\"预测输出\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"预测输出\", False, str(e)))\n",
    "    \n",
    "    # 测试 4: 不同阶数的核函数\n",
    "    try:\n",
    "        for degree in [1, 2, 3, 4]:\n",
    "            m = SVR(kernel='poly', degree=degree)\n",
    "            m.fit(StandardScaler().fit_transform(X_train), y_train)\n",
    "        test_results.append((\"不同阶数核函数\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"不同阶数核函数\", False, str(e)))\n",
    "    \n",
    "    # 测试 5: 支持向量数量合理\n",
    "    try:\n",
    "        n_sv = test_model.named_steps['svr'].n_support_[0]\n",
    "        assert 0 < n_sv <= len(X_train), \"支持向量数量异常\"\n",
    "        test_results.append((\"支持向量数量\", True, f\"SV={n_sv}\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"支持向量数量\", False, str(e)))\n",
    "    \n",
    "    # 测试 6: R² 值在合理范围\n",
    "    try:\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        assert r2 > 0, f\"R² 值过低: {r2}\"\n",
    "        test_results.append((\"R² 值合理性\", True, f\"R²={r2:.4f}\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"R² 值合理性\", False, str(e)))\n",
    "    \n",
    "    # 输出结果\n",
    "    print(\"=\"*60)\n",
    "    print(\"单元测试结果\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = 0\n",
    "    for name, success, msg in test_results:\n",
    "        status = \"✓ 通过\" if success else \"✗ 失败\"\n",
    "        passed += int(success)\n",
    "        print(f\"{status} | {name}\")\n",
    "        if msg:\n",
    "            print(f\"       {msg}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"总计: {passed}/{len(test_results)} 测试通过\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return passed == len(test_results)\n",
    "\n",
    "# 运行测试\n",
    "all_passed = run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 8. 知识总结\n",
    "\n",
    "### 多项式核 SVR 要点\n",
    "\n",
    "1. **适用场景**\n",
    "   - 数据具有明显的多项式关系\n",
    "   - 特征维度较低时效果更好\n",
    "   - 需要可解释的非线性模型\n",
    "\n",
    "2. **参数选择指南**\n",
    "   - `degree`: 从低阶开始，逐步增加；高阶容易过拟合\n",
    "   - `C`: 数据噪声大时使用较小的 C\n",
    "   - `coef0`: 影响高阶项和低阶项的权重平衡\n",
    "\n",
    "3. **与 RBF 核对比**\n",
    "   - 多项式核: 更适合有明确多项式结构的数据\n",
    "   - RBF 核: 更通用，适合未知非线性关系\n",
    "   - 多项式核计算可能更高效（特别是低阶时）\n",
    "\n",
    "4. **常见问题**\n",
    "   - 高阶多项式可能导致数值不稳定\n",
    "   - 特征缩放对多项式核很重要\n",
    "   - 过高的 `degree` 会导致严重过拟合\n",
    "\n",
    "### 参考文献\n",
    "\n",
    "- Vapnik, V. N. (1995). The Nature of Statistical Learning Theory\n",
    "- Schölkopf, B., & Smola, A. J. (2002). Learning with Kernels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
