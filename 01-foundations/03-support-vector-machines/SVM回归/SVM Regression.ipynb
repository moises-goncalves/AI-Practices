{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 线性支持向量机回归 (Linear SVR)\n",
    "\n",
    "## 理论基础\n",
    "\n",
    "支持向量机回归 (SVR) 将 SVM 的\"大间隔\"思想应用于回归问题。与分类不同，回归目标是找到一个函数 $f(x) = w^\\top x + b$，使得预测值与真实值的偏差在某个阈值 $\\epsilon$ 内。\n",
    "\n",
    "### ε-不敏感损失函数\n",
    "\n",
    "SVR 使用 ε-不敏感损失函数：\n",
    "\n",
    "$$\n",
    "L_\\epsilon(y, f(x)) = \\begin{cases}\n",
    "0, & |y - f(x)| \\le \\epsilon \\\\\n",
    "|y - f(x)| - \\epsilon, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "这意味着：\n",
    "- 预测值在真实值 $\\pm\\epsilon$ 范围内时，损失为 0\n",
    "- 超出该范围的部分才被线性惩罚\n",
    "\n",
    "### 优化目标\n",
    "\n",
    "$$\n",
    "\\min_{w,b,\\xi,\\xi^*} \\frac{1}{2}\\|w\\|^2 + C\\sum_{i=1}^{n}(\\xi_i + \\xi_i^*)\n",
    "$$\n",
    "\n",
    "约束条件：\n",
    "- $y_i - (w^\\top x_i + b) \\le \\epsilon + \\xi_i$\n",
    "- $(w^\\top x_i + b) - y_i \\le \\epsilon + \\xi_i^*$\n",
    "- $\\xi_i, \\xi_i^* \\ge 0$\n",
    "\n",
    "### 关键参数\n",
    "\n",
    "- **C**: 正则化参数，控制模型复杂度与拟合程度的权衡\n",
    "- **ε (epsilon)**: 不敏感区域的宽度，定义\"管道\"的半径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## 1. 环境配置与数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 导入必要的库\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 设置随机种子以确保结果可复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 配置 matplotlib\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 生成带噪声的非线性回归数据\n",
    "# =============================================================================\n",
    "\n",
    "def generate_regression_data(n_samples=100, noise_level=0.3):\n",
    "    \"\"\"\n",
    "    生成用于回归的合成数据集\n",
    "    \n",
    "    真实函数: y = 2*sin(x) + 0.5*x\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        样本数量\n",
    "    noise_level : float\n",
    "        高斯噪声的标准差\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : ndarray, shape (n_samples, 1)\n",
    "        特征矩阵\n",
    "    y : ndarray, shape (n_samples,)\n",
    "        目标值\n",
    "    \"\"\"\n",
    "    X = np.sort(np.random.uniform(-3, 3, n_samples))\n",
    "    y_true = 2 * np.sin(X) + 0.5 * X\n",
    "    y = y_true + np.random.normal(0, noise_level, n_samples)\n",
    "    return X.reshape(-1, 1), y\n",
    "\n",
    "# 生成数据\n",
    "X, y = generate_regression_data(n_samples=100, noise_level=0.3)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape[0]}\")\n",
    "print(f\"测试集大小: {X_test.shape[0]}\")\n",
    "print(f\"特征维度: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization_section",
   "metadata": {},
   "source": [
    "## 2. 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化原始数据分布\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 左图: 散点图\n",
    "axes[0].scatter(X_train, y_train, c='steelblue', alpha=0.7, \n",
    "                edgecolors='white', s=50, label='训练数据')\n",
    "axes[0].scatter(X_test, y_test, c='coral', alpha=0.7, \n",
    "                edgecolors='white', s=50, label='测试数据')\n",
    "\n",
    "# 绘制真实函数\n",
    "X_line = np.linspace(-3, 3, 200).reshape(-1, 1)\n",
    "y_true_line = 2 * np.sin(X_line) + 0.5 * X_line\n",
    "axes[0].plot(X_line, y_true_line, 'g--', linewidth=2, label='真实函数')\n",
    "\n",
    "axes[0].set_xlabel('X', fontsize=12)\n",
    "axes[0].set_ylabel('y', fontsize=12)\n",
    "axes[0].set_title('回归数据分布', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 右图: 目标值分布直方图\n",
    "axes[1].hist(y_train, bins=20, color='steelblue', alpha=0.7, \n",
    "             edgecolor='white', label='训练集')\n",
    "axes[1].hist(y_test, bins=15, color='coral', alpha=0.7, \n",
    "             edgecolor='white', label='测试集')\n",
    "axes[1].set_xlabel('y', fontsize=12)\n",
    "axes[1].set_ylabel('频数', fontsize=12)\n",
    "axes[1].set_title('目标值分布', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_section",
   "metadata": {},
   "source": [
    "## 3. 模型训练与 ε 参数分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 探索不同 epsilon 值对模型的影响\n",
    "# =============================================================================\n",
    "\n",
    "epsilon_values = [0.0, 0.5, 1.0, 1.5, 2.0]\n",
    "models = {}\n",
    "\n",
    "for eps in epsilon_values:\n",
    "    # 构建 Pipeline: 标准化 + LinearSVR\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svr', LinearSVR(epsilon=eps, C=1.0, max_iter=10000, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # 训练模型\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    models[eps] = pipeline\n",
    "    \n",
    "    # 评估\n",
    "    y_pred_train = pipeline.predict(X_train)\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    \n",
    "    print(f\"ε = {eps:.1f}:\")\n",
    "    print(f\"  训练集 R² = {r2_score(y_train, y_pred_train):.4f}\")\n",
    "    print(f\"  测试集 R² = {r2_score(y_test, y_pred_test):.4f}\")\n",
    "    print(f\"  测试集 MSE = {mean_squared_error(y_test, y_pred_test):.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_epsilon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化不同 epsilon 值的拟合效果\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "X_plot = np.linspace(X.min() - 0.5, X.max() + 0.5, 300).reshape(-1, 1)\n",
    "\n",
    "for idx, (eps, model) in enumerate(models.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # 预测\n",
    "    y_plot = model.predict(X_plot)\n",
    "    \n",
    "    # 绘制数据点\n",
    "    ax.scatter(X_train, y_train, c='steelblue', alpha=0.6, \n",
    "               edgecolors='white', s=40, label='训练数据')\n",
    "    \n",
    "    # 绘制预测线和 ε-tube\n",
    "    ax.plot(X_plot, y_plot, 'r-', linewidth=2, label=f'SVR 预测')\n",
    "    ax.fill_between(X_plot.ravel(), y_plot - eps, y_plot + eps, \n",
    "                    alpha=0.2, color='red', label=f'ε-管道 (±{eps})')\n",
    "    \n",
    "    # 获取测试集性能\n",
    "    r2 = r2_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    ax.set_xlabel('X', fontsize=11)\n",
    "    ax.set_ylabel('y', fontsize=11)\n",
    "    ax.set_title(f'ε = {eps:.1f} (R² = {r2:.3f})', fontsize=12)\n",
    "    ax.legend(loc='upper left', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 隐藏多余的子图\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.suptitle('LinearSVR: 不同 ε 值的拟合效果对比', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c_parameter_section",
   "metadata": {},
   "source": [
    "## 4. C 参数（正则化强度）分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 探索不同 C 值对模型的影响\n",
    "# =============================================================================\n",
    "\n",
    "C_values = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "epsilon_fixed = 0.5\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for idx, C in enumerate(C_values):\n",
    "    # 构建并训练模型\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svr', LinearSVR(epsilon=epsilon_fixed, C=C, max_iter=10000, random_state=42))\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # 预测\n",
    "    y_plot = pipeline.predict(X_plot)\n",
    "    r2 = r2_score(y_test, pipeline.predict(X_test))\n",
    "    \n",
    "    # 可视化\n",
    "    ax = axes[idx]\n",
    "    ax.scatter(X_train, y_train, c='steelblue', alpha=0.6, s=30)\n",
    "    ax.plot(X_plot, y_plot, 'r-', linewidth=2)\n",
    "    ax.fill_between(X_plot.ravel(), y_plot - epsilon_fixed, y_plot + epsilon_fixed, \n",
    "                    alpha=0.2, color='red')\n",
    "    ax.set_title(f'C = {C}\\nR² = {r2:.3f}', fontsize=11)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[0].set_ylabel('y')\n",
    "plt.suptitle(f'LinearSVR: 不同 C 值的拟合效果 (ε = {epsilon_fixed})', fontsize=13, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n参数影响总结:\")\n",
    "print(\"- C 值较小: 强正则化，模型更简单，可能欠拟合\")\n",
    "print(\"- C 值较大: 弱正则化，模型更复杂，可能过拟合\")\n",
    "print(\"- 对于线性 SVR，由于模型本身是线性的，C 的影响相对有限\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparameter_section",
   "metadata": {},
   "source": [
    "## 5. 超参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grid_search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 使用网格搜索进行超参数调优\n",
    "# =============================================================================\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'svr__C': [0.1, 1.0, 10.0],\n",
    "    'svr__epsilon': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# 创建 Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', LinearSVR(max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "# 网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"最佳参数:\", grid_search.best_params_)\n",
    "print(f\"最佳交叉验证 MSE: {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 使用最佳模型评估\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "print(f\"\\n测试集性能:\")\n",
    "print(f\"  R² Score: {r2_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  MSE: {mean_squared_error(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test, y_pred_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation_section",
   "metadata": {},
   "source": [
    "## 6. 模型评估与诊断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 残差分析与模型诊断\n",
    "# =============================================================================\n",
    "\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "residuals_train = y_train - y_pred_train\n",
    "residuals_test = y_test - y_pred_test\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. 预测值 vs 真实值\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(y_train, y_pred_train, c='steelblue', alpha=0.6, label='训练集')\n",
    "ax.scatter(y_test, y_pred_test, c='coral', alpha=0.6, label='测试集')\n",
    "lims = [min(y.min(), y_pred_test.min()) - 0.5, max(y.max(), y_pred_test.max()) + 0.5]\n",
    "ax.plot(lims, lims, 'k--', alpha=0.7, label='理想线 (y=x)')\n",
    "ax.set_xlabel('真实值', fontsize=11)\n",
    "ax.set_ylabel('预测值', fontsize=11)\n",
    "ax.set_title('预测值 vs 真实值', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 残差分布\n",
    "ax = axes[0, 1]\n",
    "ax.hist(residuals_train, bins=20, alpha=0.6, color='steelblue', \n",
    "        label=f'训练集 (std={residuals_train.std():.3f})')\n",
    "ax.hist(residuals_test, bins=15, alpha=0.6, color='coral', \n",
    "        label=f'测试集 (std={residuals_test.std():.3f})')\n",
    "ax.axvline(x=0, color='black', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('残差', fontsize=11)\n",
    "ax.set_ylabel('频数', fontsize=11)\n",
    "ax.set_title('残差分布', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 残差 vs 预测值\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(y_pred_train, residuals_train, c='steelblue', alpha=0.6, label='训练集')\n",
    "ax.scatter(y_pred_test, residuals_test, c='coral', alpha=0.6, label='测试集')\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('预测值', fontsize=11)\n",
    "ax.set_ylabel('残差', fontsize=11)\n",
    "ax.set_title('残差 vs 预测值', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 最终拟合结果\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(X_train, y_train, c='steelblue', alpha=0.6, s=40, label='训练数据')\n",
    "ax.scatter(X_test, y_test, c='coral', alpha=0.6, s=40, label='测试数据')\n",
    "y_plot_best = best_model.predict(X_plot)\n",
    "best_eps = grid_search.best_params_['svr__epsilon']\n",
    "ax.plot(X_plot, y_plot_best, 'g-', linewidth=2, label='SVR 预测')\n",
    "ax.fill_between(X_plot.ravel(), y_plot_best - best_eps, y_plot_best + best_eps, \n",
    "                alpha=0.2, color='green', label=f'ε-管道 (±{best_eps})')\n",
    "ax.set_xlabel('X', fontsize=11)\n",
    "ax.set_ylabel('y', fontsize=11)\n",
    "ax.set_title('最佳模型拟合结果', fontsize=12)\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unit_test_section",
   "metadata": {},
   "source": [
    "## 7. 单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unit_tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 单元测试：验证模型和数据处理的正确性\n",
    "# =============================================================================\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"运行所有单元测试\"\"\"\n",
    "    test_results = []\n",
    "    \n",
    "    # 测试 1: 数据生成函数\n",
    "    try:\n",
    "        X_test_gen, y_test_gen = generate_regression_data(n_samples=50)\n",
    "        assert X_test_gen.shape == (50, 1), \"特征维度错误\"\n",
    "        assert y_test_gen.shape == (50,), \"目标维度错误\"\n",
    "        test_results.append((\"数据生成函数\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"数据生成函数\", False, str(e)))\n",
    "    \n",
    "    # 测试 2: 模型可训练性\n",
    "    try:\n",
    "        test_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svr', LinearSVR(epsilon=0.5, max_iter=1000, random_state=42))\n",
    "        ])\n",
    "        test_pipeline.fit(X_train, y_train)\n",
    "        assert hasattr(test_pipeline.named_steps['svr'], 'coef_'), \"模型未正确训练\"\n",
    "        test_results.append((\"模型训练\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"模型训练\", False, str(e)))\n",
    "    \n",
    "    # 测试 3: 预测输出维度\n",
    "    try:\n",
    "        predictions = test_pipeline.predict(X_test)\n",
    "        assert predictions.shape == y_test.shape, \"预测输出维度不匹配\"\n",
    "        test_results.append((\"预测输出维度\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"预测输出维度\", False, str(e)))\n",
    "    \n",
    "    # 测试 4: R² 值在合理范围\n",
    "    try:\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        assert -1 <= r2 <= 1, f\"R² 值异常: {r2}\"\n",
    "        test_results.append((\"R² 值范围\", True, f\"R² = {r2:.4f}\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"R² 值范围\", False, str(e)))\n",
    "    \n",
    "    # 测试 5: 模型参数可访问\n",
    "    try:\n",
    "        coef = test_pipeline.named_steps['svr'].coef_\n",
    "        intercept = test_pipeline.named_steps['svr'].intercept_\n",
    "        assert coef is not None and intercept is not None\n",
    "        test_results.append((\"模型参数访问\", True, f\"系数维度: {coef.shape}\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"模型参数访问\", False, str(e)))\n",
    "    \n",
    "    # 测试 6: Pipeline 结构完整性\n",
    "    try:\n",
    "        assert len(test_pipeline.steps) == 2\n",
    "        assert 'scaler' in test_pipeline.named_steps\n",
    "        assert 'svr' in test_pipeline.named_steps\n",
    "        test_results.append((\"Pipeline 结构\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"Pipeline 结构\", False, str(e)))\n",
    "    \n",
    "    # 输出测试结果\n",
    "    print(\"=\"*60)\n",
    "    print(\"单元测试结果\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = 0\n",
    "    for name, success, msg in test_results:\n",
    "        status = \"✓ 通过\" if success else \"✗ 失败\"\n",
    "        passed += int(success)\n",
    "        print(f\"{status} | {name}\")\n",
    "        if msg:\n",
    "            print(f\"       {msg}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"总计: {passed}/{len(test_results)} 测试通过\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return passed == len(test_results)\n",
    "\n",
    "# 运行测试\n",
    "all_passed = run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "## 8. 知识总结\n",
    "\n",
    "### LinearSVR 的特点\n",
    "\n",
    "1. **算法原理**\n",
    "   - 基于 ε-不敏感损失函数\n",
    "   - 在预测值周围建立\"管道\"，管道内的点不计入损失\n",
    "   - 通过最小化管道外的偏差和权重范数来训练\n",
    "\n",
    "2. **关键参数**\n",
    "   - `epsilon`: 定义不敏感区域的宽度，较大的 ε 导致更多的支持向量\n",
    "   - `C`: 正则化参数，控制模型复杂度\n",
    "   - `loss`: 损失函数类型 ('epsilon_insensitive' 或 'squared_epsilon_insensitive')\n",
    "\n",
    "3. **使用建议**\n",
    "   - 必须对特征进行标准化（SVM 对尺度敏感）\n",
    "   - 适合中等规模数据集（大规模数据考虑 SGDRegressor）\n",
    "   - 对于非线性关系，考虑使用 SVR 配合核函数\n",
    "\n",
    "4. **与其他回归方法对比**\n",
    "   - 相比最小二乘法，SVR 对异常值更鲁棒\n",
    "   - 相比 Ridge/Lasso，SVR 有稀疏解（部分样本成为支持向量）\n",
    "\n",
    "### 参考文献\n",
    "\n",
    "- Drucker, H., et al. (1997). Support Vector Regression Machines\n",
    "- Smola, A. J., & Schölkopf, B. (2004). A Tutorial on Support Vector Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
