{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# SVC 与线性核：实现方式对比\n",
    "\n",
    "## 概述\n",
    "\n",
    "scikit-learn 提供了多种线性 SVM 分类器实现，本 notebook 对比分析它们的差异、适用场景和性能特点。\n",
    "\n",
    "### 三种主要实现\n",
    "\n",
    "| 实现 | 核心库 | 优化目标 | 适用规模 |\n",
    "|------|--------|----------|----------|\n",
    "| `SVC(kernel='linear')` | libsvm | 对偶问题 | 小规模 |\n",
    "| `LinearSVC` | liblinear | 原始/对偶 | 中大规模 |\n",
    "| `SGDClassifier(loss='hinge')` | 自研 | SGD | 超大规模 |\n",
    "\n",
    "### 数学背景\n",
    "\n",
    "线性 SVM 的优化目标：\n",
    "\n",
    "$$\n",
    "\\min_{w,b} \\frac{1}{2}\\|w\\|^2 + C\\sum_{i=1}^{n}\\max(0, 1 - y_i(w^\\top x_i + b))\n",
    "$$\n",
    "\n",
    "其中 $\\max(0, 1 - y_i(w^\\top x_i + b))$ 是 hinge 损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_section",
   "metadata": {},
   "source": [
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 导入库\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification, load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# matplotlib 配置\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_section",
   "metadata": {},
   "source": [
    "## 2. 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 生成二分类数据集\n",
    "# =============================================================================\n",
    "\n",
    "# 使用 make_classification 生成线性可分的数据\n",
    "X, y = make_classification(\n",
    "    n_samples=500,\n",
    "    n_features=2,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=1.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"训练集: {X_train.shape[0]} 样本, {X_train.shape[1]} 特征\")\n",
    "print(f\"测试集: {X_test.shape[0]} 样本\")\n",
    "print(f\"类别分布: 0类 = {sum(y_train==0)}, 1类 = {sum(y_train==1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化数据分布\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 原始数据\n",
    "ax = axes[0]\n",
    "scatter = ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, \n",
    "                     cmap='RdYlBu', alpha=0.7, edgecolors='white', s=50)\n",
    "ax.set_xlabel('特征 1', fontsize=12)\n",
    "ax.set_ylabel('特征 2', fontsize=12)\n",
    "ax.set_title('原始数据分布', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax, label='类别')\n",
    "\n",
    "# 标准化后的数据\n",
    "ax = axes[1]\n",
    "scatter = ax.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, \n",
    "                     cmap='RdYlBu', alpha=0.7, edgecolors='white', s=50)\n",
    "ax.set_xlabel('特征 1 (标准化)', fontsize=12)\n",
    "ax.set_ylabel('特征 2 (标准化)', fontsize=12)\n",
    "ax.set_title('标准化后的数据分布', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax, label='类别')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "implementation_section",
   "metadata": {},
   "source": [
    "## 3. 三种线性 SVM 实现对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 定义三种线性 SVM 分类器\n",
    "# =============================================================================\n",
    "\n",
    "# 设置相同的正则化强度\n",
    "C = 1.0\n",
    "\n",
    "# 定义模型\n",
    "models = {\n",
    "    'SVC (linear kernel)': SVC(kernel='linear', C=C, random_state=42),\n",
    "    'LinearSVC': LinearSVC(C=C, loss='hinge', max_iter=10000, random_state=42),\n",
    "    'SGDClassifier': SGDClassifier(\n",
    "        loss='hinge',           # hinge loss = SVM\n",
    "        alpha=1/(len(X_train) * C),  # alpha ≈ 1/(n*C)\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# 训练和评估\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # 训练\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 预测\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # 评估\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'train_time': train_time,\n",
    "        'model': model\n",
    "    })\n",
    "\n",
    "# 打印结果\n",
    "print(\"=\"*70)\n",
    "print(\"三种线性 SVM 实现性能对比\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'模型':<25} {'训练准确率':<15} {'测试准确率':<15} {'训练时间(ms)':<15}\")\n",
    "print(\"-\"*70)\n",
    "for r in results:\n",
    "    print(f\"{r['name']:<25} {r['train_acc']:<15.4f} {r['test_acc']:<15.4f} {r['train_time']*1000:<15.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization_section",
   "metadata": {},
   "source": [
    "## 4. 决策边界可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decision_boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化决策边界\n",
    "# =============================================================================\n",
    "\n",
    "def plot_decision_boundary(ax, model, X, y, title):\n",
    "    \"\"\"绘制决策边界和间隔\"\"\"\n",
    "    # 创建网格\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # 预测\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # 绘制决策区域\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    \n",
    "    # 绘制决策边界\n",
    "    ax.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
    "    \n",
    "    # 绘制数据点\n",
    "    ax.scatter(X[y==0, 0], X[y==0, 1], c='red', marker='o', \n",
    "               edgecolors='white', s=50, label='类别 0')\n",
    "    ax.scatter(X[y==1, 0], X[y==1, 1], c='blue', marker='s', \n",
    "               edgecolors='white', s=50, label='类别 1')\n",
    "    \n",
    "    ax.set_xlabel('特征 1', fontsize=11)\n",
    "    ax.set_ylabel('特征 2', fontsize=11)\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 绘制三个模型的决策边界\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "    plot_decision_boundary(axes[idx], r['model'], X_train_scaled, y_train, \n",
    "                          f\"{r['name']}\\n(Acc: {r['test_acc']:.3f})\")\n",
    "\n",
    "plt.suptitle('线性 SVM 分类器决策边界对比', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parameter_section",
   "metadata": {},
   "source": [
    "## 5. 模型参数分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_parameters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 分析模型参数（权重和偏置）\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"模型参数对比\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for r in results:\n",
    "    model = r['model']\n",
    "    print(f\"\\n{r['name']}:\")\n",
    "    \n",
    "    # 获取权重和偏置\n",
    "    if hasattr(model, 'coef_'):\n",
    "        weights = model.coef_.flatten()\n",
    "        print(f\"  权重 (w): [{weights[0]:.4f}, {weights[1]:.4f}]\")\n",
    "    \n",
    "    if hasattr(model, 'intercept_'):\n",
    "        intercept = model.intercept_[0] if len(model.intercept_) > 0 else model.intercept_\n",
    "        print(f\"  偏置 (b): {intercept:.4f}\")\n",
    "    \n",
    "    # SVC 特有: 支持向量\n",
    "    if hasattr(model, 'support_'):\n",
    "        print(f\"  支持向量数: {len(model.support_)}\")\n",
    "\n",
    "# 可视化权重向量\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "width = 0.25\n",
    "x = np.arange(2)\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "    if hasattr(r['model'], 'coef_'):\n",
    "        weights = r['model'].coef_.flatten()\n",
    "        ax.bar(x + idx*width, weights, width, label=r['name'], alpha=0.8)\n",
    "\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(['权重 w1', '权重 w2'])\n",
    "ax.set_ylabel('权重值')\n",
    "ax.set_title('三种实现的权重对比')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c_parameter_section",
   "metadata": {},
   "source": [
    "## 6. C 参数影响分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 分析 C 参数对决策边界的影响\n",
    "# =============================================================================\n",
    "\n",
    "C_values = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for idx, C in enumerate(C_values):\n",
    "    # 训练模型\n",
    "    model = LinearSVC(C=C, loss='hinge', max_iter=10000, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 计算准确率\n",
    "    acc = accuracy_score(y_test, model.predict(X_test_scaled))\n",
    "    \n",
    "    # 绘制\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # 创建网格\n",
    "    h = 0.05\n",
    "    x_min, x_max = X_train_scaled[:, 0].min() - 0.5, X_train_scaled[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_train_scaled[:, 1].min() - 0.5, X_train_scaled[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    ax.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, \n",
    "               cmap='RdYlBu', edgecolors='white', s=30)\n",
    "    ax.set_title(f'C = {C}\\nAcc = {acc:.3f}')\n",
    "    ax.set_xlabel('特征 1')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[0].set_ylabel('特征 2')\n",
    "plt.suptitle('正则化参数 C 对决策边界的影响', fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nC 参数总结:\")\n",
    "print(\"- C 较小: 强正则化，间隔更宽，允许更多误分类\")\n",
    "print(\"- C 较大: 弱正则化，间隔更窄，更严格地分类训练样本\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scalability_section",
   "metadata": {},
   "source": [
    "## 7. 大规模数据扩展性测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scalability_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 测试不同规模数据上的训练时间\n",
    "# =============================================================================\n",
    "\n",
    "sample_sizes = [100, 500, 1000, 2000, 5000]\n",
    "timing_results = {name: [] for name in ['SVC (linear)', 'LinearSVC', 'SGDClassifier']}\n",
    "\n",
    "for n_samples in sample_sizes:\n",
    "    # 生成数据\n",
    "    X_scale, y_scale = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=20,\n",
    "        n_informative=10,\n",
    "        n_redundant=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    X_scale = StandardScaler().fit_transform(X_scale)\n",
    "    \n",
    "    # 测试 SVC\n",
    "    if n_samples <= 2000:  # SVC 在大数据上太慢\n",
    "        start = time.time()\n",
    "        SVC(kernel='linear', C=1.0).fit(X_scale, y_scale)\n",
    "        timing_results['SVC (linear)'].append(time.time() - start)\n",
    "    else:\n",
    "        timing_results['SVC (linear)'].append(np.nan)\n",
    "    \n",
    "    # 测试 LinearSVC\n",
    "    start = time.time()\n",
    "    LinearSVC(C=1.0, max_iter=10000).fit(X_scale, y_scale)\n",
    "    timing_results['LinearSVC'].append(time.time() - start)\n",
    "    \n",
    "    # 测试 SGDClassifier\n",
    "    start = time.time()\n",
    "    SGDClassifier(loss='hinge', max_iter=1000).fit(X_scale, y_scale)\n",
    "    timing_results['SGDClassifier'].append(time.time() - start)\n",
    "\n",
    "# 可视化\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for name, times in timing_results.items():\n",
    "    ax.plot(sample_sizes, times, 'o-', linewidth=2, markersize=8, label=name)\n",
    "\n",
    "ax.set_xlabel('样本数量', fontsize=12)\n",
    "ax.set_ylabel('训练时间 (秒)', fontsize=12)\n",
    "ax.set_title('不同实现的扩展性对比', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n扩展性总结:\")\n",
    "print(\"- SVC: O(n²) ~ O(n³) 复杂度，适合小数据集\")\n",
    "print(\"- LinearSVC: O(n) 复杂度，适合中大规模数据\")\n",
    "print(\"- SGDClassifier: O(n) 复杂度，适合超大规模和流式数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unit_test_section",
   "metadata": {},
   "source": [
    "## 8. 单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unit_tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 单元测试\n",
    "# =============================================================================\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"运行单元测试\"\"\"\n",
    "    test_results = []\n",
    "    \n",
    "    # 测试 1: SVC 线性核训练\n",
    "    try:\n",
    "        model = SVC(kernel='linear', C=1.0)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        assert hasattr(model, 'support_'), \"SVC 未正确训练\"\n",
    "        test_results.append((\"SVC 线性核训练\", True, f\"支持向量数: {len(model.support_)}\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"SVC 线性核训练\", False, str(e)))\n",
    "    \n",
    "    # 测试 2: LinearSVC 训练\n",
    "    try:\n",
    "        model = LinearSVC(C=1.0, max_iter=10000)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        assert hasattr(model, 'coef_'), \"LinearSVC 未正确训练\"\n",
    "        test_results.append((\"LinearSVC 训练\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"LinearSVC 训练\", False, str(e)))\n",
    "    \n",
    "    # 测试 3: SGDClassifier 训练\n",
    "    try:\n",
    "        model = SGDClassifier(loss='hinge', max_iter=1000)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        assert hasattr(model, 'coef_'), \"SGDClassifier 未正确训练\"\n",
    "        test_results.append((\"SGDClassifier 训练\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"SGDClassifier 训练\", False, str(e)))\n",
    "    \n",
    "    # 测试 4: 预测输出格式\n",
    "    try:\n",
    "        for name, m in models.items():\n",
    "            pred = m.predict(X_test_scaled)\n",
    "            assert pred.shape == y_test.shape, f\"{name} 预测维度错误\"\n",
    "        test_results.append((\"预测输出格式\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"预测输出格式\", False, str(e)))\n",
    "    \n",
    "    # 测试 5: 准确率合理\n",
    "    try:\n",
    "        for name, m in models.items():\n",
    "            acc = accuracy_score(y_test, m.predict(X_test_scaled))\n",
    "            assert acc > 0.5, f\"{name} 准确率过低: {acc}\"\n",
    "        test_results.append((\"准确率合理性\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"准确率合理性\", False, str(e)))\n",
    "    \n",
    "    # 测试 6: Pipeline 集成\n",
    "    try:\n",
    "        pipe = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svc', LinearSVC(C=1.0, max_iter=10000))\n",
    "        ])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        pred = pipe.predict(X_test)\n",
    "        assert pred.shape == y_test.shape\n",
    "        test_results.append((\"Pipeline 集成\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"Pipeline 集成\", False, str(e)))\n",
    "    \n",
    "    # 输出结果\n",
    "    print(\"=\"*60)\n",
    "    print(\"单元测试结果\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = 0\n",
    "    for name, success, msg in test_results:\n",
    "        status = \"✓ 通过\" if success else \"✗ 失败\"\n",
    "        passed += int(success)\n",
    "        print(f\"{status} | {name}\")\n",
    "        if msg:\n",
    "            print(f\"       {msg}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"总计: {passed}/{len(test_results)} 测试通过\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return passed == len(test_results)\n",
    "\n",
    "# 运行测试\n",
    "all_passed = run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 9. 知识总结\n",
    "\n",
    "### 三种实现的选择指南\n",
    "\n",
    "| 场景 | 推荐实现 | 原因 |\n",
    "|------|----------|------|\n",
    "| 样本数 < 10,000 | `SVC(kernel='linear')` | 稳定可靠，支持向量信息丰富 |\n",
    "| 10,000 < 样本数 < 100,000 | `LinearSVC` | 训练快速，内存效率高 |\n",
    "| 样本数 > 100,000 或流式数据 | `SGDClassifier` | 支持增量学习，内存占用低 |\n",
    "| 需要概率输出 | `SVC(probability=True)` | 支持 Platt scaling |\n",
    "| 需要自定义损失 | `SGDClassifier` | 支持多种损失函数 |\n",
    "\n",
    "### 关键参数\n",
    "\n",
    "1. **C (正则化参数)**\n",
    "   - 控制间隔宽度与误分类惩罚的权衡\n",
    "   - 通常在 $[10^{-3}, 10^3]$ 范围内网格搜索\n",
    "\n",
    "2. **loss (损失函数)**\n",
    "   - `hinge`: 标准 SVM (LinearSVC/SGDClassifier)\n",
    "   - `squared_hinge`: 平方 hinge，梯度更平滑 (LinearSVC 默认)\n",
    "\n",
    "3. **dual (对偶问题)**\n",
    "   - `dual=True`: 样本数 < 特征数时更高效\n",
    "   - `dual=False`: 样本数 > 特征数时更高效\n",
    "\n",
    "### 最佳实践\n",
    "\n",
    "1. 始终对特征进行标准化\n",
    "2. 使用 Pipeline 封装预处理和模型\n",
    "3. 通过交叉验证选择最佳 C 值\n",
    "4. 大数据集优先考虑 LinearSVC 或 SGDClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
