{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 支持向量机线性分类器入门\n",
    "\n",
    "## 理论基础\n",
    "\n",
    "支持向量机 (SVM) 是一种强大的监督学习算法，核心思想是寻找一个最优超平面来分隔不同类别的数据点。\n",
    "\n",
    "### 核心概念\n",
    "\n",
    "1. **超平面 (Hyperplane)**: 在 n 维空间中，超平面是 n-1 维的决策边界\n",
    "   - 二维空间中是一条直线\n",
    "   - 三维空间中是一个平面\n",
    "   - 数学表达: $w^\\top x + b = 0$\n",
    "\n",
    "2. **支持向量 (Support Vectors)**: 距离超平面最近的样本点\n",
    "   - 决定超平面位置的关键样本\n",
    "   - 移除其他样本不影响决策边界\n",
    "\n",
    "3. **间隔 (Margin)**: 超平面到最近样本点的距离\n",
    "   - 几何间隔: $\\gamma = \\frac{2}{\\|w\\|}$\n",
    "   - SVM 的目标是最大化间隔\n",
    "\n",
    "### 硬间隔 vs 软间隔\n",
    "\n",
    "- **硬间隔**: 要求所有样本被正确分类，不允许任何违规\n",
    "- **软间隔**: 允许部分样本违规，通过参数 C 控制权衡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_section",
   "metadata": {},
   "source": [
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 导入必要的库\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# matplotlib 配置\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_section",
   "metadata": {},
   "source": [
    "## 2. 数据准备\n",
    "\n",
    "使用经典的鸢尾花数据集进行二分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 加载并准备鸢尾花数据集\n",
    "# =============================================================================\n",
    "\n",
    "# 加载数据\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 选择两个特征: 花瓣长度和花瓣宽度\n",
    "X = iris['data'][:, (2, 3)]  # petal length, petal width\n",
    "\n",
    "# 二分类任务: 是否为 Virginica (类别 2)\n",
    "y = (iris['target'] == 2).astype(np.float64)\n",
    "\n",
    "# 数据集信息\n",
    "print(\"=\" * 50)\n",
    "print(\"数据集信息\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"样本数量: {X.shape[0]}\")\n",
    "print(f\"特征数量: {X.shape[1]}\")\n",
    "print(f\"特征名称: {iris['feature_names'][2]}, {iris['feature_names'][3]}\")\n",
    "print(f\"\\n类别分布:\")\n",
    "print(f\"  非 Virginica (0): {sum(y == 0):.0f} 样本\")\n",
    "print(f\"  Virginica (1): {sum(y == 1):.0f} 样本\")\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n训练集: {X_train.shape[0]} 样本\")\n",
    "print(f\"测试集: {X_test.shape[0]} 样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化原始数据\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 左图: 散点图\n",
    "ax = axes[0]\n",
    "ax.scatter(X[y==0, 0], X[y==0, 1], c='steelblue', marker='o', \n",
    "           edgecolors='white', s=60, label='非 Virginica')\n",
    "ax.scatter(X[y==1, 0], X[y==1, 1], c='coral', marker='s', \n",
    "           edgecolors='white', s=60, label='Virginica')\n",
    "ax.set_xlabel('花瓣长度 (cm)', fontsize=12)\n",
    "ax.set_ylabel('花瓣宽度 (cm)', fontsize=12)\n",
    "ax.set_title('鸢尾花数据分布', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 右图: 特征分布直方图\n",
    "ax = axes[1]\n",
    "ax.hist(X[y==0, 0], bins=15, alpha=0.6, color='steelblue', \n",
    "        label='非 Virginica - 花瓣长度')\n",
    "ax.hist(X[y==1, 0], bins=15, alpha=0.6, color='coral', \n",
    "        label='Virginica - 花瓣长度')\n",
    "ax.set_xlabel('花瓣长度 (cm)', fontsize=12)\n",
    "ax.set_ylabel('频数', fontsize=12)\n",
    "ax.set_title('花瓣长度分布', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_section",
   "metadata": {},
   "source": [
    "## 3. 构建 SVM 分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 构建标准化 + SVM Pipeline\n",
    "# =============================================================================\n",
    "\n",
    "# 重要: SVM 对特征尺度敏感，必须先标准化!\n",
    "svm_clf = Pipeline([\n",
    "    # 标准化: 将特征缩放到均值=0，标准差=1\n",
    "    ('scaler', StandardScaler()),\n",
    "    \n",
    "    # 线性 SVM 分类器\n",
    "    # C=1: 正则化参数，控制间隔和违规之间的权衡\n",
    "    # loss='hinge': 使用标准的 hinge 损失函数\n",
    "    ('linear_svc', LinearSVC(C=1, loss='hinge', max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "# 训练模型\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Pipeline 结构:\")\n",
    "for name, step in svm_clf.steps:\n",
    "    print(f\"  {name}: {type(step).__name__}\")\n",
    "\n",
    "print(f\"\\n模型参数:\")\n",
    "print(f\"  权重 (w): {svm_clf.named_steps['linear_svc'].coef_.flatten()}\")\n",
    "print(f\"  偏置 (b): {svm_clf.named_steps['linear_svc'].intercept_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "make_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 模型预测\n",
    "# =============================================================================\n",
    "\n",
    "# 测试样本\n",
    "test_samples = [\n",
    "    [5.5, 1.7],  # 较长较宽的花瓣\n",
    "    [2.0, 0.5],  # 较短较窄的花瓣\n",
    "    [4.0, 1.3],  # 中等大小\n",
    "]\n",
    "\n",
    "print(\"预测结果:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'花瓣长度':<12} {'花瓣宽度':<12} {'预测类别':<15} {'决策值':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for sample in test_samples:\n",
    "    pred = svm_clf.predict([sample])[0]\n",
    "    decision = svm_clf.decision_function([sample])[0]\n",
    "    class_name = \"Virginica\" if pred == 1 else \"非 Virginica\"\n",
    "    print(f\"{sample[0]:<12} {sample[1]:<12} {class_name:<15} {decision:<12.4f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"\\n注: 决策值 > 0 预测为正类 (Virginica)，< 0 预测为负类\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization_section",
   "metadata": {},
   "source": [
    "## 4. 决策边界可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_decision_boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化决策边界和间隔\n",
    "# =============================================================================\n",
    "\n",
    "# 创建网格\n",
    "x0_min, x0_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "x1_min, x1_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "xx0, xx1 = np.meshgrid(np.linspace(x0_min, x0_max, 200),\n",
    "                        np.linspace(x1_min, x1_max, 200))\n",
    "\n",
    "# 预测网格点\n",
    "X_grid = np.c_[xx0.ravel(), xx1.ravel()]\n",
    "y_pred = svm_clf.predict(X_grid).reshape(xx0.shape)\n",
    "\n",
    "# 获取决策函数值\n",
    "decision_values = svm_clf.decision_function(X_grid).reshape(xx0.shape)\n",
    "\n",
    "# 绘图\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 绘制决策边界和间隔\n",
    "ax.contourf(xx0, xx1, y_pred, alpha=0.3, cmap='RdYlGn')\n",
    "contours = ax.contour(xx0, xx1, decision_values, levels=[-1, 0, 1], \n",
    "                      colors=['blue', 'black', 'blue'], \n",
    "                      linestyles=['--', '-', '--'], linewidths=[1.5, 2, 1.5])\n",
    "ax.clabel(contours, fmt={-1: 'margin=-1', 0: 'decision boundary', 1: 'margin=+1'}, \n",
    "          inline=True, fontsize=9)\n",
    "\n",
    "# 绘制训练样本\n",
    "ax.scatter(X[y==0, 0], X[y==0, 1], c='red', marker='o', \n",
    "           edgecolors='black', s=60, label='非 Virginica')\n",
    "ax.scatter(X[y==1, 0], X[y==1, 1], c='green', marker='s', \n",
    "           edgecolors='black', s=60, label='Virginica')\n",
    "\n",
    "# 标记测试样本\n",
    "for sample in test_samples:\n",
    "    ax.scatter(sample[0], sample[1], c='yellow', marker='*', \n",
    "               s=200, edgecolors='black', linewidths=2, zorder=5)\n",
    "\n",
    "ax.set_xlabel('花瓣长度 (cm)', fontsize=12)\n",
    "ax.set_ylabel('花瓣宽度 (cm)', fontsize=12)\n",
    "ax.set_title('SVM 线性分类器 - 决策边界与间隔', fontsize=14)\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation_section",
   "metadata": {},
   "source": [
    "## 5. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 评估模型性能\n",
    "# =============================================================================\n",
    "\n",
    "# 预测\n",
    "y_pred_train = svm_clf.predict(X_train)\n",
    "y_pred_test = svm_clf.predict(X_test)\n",
    "\n",
    "# 准确率\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# 交叉验证\n",
    "cv_scores = cross_val_score(svm_clf, X, y, cv=5)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"模型性能评估\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n训练集准确率: {train_acc:.4f}\")\n",
    "print(f\"测试集准确率: {test_acc:.4f}\")\n",
    "print(f\"\\n5-折交叉验证:\")\n",
    "print(f\"  各折准确率: {cv_scores}\")\n",
    "print(f\"  平均准确率: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "# 分类报告\n",
    "print(f\"\\n分类报告 (测试集):\")\n",
    "print(classification_report(y_test, y_pred_test, \n",
    "                           target_names=['非 Virginica', 'Virginica']))\n",
    "\n",
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(f\"混淆矩阵:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_confusion_matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化混淆矩阵\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 左图: 混淆矩阵热力图\n",
    "ax = axes[0]\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=[0, 1], yticks=[0, 1],\n",
    "       xticklabels=['非 Virginica', 'Virginica'],\n",
    "       yticklabels=['非 Virginica', 'Virginica'],\n",
    "       xlabel='预测类别', ylabel='真实类别',\n",
    "       title='混淆矩阵')\n",
    "\n",
    "# 在矩阵上标注数值\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\", fontsize=16,\n",
    "                color=\"white\" if cm[i, j] > cm.max()/2 else \"black\")\n",
    "\n",
    "# 右图: 决策值分布\n",
    "ax = axes[1]\n",
    "decision_train = svm_clf.decision_function(X_train)\n",
    "ax.hist(decision_train[y_train==0], bins=20, alpha=0.6, color='steelblue', \n",
    "        label='非 Virginica', density=True)\n",
    "ax.hist(decision_train[y_train==1], bins=20, alpha=0.6, color='coral', \n",
    "        label='Virginica', density=True)\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=2, label='决策边界')\n",
    "ax.set_xlabel('决策函数值', fontsize=12)\n",
    "ax.set_ylabel('密度', fontsize=12)\n",
    "ax.set_title('决策函数值分布', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c_analysis_section",
   "metadata": {},
   "source": [
    "## 6. 正则化参数 C 的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 分析 C 参数对决策边界的影响\n",
    "# =============================================================================\n",
    "\n",
    "C_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, C in enumerate(C_values):\n",
    "    # 训练模型\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', LinearSVC(C=C, loss='hinge', max_iter=10000, random_state=42))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 计算准确率\n",
    "    acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    # 可视化\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # 决策边界\n",
    "    y_grid = model.predict(X_grid).reshape(xx0.shape)\n",
    "    ax.contourf(xx0, xx1, y_grid, alpha=0.3, cmap='RdYlGn')\n",
    "    \n",
    "    # 间隔边界\n",
    "    decision = model.decision_function(X_grid).reshape(xx0.shape)\n",
    "    ax.contour(xx0, xx1, decision, levels=[-1, 0, 1], \n",
    "               colors=['blue', 'black', 'blue'], \n",
    "               linestyles=['--', '-', '--'])\n",
    "    \n",
    "    # 数据点\n",
    "    ax.scatter(X[y==0, 0], X[y==0, 1], c='red', marker='o', \n",
    "               edgecolors='black', s=30)\n",
    "    ax.scatter(X[y==1, 0], X[y==1, 1], c='green', marker='s', \n",
    "               edgecolors='black', s=30)\n",
    "    \n",
    "    ax.set_title(f'C = {C}\\nAcc = {acc:.3f}', fontsize=12)\n",
    "    ax.set_xlabel('花瓣长度')\n",
    "    ax.set_ylabel('花瓣宽度')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('正则化参数 C 对决策边界的影响', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nC 参数总结:\")\n",
    "print(\"- C 很小 (强正则化): 间隔很宽，模型简单，可能欠拟合\")\n",
    "print(\"- C 很大 (弱正则化): 间隔很窄，模型复杂，可能过拟合\")\n",
    "print(\"- 最佳 C 值通常通过交叉验证确定\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unit_test_section",
   "metadata": {},
   "source": [
    "## 7. 单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unit_tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 单元测试\n",
    "# =============================================================================\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"运行单元测试\"\"\"\n",
    "    test_results = []\n",
    "    \n",
    "    # 测试 1: 数据加载\n",
    "    try:\n",
    "        iris_test = datasets.load_iris()\n",
    "        assert iris_test['data'].shape == (150, 4)\n",
    "        assert iris_test['target'].shape == (150,)\n",
    "        test_results.append((\"数据加载\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"数据加载\", False, str(e)))\n",
    "    \n",
    "    # 测试 2: Pipeline 训练\n",
    "    try:\n",
    "        test_pipe = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svc', LinearSVC(C=1, max_iter=10000))\n",
    "        ])\n",
    "        test_pipe.fit(X_train, y_train)\n",
    "        assert hasattr(test_pipe.named_steps['svc'], 'coef_')\n",
    "        test_results.append((\"Pipeline 训练\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"Pipeline 训练\", False, str(e)))\n",
    "    \n",
    "    # 测试 3: 预测输出\n",
    "    try:\n",
    "        pred = test_pipe.predict(X_test)\n",
    "        assert pred.shape == y_test.shape\n",
    "        assert set(pred).issubset({0, 1})\n",
    "        test_results.append((\"预测输出\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"预测输出\", False, str(e)))\n",
    "    \n",
    "    # 测试 4: 决策函数\n",
    "    try:\n",
    "        decision = test_pipe.decision_function(X_test)\n",
    "        assert decision.shape == (len(X_test),)\n",
    "        test_results.append((\"决策函数\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"决策函数\", False, str(e)))\n",
    "    \n",
    "    # 测试 5: 准确率合理\n",
    "    try:\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        assert acc > 0.7, f\"准确率过低: {acc}\"\n",
    "        test_results.append((\"准确率合理性\", True, f\"Acc = {acc:.4f}\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"准确率合理性\", False, str(e)))\n",
    "    \n",
    "    # 测试 6: 交叉验证\n",
    "    try:\n",
    "        cv = cross_val_score(test_pipe, X, y, cv=3)\n",
    "        assert len(cv) == 3\n",
    "        assert all(0 <= s <= 1 for s in cv)\n",
    "        test_results.append((\"交叉验证\", True, f\"Mean CV = {cv.mean():.4f}\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"交叉验证\", False, str(e)))\n",
    "    \n",
    "    # 输出结果\n",
    "    print(\"=\"*60)\n",
    "    print(\"单元测试结果\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = 0\n",
    "    for name, success, msg in test_results:\n",
    "        status = \"✓ 通过\" if success else \"✗ 失败\"\n",
    "        passed += int(success)\n",
    "        print(f\"{status} | {name}\")\n",
    "        if msg:\n",
    "            print(f\"       {msg}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"总计: {passed}/{len(test_results)} 测试通过\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return passed == len(test_results)\n",
    "\n",
    "# 运行测试\n",
    "all_passed = run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 8. 知识总结\n",
    "\n",
    "### SVM 核心要点\n",
    "\n",
    "1. **最大间隔原理**\n",
    "   - SVM 寻找使间隔最大化的超平面\n",
    "   - 只有支持向量决定边界位置\n",
    "   - 间隔越大，泛化能力通常越好\n",
    "\n",
    "2. **关键参数**\n",
    "   - `C`: 正则化参数\n",
    "     - C 大: 严格分类，小间隔，可能过拟合\n",
    "     - C 小: 宽松分类，大间隔，可能欠拟合\n",
    "   - `kernel`: 核函数类型 ('linear', 'rbf', 'poly')\n",
    "   - `gamma`: RBF 核的参数\n",
    "\n",
    "3. **使用建议**\n",
    "   - 必须标准化特征 (SVM 对尺度敏感)\n",
    "   - 使用 Pipeline 封装预处理和模型\n",
    "   - 通过交叉验证选择最佳参数\n",
    "\n",
    "4. **常用实现类**\n",
    "   - `LinearSVC`: 线性 SVM，训练快\n",
    "   - `SVC`: 支持核技巧，更灵活\n",
    "   - `SVR`: SVM 回归\n",
    "\n",
    "### 参考文献\n",
    "\n",
    "- Cortes, C., & Vapnik, V. (1995). Support-Vector Networks\n",
    "- Schölkopf, B., & Smola, A. J. (2002). Learning with Kernels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
