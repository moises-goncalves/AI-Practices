{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 基于多项式特征的 SVM 非线性分类\n",
    "\n",
    "## 理论背景\n",
    "\n",
    "当数据在原始特征空间中线性不可分时，可以通过添加多项式特征将数据映射到高维空间，在高维空间中实现线性分离。\n",
    "\n",
    "### 多项式特征映射\n",
    "\n",
    "对于二维特征 $(x_1, x_2)$，三阶多项式特征映射为：\n",
    "\n",
    "$$\\phi(x_1, x_2) = (1, x_1, x_2, x_1^2, x_1 x_2, x_2^2, x_1^3, x_1^2 x_2, x_1 x_2^2, x_2^3)$$\n",
    "\n",
    "### 优点与缺点\n",
    "\n",
    "**优点：**\n",
    "- 直观易懂\n",
    "- 可以使用线性分类器\n",
    "- 特征可解释\n",
    "\n",
    "**缺点：**\n",
    "- 特征数量爆炸性增长\n",
    "- 高阶多项式容易过拟合\n",
    "- 计算和内存开销大"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_section",
   "metadata": {},
   "source": [
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 导入必要的库\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# matplotlib 配置\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_section",
   "metadata": {},
   "source": [
    "## 2. 数据准备\n",
    "\n",
    "使用 `make_moons` 生成非线性可分的月牙形数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 生成月牙形非线性数据集\n",
    "# =============================================================================\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.15, random_state=42)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"数据集信息:\")\n",
    "print(f\"  总样本数: {len(X)}\")\n",
    "print(f\"  训练集: {len(X_train)} 样本\")\n",
    "print(f\"  测试集: {len(X_test)} 样本\")\n",
    "print(f\"  特征维度: {X.shape[1]}\")\n",
    "print(f\"  类别分布: 类0 = {sum(y==0)}, 类1 = {sum(y==1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化月牙形数据\n",
    "# =============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.scatter(X[y==0, 0], X[y==0, 1], c='steelblue', marker='o', \n",
    "           edgecolors='white', s=60, label='类别 0')\n",
    "ax.scatter(X[y==1, 0], X[y==1, 1], c='coral', marker='s', \n",
    "           edgecolors='white', s=60, label='类别 1')\n",
    "\n",
    "ax.set_xlabel('特征 1', fontsize=12)\n",
    "ax.set_ylabel('特征 2', fontsize=12)\n",
    "ax.set_title('月牙形数据集 (make_moons) - 非线性可分', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n观察: 两个月牙形类别交错分布，无法用一条直线分开\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear_section",
   "metadata": {},
   "source": [
    "## 3. 线性 SVM 的局限性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear_svm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 展示线性 SVM 在非线性数据上的局限\n",
    "# =============================================================================\n",
    "\n",
    "# 训练线性 SVM\n",
    "linear_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', LinearSVC(C=1, loss='hinge', max_iter=10000, random_state=42))\n",
    "])\n",
    "linear_svm.fit(X_train, y_train)\n",
    "\n",
    "# 评估\n",
    "linear_acc = accuracy_score(y_test, linear_svm.predict(X_test))\n",
    "print(f\"线性 SVM 测试准确率: {linear_acc:.4f}\")\n",
    "\n",
    "# 可视化决策边界\n",
    "def plot_decision_boundary(model, X, y, ax, title):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    ax.scatter(X[y==0, 0], X[y==0, 1], c='steelblue', marker='o', \n",
    "               edgecolors='white', s=40)\n",
    "    ax.scatter(X[y==1, 0], X[y==1, 1], c='coral', marker='s', \n",
    "               edgecolors='white', s=40)\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plot_decision_boundary(linear_svm, X, y, ax, \n",
    "                       f'线性 SVM (准确率: {linear_acc:.2%})')\n",
    "ax.set_xlabel('特征 1')\n",
    "ax.set_ylabel('特征 2')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n结论: 线性 SVM 无法很好地分离月牙形数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polynomial_section",
   "metadata": {},
   "source": [
    "## 4. 多项式特征 + 线性 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polynomial_svm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 构建多项式特征 + 线性 SVM Pipeline\n",
    "# =============================================================================\n",
    "\n",
    "# 创建带多项式特征的 Pipeline\n",
    "polynomial_svm_clf = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=3)),  # 三阶多项式\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', LinearSVC(C=5, loss='hinge', max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "# 训练\n",
    "polynomial_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# 评估\n",
    "poly_acc_train = accuracy_score(y_train, polynomial_svm_clf.predict(X_train))\n",
    "poly_acc_test = accuracy_score(y_test, polynomial_svm_clf.predict(X_test))\n",
    "\n",
    "print(\"多项式特征 SVM 性能:\")\n",
    "print(f\"  训练准确率: {poly_acc_train:.4f}\")\n",
    "print(f\"  测试准确率: {poly_acc_test:.4f}\")\n",
    "\n",
    "# 查看特征维度变化\n",
    "poly_features = polynomial_svm_clf.named_steps['poly_features']\n",
    "print(f\"\\n特征维度变化:\")\n",
    "print(f\"  原始特征数: {X.shape[1]}\")\n",
    "print(f\"  多项式特征数: {poly_features.n_output_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 对比线性 SVM 和多项式 SVM\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 线性 SVM\n",
    "plot_decision_boundary(linear_svm, X, y, axes[0], \n",
    "                       f'线性 SVM\\n准确率: {linear_acc:.2%}')\n",
    "axes[0].set_xlabel('特征 1')\n",
    "axes[0].set_ylabel('特征 2')\n",
    "\n",
    "# 多项式 SVM\n",
    "plot_decision_boundary(polynomial_svm_clf, X, y, axes[1], \n",
    "                       f'多项式特征 SVM (degree=3)\\n准确率: {poly_acc_test:.2%}')\n",
    "axes[1].set_xlabel('特征 1')\n",
    "axes[1].set_ylabel('特征 2')\n",
    "\n",
    "plt.suptitle('线性 vs 多项式特征 SVM', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "degree_section",
   "metadata": {},
   "source": [
    "## 5. 多项式阶数分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "degree_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 分析不同多项式阶数的影响\n",
    "# =============================================================================\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5, 6]\n",
    "results = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, degree in enumerate(degrees):\n",
    "    # 训练模型\n",
    "    model = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=degree)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', LinearSVC(C=5, loss='hinge', max_iter=10000, random_state=42))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 评估\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    n_features = model.named_steps['poly'].n_output_features_\n",
    "    \n",
    "    results.append({\n",
    "        'degree': degree,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'n_features': n_features\n",
    "    })\n",
    "    \n",
    "    # 可视化\n",
    "    plot_decision_boundary(model, X, y, axes[idx], \n",
    "                          f'Degree={degree}\\nAcc={test_acc:.2%}, Features={n_features}')\n",
    "\n",
    "plt.suptitle('多项式阶数对决策边界的影响', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 结果表格\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"不同多项式阶数的性能对比\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'阶数':<8} {'特征数':<12} {'训练准确率':<15} {'测试准确率':<15}\")\n",
    "print(\"-\"*70)\n",
    "for r in results:\n",
    "    print(f\"{r['degree']:<8} {r['n_features']:<12} {r['train_acc']:<15.4f} {r['test_acc']:<15.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_degree_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化阶数与性能的关系\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 左图: 准确率随阶数变化\n",
    "ax = axes[0]\n",
    "ax.plot([r['degree'] for r in results], [r['train_acc'] for r in results], \n",
    "        'o-', linewidth=2, markersize=8, label='训练准确率')\n",
    "ax.plot([r['degree'] for r in results], [r['test_acc'] for r in results], \n",
    "        's-', linewidth=2, markersize=8, label='测试准确率')\n",
    "ax.set_xlabel('多项式阶数', fontsize=12)\n",
    "ax.set_ylabel('准确率', fontsize=12)\n",
    "ax.set_title('准确率 vs 多项式阶数', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xticks([r['degree'] for r in results])\n",
    "\n",
    "# 右图: 特征数随阶数变化\n",
    "ax = axes[1]\n",
    "ax.bar([r['degree'] for r in results], [r['n_features'] for r in results], \n",
    "       color='steelblue', alpha=0.7, edgecolor='white')\n",
    "ax.set_xlabel('多项式阶数', fontsize=12)\n",
    "ax.set_ylabel('特征数量', fontsize=12)\n",
    "ax.set_title('特征维度爆炸', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 添加数值标签\n",
    "for r in results:\n",
    "    ax.text(r['degree'], r['n_features'] + 1, str(r['n_features']), \n",
    "            ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n观察:\")\n",
    "print(\"- 阶数过低: 欠拟合，无法捕获非线性模式\")\n",
    "print(\"- 阶数过高: 特征数爆炸，可能过拟合，计算开销大\")\n",
    "print(\"- 需要在模型复杂度和泛化能力之间找平衡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparameter_section",
   "metadata": {},
   "source": [
    "## 6. 超参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grid_search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 网格搜索找最佳参数\n",
    "# =============================================================================\n",
    "\n",
    "# 参数网格\n",
    "param_grid = {\n",
    "    'poly__degree': [2, 3, 4],\n",
    "    'svm__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# 基础模型\n",
    "base_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', LinearSVC(loss='hinge', max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "# 网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    base_model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"网格搜索结果:\")\n",
    "print(f\"  最佳参数: {grid_search.best_params_}\")\n",
    "print(f\"  最佳交叉验证准确率: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 最佳模型评估\n",
    "best_model = grid_search.best_estimator_\n",
    "best_acc = accuracy_score(y_test, best_model.predict(X_test))\n",
    "print(f\"  测试集准确率: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unit_test_section",
   "metadata": {},
   "source": [
    "## 7. 单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unit_tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 单元测试\n",
    "# =============================================================================\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"运行单元测试\"\"\"\n",
    "    test_results = []\n",
    "    \n",
    "    # 测试 1: make_moons 数据生成\n",
    "    try:\n",
    "        X_t, y_t = make_moons(n_samples=100, noise=0.1)\n",
    "        assert X_t.shape == (100, 2)\n",
    "        assert y_t.shape == (100,)\n",
    "        test_results.append((\"数据生成\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"数据生成\", False, str(e)))\n",
    "    \n",
    "    # 测试 2: 多项式特征生成\n",
    "    try:\n",
    "        poly = PolynomialFeatures(degree=3)\n",
    "        X_poly = poly.fit_transform(X_t)\n",
    "        assert X_poly.shape[1] == 10  # (1, x1, x2, x1^2, x1*x2, x2^2, x1^3, ...)\n",
    "        test_results.append((\"多项式特征\", True, f\"特征数: {X_poly.shape[1]}\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"多项式特征\", False, str(e)))\n",
    "    \n",
    "    # 测试 3: Pipeline 训练\n",
    "    try:\n",
    "        test_pipe = Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=3)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svm', LinearSVC(max_iter=10000))\n",
    "        ])\n",
    "        test_pipe.fit(X_train, y_train)\n",
    "        assert hasattr(test_pipe.named_steps['svm'], 'coef_')\n",
    "        test_results.append((\"Pipeline 训练\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"Pipeline 训练\", False, str(e)))\n",
    "    \n",
    "    # 测试 4: 预测输出\n",
    "    try:\n",
    "        pred = test_pipe.predict(X_test)\n",
    "        assert pred.shape == y_test.shape\n",
    "        test_results.append((\"预测输出\", True, \"\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"预测输出\", False, str(e)))\n",
    "    \n",
    "    # 测试 5: 准确率显著提升\n",
    "    try:\n",
    "        poly_acc = accuracy_score(y_test, pred)\n",
    "        # 多项式 SVM 应该比线性 SVM 好\n",
    "        assert poly_acc > linear_acc, \"多项式 SVM 应该优于线性 SVM\"\n",
    "        test_results.append((\"准确率提升\", True, f\"线性:{linear_acc:.2%} < 多项式:{poly_acc:.2%}\"))\n",
    "    except Exception as e:\n",
    "        test_results.append((\"准确率提升\", False, str(e)))\n",
    "    \n",
    "    # 输出结果\n",
    "    print(\"=\"*60)\n",
    "    print(\"单元测试结果\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = 0\n",
    "    for name, success, msg in test_results:\n",
    "        status = \"✓ 通过\" if success else \"✗ 失败\"\n",
    "        passed += int(success)\n",
    "        print(f\"{status} | {name}\")\n",
    "        if msg:\n",
    "            print(f\"       {msg}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"总计: {passed}/{len(test_results)} 测试通过\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return passed == len(test_results)\n",
    "\n",
    "# 运行测试\n",
    "all_passed = run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 8. 知识总结\n",
    "\n",
    "### 多项式特征方法\n",
    "\n",
    "1. **核心思想**\n",
    "   - 显式构造高阶多项式特征\n",
    "   - 在高维空间中使用线性分类器\n",
    "   - 将非线性问题转化为线性问题\n",
    "\n",
    "2. **优点**\n",
    "   - 直观，特征可解释\n",
    "   - 可以使用高效的线性求解器\n",
    "   - 适合低维数据\n",
    "\n",
    "3. **缺点**\n",
    "   - 特征数随阶数指数增长\n",
    "   - 内存和计算开销大\n",
    "   - 高阶容易过拟合\n",
    "\n",
    "4. **替代方案: 核技巧**\n",
    "   - 使用多项式核 `SVC(kernel='poly')` \n",
    "   - 无需显式构造高维特征\n",
    "   - 通过核函数隐式计算\n",
    "\n",
    "### 参数选择建议\n",
    "\n",
    "- `degree`: 从低阶开始 (2-3)，通过交叉验证确定\n",
    "- `C`: 较大的 C 可能导致过拟合，需要调优\n",
    "- 对于高维数据，优先考虑核方法而非显式多项式特征"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
