### 超参数优化

## 超参数优化过程：
1. 定义超参数搜索空间
2. 构建模型
3. 将模型在训练数据上拟合， 并衡量其在验证数据上的性能
4. 选择要尝试的下一个超参数组合
5. 重复步骤3和4，直到达到预定的计算预算
6. 使用在验证集上表现最好的超参数组合， 在训练集和验证集的联合数据集上训练最终模型
7. 在测试集上评估最终模型
8. 部署最终模型

## 常用的超参数优化方法
1. 随机搜索 （Random Search）
2. 网格搜索 （Grid Search）
3. 贝叶斯优化 （Bayesian Optimization）
4. 遗传算法 （Genetic Algorithms）
5. 超带宽优化 （Hyperband）
6. 梯度提升优化 （Gradient-based Optimization）
7. 多臂老虎机算法 （Multi-Armed Bandit Algorithms）
8. 强化学习 （Reinforcement Learning）
9. 组合方法 （Hybrid Methods）

## 超参数优化工具
1. Keras Tuner: 一个用于超参数优化的Keras API 库，支持随机搜索、贝叶斯优化和超带宽优化等方法。
2. Optuna: 一个开源的超参数优化框架，支持多种优化算法，包括贝叶斯优化、TPE（Tree-structured Parzen Estimator）和CMA-ES（Covariance Matrix Adaptation Evolution Strategy）等。
3. Hyperopt: 一个用于超参数优化的Python库，支持随机搜索和贝叶斯优化等方法。
4. Scikit-Optimize: 一个用于超参数优化的Python库，支持随机搜索、贝叶斯优化和遗传算法等方法。
5. Optuna: 一个用于超参数优化的Python库，支持贝叶斯优化、TPE（Tree-structured Parzen Estimator）和CMA-ES（Covariance Matrix Adaptation Evolution Strategy）等。
6. Hyperband: 一个用于超参数优化的Python库，支持超带宽优化方法。
7. Hyperas: 一个用于超参数优化的Python库，支持遗传算法和强化学习方法 将Keras与Hyperopt结合使用

## 超参数调整技巧
1. 使用交叉验证：在训练过程中使用交叉验证来评估模型的性能，以避免过拟合。
2. 使用早停：在训练过程中监控验证集的性能，并在验证集的性能不再提高时停止训练。
3. 使用正则化：在模型中使用正则化技术，如L1或L2正则化，以防止过拟合。
4. 使用dropout：在模型中使用dropout技术，以防止过拟合。
5. 使用数据增强：在训练过程中使用数据增强技术，如旋转、缩放、裁剪等，以增加数据的多样性。

## 注意事项
1. 注意超参数调整在计算时验证集上进行 在次数多的时候实际上也在使用验证集的信息导致信息泄漏 过拟合