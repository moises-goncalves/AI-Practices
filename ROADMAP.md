# AI-Practices é¡¹ç›®ä¼˜åŒ–è·¯çº¿å›¾

## ä¸€ã€é¡¹ç›®ç°çŠ¶åˆ†æ

### å·²æœ‰ä¼˜åŠ¿

| ç»´åº¦ | ç°çŠ¶ |
|:-----|:-----|
| **å†…å®¹è¦†ç›–** | 9å¤§æ¨¡å—ã€180+ notebooksã€æ¶µç›–ML/DL/CV/NLP/RL |
| **å·¥ç¨‹è§„èŒƒ** | æœ‰CONTRIBUTING.mdã€CODEOWNERSã€Issueæ¨¡æ¿ã€PRæ¨¡æ¿ |
| **CI/CD** | å·²æœ‰validate-structureã€deploy-docsã€dependabot |
| **æ–‡æ¡£ç³»ç»Ÿ** | VitePressæ–‡æ¡£ç«™ã€ä¸­è‹±åŒè¯­README |
| **æµ‹è¯•è¦†ç›–** | éƒ¨åˆ†æ¨¡å—æœ‰æµ‹è¯•(RLæ¨¡å—è¾ƒå®Œå–„ï¼Œçº¦20ä¸ªæµ‹è¯•æ–‡ä»¶) |
| **ä»£ç è´¨é‡** | å·²é…ç½® pre-commit hooks (black, isort, ruff, nbqa) |

### å¾…æ”¹è¿›é¢†åŸŸ

| ç»´åº¦ | é—®é¢˜ |
|:-----|:-----|
| **å†…å®¹ç©ºç™½** | ç¼ºå°‘LLM/Diffusion/å¤šæ¨¡æ€ï¼›éƒ¨åˆ†ç›®å½•ä¸ºç©º |
| **æµ‹è¯•è¦†ç›–** | 01-06æ¨¡å—å‡ ä¹æ— æµ‹è¯• |
| **Docker** | æ— å®¹å™¨åŒ–æ”¯æŒ |

---

## äºŒã€å·²å®Œæˆå†…å®¹ (2024)

### Phase 1: Transformer æ¨¡å— âœ…

#### 1.1 `04-sequence-models/05-transformer` å·²å®Œæˆ

```
04-sequence-models/05-transformer/
â”œâ”€â”€ 01-attention-mechanism/
â”‚   â”œâ”€â”€ self_attention.ipynb         # ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ› + æ–¹å·®è¯æ˜
â”‚   â””â”€â”€ multi_head_attention.ipynb   # å¤šå¤´æ³¨æ„åŠ› + Flash Attention
â”œâ”€â”€ 02-transformer-architecture/
â”‚   â”œâ”€â”€ encoder.ipynb                # Pre-LN/Post-LN + GELU
â”‚   â”œâ”€â”€ decoder.ipynb                # è§£ç å™¨æ¶æ„
â”‚   â””â”€â”€ positional_encoding.ipynb    # ä½ç½®ç¼–ç  (RoPE, ALiBi)
â””â”€â”€ 03-bert-gpt-basics/
    â””â”€â”€ gpt_from_scratch.ipynb       # GPTä»é›¶å®ç° + KV Cache
```

**ç‰¹æ€§**:
- ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›çš„æ•°å­¦è¯æ˜ (æ–¹å·®ä¸º d_k)
- Pre-LN/Post-LN æ¶æ„åˆ‡æ¢
- GELU æ¿€æ´»å‡½æ•°å®ç°
- å› æœæ©ç å¯è§†åŒ–
- KV Cache æ¨ç†åŠ é€Ÿ
- Nucleus Sampling é‡‡æ ·ç­–ç•¥

### Phase 2: ç”Ÿæˆå¼æ¨¡å‹ âœ…

#### 2.1 `06-generative-models/01-vae` å·²å®Œæˆ

```
06-generative-models/01-vae/
â””â”€â”€ variational_ae.ipynb             # VAE + ELBOæ¨å¯¼ + KLæ•£åº¦è§£æè§£
```

**ç‰¹æ€§**:
- ELBO (Evidence Lower Bound) å®Œæ•´æ¨å¯¼
- KL æ•£åº¦è§£æè§£è¯æ˜
- é‡å‚æ•°åŒ–æŠ€å·§
- Î²-VAE å˜ä½“
- CNN-VAE å·ç§¯æ¶æ„
- VQ-VAE ç¦»æ•£ç æœ¬
- æ½œåœ¨ç©ºé—´æµå½¢å¯è§†åŒ–

#### 2.2 `06-generative-models/03-diffusion` å·²å®Œæˆ

```
06-generative-models/03-diffusion/
â”œâ”€â”€ ddpm_basics.ipynb                # DDPMåŸºç¡€ + ç‰©ç†ç›´è§‰ + SNRåˆ†æ
â””â”€â”€ ddpm_implementation.ipynb        # å®Œæ•´å®ç°
```

**ç‰¹æ€§**:
- éå¹³è¡¡çƒ­åŠ›å­¦æ‰©æ•£è¿‡ç¨‹ç±»æ¯”
- Fokker-Planck æ–¹ç¨‹è§£é‡Š
- Closed-form å‰å‘è¿‡ç¨‹æ¨å¯¼
- ä¿¡å™ªæ¯” (SNR) å¯è§†åŒ–
- ç®€åŒ– U-Net å™ªå£°é¢„æµ‹
- DDIM åŠ é€Ÿé‡‡æ ·
- Classifier-Free Guidance (CFG)

---

## ä¸‰ã€å¾…è¡¥å……å†…å®¹

### Phase 3: å¡«è¡¥ç©ºç™½æ¨¡å—

#### 3.1 è¡¥å…… `06-generative-models` å‰©ä½™å†…å®¹

```
06-generative-models/
â”œâ”€â”€ 01-vae/
â”‚   â”œâ”€â”€ README.md                    # âœ… å·²å®Œæˆ (æ¨¡å—çŸ¥è¯†ç‚¹)
â”‚   â”œâ”€â”€ vanilla_ae.ipynb             # âœ… å·²å®Œæˆ (ä¿¡æ¯ç“¶é¢ˆã€PCAå…³ç³»)
â”‚   â”œâ”€â”€ variational_ae.ipynb         # âœ… å·²å®Œæˆ (ELBOæ¨å¯¼)
â”‚   â””â”€â”€ vq_vae.ipynb                 # âœ… å·²å®Œæˆ (ç¦»æ•£ç æœ¬ã€ç›´é€šä¼°è®¡å™¨)
â”œâ”€â”€ 02-gans/
â”‚   â”œâ”€â”€ README.md                    # âœ… å·²æœ‰
â”‚   â”œâ”€â”€ gan_basics.ipynb             # âœ… å·²å®Œæˆ (Nashå‡è¡¡ã€Minimax)
â”‚   â”œâ”€â”€ dcgan.ipynb                  # âœ… å·²å®Œæˆ (è½¬ç½®å·ç§¯ã€æ¶æ„è®¾è®¡)
â”‚   â”œâ”€â”€ wgan_gp.ipynb                # âœ… å·²å®Œæˆ (Wassersteinè·ç¦»ã€GP)
â”‚   â””â”€â”€ GANç½‘ç»œå®ç°.ipynb            # âœ… å·²æœ‰
â”œâ”€â”€ 03-diffusion-models/
â”‚   â”œâ”€â”€ ddpm_basics.ipynb            # âœ… å·²å®Œæˆ
â”‚   â”œâ”€â”€ ddpm_implementation.ipynb    # âœ… å·²å®Œæˆ
â”‚   â””â”€â”€ stable_diffusion_intro.ipynb # Stable Diffusionå…¥é—¨
â”œâ”€â”€ 04-text-generation/
â”‚   â””â”€â”€ char_rnn.ipynb               # å­—ç¬¦çº§RNNæ–‡æœ¬ç”Ÿæˆ
â”œâ”€â”€ 05-deepdream/
â”‚   â””â”€â”€ deepdream.ipynb              # DeepDreamé£æ ¼è¿ç§»
â””â”€â”€ 06-neural-style-transfer/
    â””â”€â”€ neural_style_transfer.ipynb  # ç¥ç»é£æ ¼è¿ç§»
```

#### 3.2 è¡¥å…… `05-advanced-topics/03-model-optimization` âœ… å·²å®Œæˆ (2026-01-02)

```
05-advanced-topics/03-model-optimization/
â”œâ”€â”€ 01-quantization/
â”‚   â”œâ”€â”€ README.md                           # âœ… å·²å®Œæˆ
â”‚   â””â”€â”€ notebooks/
â”‚       â”œâ”€â”€ quantization_fundamentals.ipynb # âœ… å·²å®Œæˆ (SOTAæ ‡å‡†)
â”‚       â”œâ”€â”€ post_training_quantization.ipynb # âœ… å·²å®Œæˆ
â”‚       â””â”€â”€ quantization_aware_training.ipynb # âœ… å·²å®Œæˆ
â”œâ”€â”€ 02-pruning/
â”‚   â”œâ”€â”€ README.md                           # âœ… å·²å®Œæˆ
â”‚   â””â”€â”€ notebooks/
â”‚       â”œâ”€â”€ pruning_fundamentals.ipynb      # âœ… å·²å®Œæˆ
â”‚       â”œâ”€â”€ structured_pruning.ipynb        # âœ… å·²å®Œæˆ
â”‚       â””â”€â”€ lottery_ticket_hypothesis.ipynb # âœ… å·²å®Œæˆ
â”œâ”€â”€ 03-knowledge-distillation/
â”‚   â”œâ”€â”€ README.md                           # âœ… å·²å®Œæˆ
â”‚   â””â”€â”€ notebooks/
â”‚       â”œâ”€â”€ distillation_basics.ipynb       # âœ… å·²å®Œæˆ
â”‚       â”œâ”€â”€ feature_distillation.ipynb      # âœ… å·²å®Œæˆ
â”‚       â””â”€â”€ self_distillation.ipynb         # âœ… å·²å®Œæˆ
â””â”€â”€ 04-deployment/
    â”œâ”€â”€ README.md                           # âœ… å·²å®Œæˆ
    â””â”€â”€ notebooks/
        â”œâ”€â”€ onnx_export.ipynb               # âœ… å·²å®Œæˆ
        â”œâ”€â”€ tensorrt_optimization.ipynb     # âœ… å·²å®Œæˆ
        â””â”€â”€ torchscript_deployment.ipynb    # âœ… å·²å®Œæˆ
```

---

## å››ã€å®æ–½æ—¶é—´è¡¨ (æ›´æ–°äº 2026-01-02)

| é˜¶æ®µ | å†…å®¹ | æ—¶é—´ | çŠ¶æ€ |
|:----:|:-----|:----:|:------:|
| Week 1-2 | è¡¥å……04-sequence-models/05-transformer | 2å‘¨ | âœ… å·²å®Œæˆ |
| Week 2-3 | è¡¥å……06-generative-models (VAE/GAN/Diffusion) | 2å‘¨ | âœ… å·²å®Œæˆ |
| Week 3-4 | è¡¥å……05-advanced-topics/03-model-optimization | 1å‘¨ | âœ… å·²å®Œæˆ |
| Week 4-6 | æ–°å¢10-large-language-models (01-03å­æ¨¡å—) | 2å‘¨ | âœ… å·²å®Œæˆ |
| Week 6-8 | æ–°å¢10-large-language-models (04-07å­æ¨¡å—) | 2å‘¨ | ğŸ”² å¾…å¼€å‘ |
| Week 8-10 | æ–°å¢11-multimodal-learningæ¨¡å— | 2å‘¨ | ğŸ”² å¾…å¼€å‘ |
| Week 10+ | å·¥ç¨‹åŒ–: Docker + æµ‹è¯•è¦†ç›– | æŒç»­ | ğŸ”² å¾…å¼€å‘ |

### ä¸‹æ¬¡å¼€å‘é‡ç‚¹ (10-large-language-models)

1. **04-prompt-engineering**: æç¤ºå·¥ç¨‹åŸºç¡€ã€Few-shotã€CoT
2. **05-rag**: å‘é‡æ•°æ®åº“ã€RAGæµæ°´çº¿
3. **06-agents**: LangChainã€å·¥å…·è°ƒç”¨
4. **07-alignment**: RLHFã€DPO

```
10-large-language-models/
â”œâ”€â”€ README.md                        # âœ… å·²å®Œæˆ
â”œâ”€â”€ 01-llm-fundamentals/
â”‚   â”œâ”€â”€ README.md                    # âœ… å·²å®Œæˆ
â”‚   â”œâ”€â”€ knowledge_points.md          # âœ… å·²å®Œæˆ (606è¡Œï¼ŒTransformerè¯¦è§£)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ transformer_architecture_v2.py  # âœ… å·²å®Œæˆ
â”‚   â””â”€â”€ notebooks/
â”‚       â”œâ”€â”€ transformer_architecture.ipynb  # âœ… å·²å®Œæˆ
â”‚       â””â”€â”€ tokenizer_architecture.ipynb    # âœ… å·²å®Œæˆ
â”‚
â”œâ”€â”€ 02-pretrained-models/
â”‚   â”œâ”€â”€ README.md                    # âœ… å·²å®Œæˆ
â”‚   â”œâ”€â”€ knowledge_points.md          # âœ… å·²å®Œæˆ (GPT/BERT/LLaMA/ç¼©æ”¾å®šå¾‹)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ __init__.py              # âœ… å·²å®Œæˆ
â”‚   â”‚   â”œâ”€â”€ gpt_model.py             # âœ… å·²å®Œæˆ (362è¡Œï¼Œå®Œæ•´GPTå®ç°)
â”‚   â”‚   â””â”€â”€ llama_model.py           # âœ… å·²å®Œæˆ (389è¡Œï¼ŒRMSNorm/RoPE/SwiGLU/GQA)
â”‚   â””â”€â”€ notebooks/
â”‚       â”œâ”€â”€ gpt_architecture.ipynb   # âœ… å·²å®Œæˆ (SOTAæ ‡å‡†)
â”‚       â””â”€â”€ llama_architecture.ipynb # âœ… å·²å®Œæˆ (SOTAæ ‡å‡†)
â”‚
â”œâ”€â”€ 03-fine-tuning/
â”‚   â”œâ”€â”€ README.md                    # âœ… å·²å®Œæˆ
â”‚   â”œâ”€â”€ knowledge_points.md          # âœ… å·²å®Œæˆ (LoRA/QLoRA/PEFT)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ __init__.py              # âœ… å·²å®Œæˆ
â”‚   â”‚   â”œâ”€â”€ lora.py                  # âœ… å·²å®Œæˆ (285è¡Œï¼Œå®Œæ•´LoRAå®ç°)
â”‚   â”‚   â””â”€â”€ trainer.py               # âœ… å·²å®Œæˆ (304è¡Œï¼Œå¾®è°ƒè®­ç»ƒå™¨)
â”‚   â””â”€â”€ notebooks/
â”‚       â””â”€â”€ lora_finetuning.ipynb    # âœ… å·²å®Œæˆ (SOTAæ ‡å‡†)
â”‚
â”œâ”€â”€ 04-prompt-engineering/           # ğŸ”² å¾…å¼€å‘
â”‚   â”œâ”€â”€ prompt_basics.ipynb
â”‚   â”œâ”€â”€ few_shot_learning.ipynb
â”‚   â”œâ”€â”€ chain_of_thought.ipynb
â”‚   â””â”€â”€ prompt_optimization.ipynb
â”‚
â”œâ”€â”€ 05-rag/                          # ğŸ”² å¾…å¼€å‘
â”‚   â”œâ”€â”€ vector_databases.ipynb
â”‚   â”œâ”€â”€ embedding_models.ipynb
â”‚   â”œâ”€â”€ rag_pipeline.ipynb
â”‚   â””â”€â”€ advanced_rag.ipynb
â”‚
â”œâ”€â”€ 06-agents/                       # ğŸ”² å¾…å¼€å‘
â”‚   â”œâ”€â”€ langchain_basics.ipynb
â”‚   â”œâ”€â”€ llamaindex_basics.ipynb
â”‚   â”œâ”€â”€ tool_use.ipynb
â”‚   â””â”€â”€ multi_agent.ipynb
â”‚
â””â”€â”€ 07-alignment/                    # ğŸ”² å¾…å¼€å‘
    â”œâ”€â”€ rlhf_basics.ipynb
    â”œâ”€â”€ dpo_training.ipynb
    â””â”€â”€ constitutional_ai.ipynb
```

**LLMæ¨¡å—å·²å®Œæˆç»Ÿè®¡ (2026-01-02)**:
- Pythonæºç : 1,340+ è¡Œ
- çŸ¥è¯†ç‚¹æ–‡æ¡£: 1,229 è¡Œ
- Notebook: 5ä¸ª (SOTAæ ‡å‡†)
- å®Œæˆåº¦: 01-03å­æ¨¡å— 100%ï¼Œæ€»ä½“çº¦ 40%

---

### Phase 3: å¤šæ¨¡æ€å­¦ä¹  (4-6å‘¨)

```
11-multimodal-learning/
â”œâ”€â”€ README.md
â”œâ”€â”€ 01-vision-language/
â”‚   â”œâ”€â”€ clip_basics.ipynb
â”‚   â”œâ”€â”€ blip_image_captioning.ipynb
â”‚   â””â”€â”€ llava_multimodal.ipynb
â”‚
â”œâ”€â”€ 02-image-generation/
â”‚   â”œâ”€â”€ stable_diffusion_pipeline.ipynb
â”‚   â”œâ”€â”€ controlnet.ipynb
â”‚   â””â”€â”€ image_editing.ipynb
â”‚
â””â”€â”€ 03-audio-models/
    â”œâ”€â”€ whisper_transcription.ipynb
    â””â”€â”€ tts_basics.ipynb
```

---

## ä¸‰ã€å·¥ç¨‹åŒ–æå‡æ–¹æ¡ˆ

### 3.1 ä»£ç è´¨é‡å·¥å…·é“¾

**pyproject.toml é…ç½®**:

```toml
[tool.black]
line-length = 100
target-version = ['py310']
include = '\.pyi?$'
exclude = '''
/(
    \.git
    | \.venv
    | node_modules
    | __pycache__
)/
'''

[tool.isort]
profile = "black"
line_length = 100
skip = [".git", "node_modules", "__pycache__"]

[tool.ruff]
line-length = 100
select = ["E", "F", "W", "I", "N", "D", "UP", "B", "C4"]
ignore = ["D100", "D104"]
exclude = ["node_modules", ".git", "__pycache__"]

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_ignores = true
ignore_missing_imports = true
```

**pre-commit é…ç½®**:

```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=5000']
      - id: detect-private-key

  - repo: https://github.com/psf/black
    rev: 23.12.1
    hooks:
      - id: black

  - repo: https://github.com/pycqa/isort
    rev: 5.13.2
    hooks:
      - id: isort

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.9
    hooks:
      - id: ruff
        args: [--fix]

  - repo: https://github.com/nbQA-dev/nbQA
    rev: 1.7.1
    hooks:
      - id: nbqa-black
      - id: nbqa-isort
```

### 3.2 æµ‹è¯•æ¡†æ¶å®Œå–„

**pytest.ini é…ç½®**:

```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = -v --tb=short --strict-markers
markers =
    slow: marks tests as slow
    gpu: marks tests requiring GPU
```

**æµ‹è¯•ç›®å½•ç»“æ„**:

```
tests/
â”œâ”€â”€ conftest.py
â”œâ”€â”€ test_foundations/
â”‚   â”œâ”€â”€ test_linear_models.py
â”‚   â””â”€â”€ test_ensemble.py
â”œâ”€â”€ test_neural_networks/
â”‚   â””â”€â”€ test_keras_models.py
â”œâ”€â”€ test_computer_vision/
â”‚   â””â”€â”€ test_cnn.py
â”œâ”€â”€ test_sequence_models/
â”‚   â””â”€â”€ test_rnn.py
â””â”€â”€ test_utils/
    â””â”€â”€ test_common.py
```

### 3.3 CI/CD å¢å¼º

**test.yml å·¥ä½œæµ**:

```yaml
name: Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11']

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov nbval

      - name: Run unit tests
        run: pytest tests/ -v --cov=utils --cov-report=xml

      - name: Validate notebooks (smoke test)
        run: |
          pytest --nbval-lax \
            01-foundations/01-training-models/01-LinearRegression.ipynb \
            --ignore=node_modules

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
```

### 3.4 Docker æ”¯æŒ

**Dockerfile**:

```dockerfile
FROM python:3.10-slim

WORKDIR /app

RUN apt-get update && apt-get install -y \
    git \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
RUN pip install jupyterlab

EXPOSE 8888

CMD ["jupyter", "lab", "--ip=0.0.0.0", "--port=8888", "--no-browser", "--allow-root"]
```

**docker-compose.yml**:

```yaml
version: '3.8'

services:
  jupyter:
    build: .
    ports:
      - "8888:8888"
    volumes:
      - .:/app
    environment:
      - JUPYTER_TOKEN=ai-practices

  jupyter-gpu:
    build: .
    runtime: nvidia
    ports:
      - "8889:8888"
    volumes:
      - .:/app
    environment:
      - JUPYTER_TOKEN=ai-practices
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

## å››ã€ç”¨æˆ·ä½“éªŒä¼˜åŒ–æ–¹æ¡ˆ

### 4.1 å­¦ä¹ è·¯å¾„å¯è§†åŒ–

```mermaid
graph LR
    A[01-åŸºç¡€] --> B[02-ç¥ç»ç½‘ç»œ]
    B --> C[03-CVå…¥é—¨]
    B --> D[04-åºåˆ—æ¨¡å‹]
    C --> E[09-å®æˆ˜é¡¹ç›®]
    D --> E
    E --> F[05-é«˜çº§ä¸»é¢˜]
    F --> G[06-ç”Ÿæˆæ¨¡å‹]
    F --> H[07-å¼ºåŒ–å­¦ä¹ ]
    G --> I[10-LLM]
    H --> I
    I --> J[11-å¤šæ¨¡æ€]
```

### 4.2 éš¾åº¦æ ‡ç­¾ç³»ç»Ÿ

ä¸ºæ¯ä¸ªnotebookæ·»åŠ å…ƒæ•°æ®:

```python
"""
---
title: çº¿æ€§å›å½’
difficulty: beginner  # beginner/intermediate/advanced
estimated_time: 30min
prerequisites: [numpy, matplotlib]
colab_link: https://colab.research.google.com/...
---
"""
```

### 4.3 ä¸€é”®è¿è¡ŒæŒ‰é’®

å„æ¨¡å—READMEæ·»åŠ Colab/BinderæŒ‰é’®:

```markdown
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zimingttkx/AI-Practices/blob/main/...)

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/zimingttkx/AI-Practices/main)
```

---

## äº”ã€æ–°å¢ä¾èµ–

```txt
# LLMç›¸å…³
transformers>=4.36.0
peft>=0.7.0
bitsandbytes>=0.41.0
accelerate>=0.25.0
datasets>=2.15.0
sentencepiece>=0.1.99
tiktoken>=0.5.0
einops>=0.7.0

# RAGç›¸å…³
langchain>=0.1.0
langchain-community>=0.0.10
llama-index>=0.9.0
chromadb>=0.4.0
faiss-cpu>=1.7.4

# å‘é‡åµŒå…¥
sentence-transformers>=2.2.0

# Diffusion
diffusers>=0.25.0

# å¤šæ¨¡æ€
open-clip-torch>=2.24.0

# å¼€å‘å·¥å…·
pytest>=7.4.0
pytest-cov>=4.1.0
nbval>=0.10.0
black>=23.12.0
isort>=5.13.0
ruff>=0.1.9
pre-commit>=3.6.0
nbqa>=1.7.0
```

---

## å…­ã€æ–‡ä»¶å˜æ›´æ¸…å•

### æ–°å¢æ–‡ä»¶

```
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ LEARNING_CHECKLIST.md
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ 04-sequence-models/05-transformer/
â”œâ”€â”€ 06-generative-models/01-autoencoders/
â”œâ”€â”€ 06-generative-models/03-diffusion-models/
â”œâ”€â”€ 05-advanced-topics/03-model-optimization/01-quantization/
â”œâ”€â”€ 10-large-language-models/
â””â”€â”€ 11-multimodal-learning/
```

### ä¿®æ”¹æ–‡ä»¶

```
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ .github/workflows/
â””â”€â”€ docs/
```
