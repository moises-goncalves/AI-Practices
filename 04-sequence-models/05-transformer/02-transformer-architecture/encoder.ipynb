{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Encoder 深度实现\n",
    "\n",
    "**SOTA 教育标准** | 包含 Pre-LN/Post-LN 切换、GELU 激活、形状追踪\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 理论基础\n",
    "\n",
    "### 1.1 Pre-LN vs Post-LN 架构对比\n",
    "\n",
    "**Post-LN (原始 Transformer, BERT-style)**:\n",
    "$$x = \\text{LayerNorm}(x + \\text{Sublayer}(x))$$\n",
    "\n",
    "**Pre-LN (GPT-style, 更稳定)**:\n",
    "$$x = x + \\text{Sublayer}(\\text{LayerNorm}(x))$$\n",
    "\n",
    "### 1.2 梯度流分析 ⭐\n",
    "\n",
    "**Post-LN 的问题**:\n",
    "- 梯度需要穿过 LayerNorm 才能到达残差路径\n",
    "- 深层网络中梯度可能不稳定\n",
    "- 需要 Learning Rate Warmup 来稳定训练\n",
    "\n",
    "**Pre-LN 的优势**:\n",
    "- 残差路径上梯度直接流动，不经过 LayerNorm\n",
    "- 梯度流更稳定，可以训练更深的网络\n",
    "- 通常不需要 Warmup\n",
    "\n",
    "**直觉**: Pre-LN 让残差连接成为\"梯度高速公路\"，信息可以无阻碍地反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 GELU 激活函数\n",
    "\n",
    "**公式**:\n",
    "$$\\text{GELU}(x) = x \\cdot \\Phi(x) = x \\cdot \\frac{1}{2}\\left[1 + \\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right]$$\n",
    "\n",
    "**近似公式** (更快):\n",
    "$$\\text{GELU}(x) \\approx 0.5x\\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}}(x + 0.044715x^3)\\right]\\right)$$\n",
    "\n",
    "**相比 ReLU 的优势**:\n",
    "1. **平滑性**: GELU 处处可微，ReLU 在 0 点不可微\n",
    "2. **概率解释**: GELU 可解释为\"以概率 $\\Phi(x)$ 保留输入\"\n",
    "3. **负值处理**: GELU 允许小的负值通过，ReLU 完全截断\n",
    "4. **实践效果**: GPT、BERT 等模型均采用 GELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EncoderConfig:\n",
    "    \"\"\"Encoder 配置类，避免魔术数字。\"\"\"\n",
    "\n",
    "    vocab_size: int = 10000\n",
    "    d_model: int = 512\n",
    "    n_layers: int = 6\n",
    "    n_heads: int = 8\n",
    "    d_ff: int = 2048\n",
    "    max_len: int = 5000\n",
    "    dropout: float = 0.1\n",
    "    pad_idx: int = 0\n",
    "    norm_first: bool = True  # True=Pre-LN (GPT), False=Post-LN (BERT)\n",
    "    activation: str = \"gelu\"  # \"gelu\" or \"relu\"\n",
    "    mask_value: float = -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    \"\"\"Gaussian Error Linear Unit 激活函数。\n",
    "\n",
    "    核心思想: 以输入值的累积分布函数为概率，随机\"门控\"输入。\n",
    "\n",
    "    数学原理:\n",
    "        GELU(x) = x * Phi(x)\n",
    "        其中 Phi(x) 是标准正态分布的 CDF。\n",
    "\n",
    "    相比 ReLU:\n",
    "        - 平滑可微，梯度更稳定\n",
    "        - 允许小负值通过，信息保留更完整\n",
    "        - GPT/BERT 等 SOTA 模型的标准选择\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, approximate: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.approximate = approximate\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.approximate:\n",
    "            # 快速近似: 0.5 * x * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))\n",
    "            return F.gelu(x, approximate=\"tanh\")\n",
    "        else:\n",
    "            # 精确计算: x * Phi(x)\n",
    "            return F.gelu(x, approximate=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力机制。\"\"\"\n",
    "\n",
    "    def __init__(self, config: EncoderConfig) -> None:\n",
    "        super().__init__()\n",
    "        assert config.d_model % config.n_heads == 0\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_heads = config.n_heads\n",
    "        self.d_k = config.d_model // config.n_heads\n",
    "        self.scale = 1.0 / math.sqrt(self.d_k)\n",
    "        self.mask_value = config.mask_value\n",
    "\n",
    "        self.W_q = nn.Linear(config.d_model, config.d_model)\n",
    "        self.W_k = nn.Linear(config.d_model, config.d_model)\n",
    "        self.W_v = nn.Linear(config.d_model, config.d_model)\n",
    "        self.W_o = nn.Linear(config.d_model, config.d_model)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        query: Tensor,\n",
    "        key: Tensor,\n",
    "        value: Tensor,\n",
    "        mask: Optional[Tensor] = None,\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        batch_size, seq_len, _ = query.shape\n",
    "\n",
    "        # 线性投影并分头: (batch, seq, d_model) -> (batch, n_heads, seq, d_k)\n",
    "        q = self.W_q(query).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.W_k(key).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.W_v(value).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # 注意力分数: einsum 'b h i d, b h j d -> b h i j'\n",
    "        scores = torch.einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask.bool(), self.mask_value)\n",
    "\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # 加权求和: einsum 'b h i j, b h j d -> b h i d'\n",
    "        context = torch.einsum(\"b h i j, b h j d -> b h i d\", attn_weights, v)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "\n",
    "        output = self.W_o(context)\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\"位置前馈网络，支持 GELU/ReLU 切换。\"\"\"\n",
    "\n",
    "    def __init__(self, config: EncoderConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(config.d_model, config.d_ff)\n",
    "        self.linear2 = nn.Linear(config.d_ff, config.d_model)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        # 激活函数选择\n",
    "        if config.activation == \"gelu\":\n",
    "            self.activation = GELU(approximate=True)\n",
    "        else:\n",
    "            self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # FFN(x) = W2 * activation(W1 * x + b1) + b2\n",
    "        return self.linear2(self.dropout(self.activation(self.linear1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"正弦位置编码。\"\"\"\n",
    "\n",
    "    def __init__(self, config: EncoderConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        pe = torch.zeros(config.max_len, config.d_model)\n",
    "        position = torch.arange(0, config.max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, config.d_model, 2).float() * (-math.log(10000.0) / config.d_model)\n",
    "        )\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Transformer Encoder 单层，支持 Pre-LN/Post-LN 切换。\n",
    "\n",
    "    核心思想:\n",
    "        Pre-LN: 先归一化再计算，残差路径畅通无阻\n",
    "        Post-LN: 先计算再归一化，需要 warmup 稳定训练\n",
    "\n",
    "    Args:\n",
    "        config: EncoderConfig，包含 norm_first 开关\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: EncoderConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.norm_first = config.norm_first\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(config)\n",
    "        self.ffn = PositionwiseFeedForward(config)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(config.d_model)\n",
    "        self.norm2 = nn.LayerNorm(config.d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(config.dropout)\n",
    "        self.dropout2 = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x: Tensor, mask: Optional[Tensor] = None) -> Tensor:\n",
    "        if self.norm_first:\n",
    "            # Pre-LN (GPT-style): x = x + Sublayer(LayerNorm(x))\n",
    "            attn_out, _ = self.self_attn(self.norm1(x), self.norm1(x), self.norm1(x), mask)\n",
    "            x = x + self.dropout1(attn_out)\n",
    "            x = x + self.dropout2(self.ffn(self.norm2(x)))\n",
    "        else:\n",
    "            # Post-LN (BERT-style): x = LayerNorm(x + Sublayer(x))\n",
    "            attn_out, _ = self.self_attn(x, x, x, mask)\n",
    "            x = self.norm1(x + self.dropout1(attn_out))\n",
    "            x = self.norm2(x + self.dropout2(self.ffn(x)))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"完整 Transformer Encoder。\"\"\"\n",
    "\n",
    "    def __init__(self, config: EncoderConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.scale = math.sqrt(config.d_model)\n",
    "\n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.d_model, padding_idx=config.pad_idx)\n",
    "        self.pos_encoding = PositionalEncoding(config)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.n_layers)])\n",
    "\n",
    "        # Pre-LN 需要最后一层 LayerNorm\n",
    "        self.final_norm = nn.LayerNorm(config.d_model) if config.norm_first else nn.Identity()\n",
    "\n",
    "    def create_padding_mask(self, src: Tensor) -> Tensor:\n",
    "        return (src == self.config.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    def forward(self, src: Tensor, mask: Optional[Tensor] = None) -> Tensor:\n",
    "        if mask is None:\n",
    "            mask = self.create_padding_mask(src)\n",
    "\n",
    "        x = self.embedding(src) * self.scale\n",
    "        x = self.pos_encoding(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return self.final_norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 形状追踪器 (TraceableModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeTracer:\n",
    "    \"\"\"张量形状追踪器，用于调试和理解数据流。\n",
    "\n",
    "    使用 PyTorch Hook 机制，在前向传播时记录每层的输入输出形状。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.traces: List[Dict] = []\n",
    "        self.hooks: List = []\n",
    "\n",
    "    def _hook_fn(self, name: str) -> Callable:\n",
    "        def hook(module: nn.Module, input: Tuple, output) -> None:\n",
    "            input_shape = input[0].shape if isinstance(input, tuple) and len(input) > 0 else \"N/A\"\n",
    "            output_shape = output.shape if isinstance(output, Tensor) else output[0].shape\n",
    "            self.traces.append(\n",
    "                {\n",
    "                    \"layer\": name,\n",
    "                    \"type\": module.__class__.__name__,\n",
    "                    \"input\": str(input_shape),\n",
    "                    \"output\": str(output_shape),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return hook\n",
    "\n",
    "    def attach(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        target_types: Tuple = (MultiHeadAttention, PositionwiseFeedForward, nn.LayerNorm),\n",
    "    ) -> None:\n",
    "        \"\"\"附加 Hook 到指定类型的模块。\"\"\"\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, target_types):\n",
    "                hook = module.register_forward_hook(self._hook_fn(name))\n",
    "                self.hooks.append(hook)\n",
    "\n",
    "    def detach(self) -> None:\n",
    "        \"\"\"移除所有 Hook。\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks.clear()\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"清空追踪记录。\"\"\"\n",
    "        self.traces.clear()\n",
    "\n",
    "    def print_traces(self) -> None:\n",
    "        \"\"\"打印形状追踪结果。\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"张量形状追踪 (Shape Trace)\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"{'Layer':<40} {'Type':<25} {'Input':<20} {'Output':<20}\")\n",
    "        print(\"-\" * 80)\n",
    "        for t in self.traces:\n",
    "            print(f\"{t['layer']:<40} {t['type']:<25} {t['input']:<20} {t['output']:<20}\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 测试与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_pass() -> None:\n",
    "    \"\"\"验证前向传播形状正确性。\"\"\"\n",
    "    config = EncoderConfig(d_model=256, n_layers=2, n_heads=4, d_ff=512)\n",
    "    encoder = Encoder(config)\n",
    "\n",
    "    batch_size, seq_len = 2, 10\n",
    "    src = torch.randint(1, config.vocab_size, (batch_size, seq_len))\n",
    "\n",
    "    output = encoder(src)\n",
    "\n",
    "    assert output.shape == (batch_size, seq_len, config.d_model)\n",
    "    print(\"[PASS] test_forward_pass\")\n",
    "\n",
    "\n",
    "test_forward_pass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pre_ln_vs_post_ln() -> None:\n",
    "    \"\"\"对比 Pre-LN 和 Post-LN 的输出差异。\"\"\"\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    config_pre = EncoderConfig(d_model=128, n_layers=2, n_heads=4, norm_first=True)\n",
    "    config_post = EncoderConfig(d_model=128, n_layers=2, n_heads=4, norm_first=False)\n",
    "\n",
    "    encoder_pre = Encoder(config_pre)\n",
    "    encoder_post = Encoder(config_post)\n",
    "\n",
    "    src = torch.randint(1, 1000, (1, 5))\n",
    "\n",
    "    out_pre = encoder_pre(src)\n",
    "    out_post = encoder_post(src)\n",
    "\n",
    "    print(f\"Pre-LN 输出范数: {out_pre.norm():.4f}\")\n",
    "    print(f\"Post-LN 输出范数: {out_post.norm():.4f}\")\n",
    "    print(\"[PASS] test_pre_ln_vs_post_ln\")\n",
    "\n",
    "\n",
    "test_pre_ln_vs_post_ln()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_shape_tracing() -> None:\n",
    "    \"\"\"演示形状追踪功能。\"\"\"\n",
    "    config = EncoderConfig(d_model=256, n_layers=2, n_heads=4, d_ff=512)\n",
    "    encoder = Encoder(config)\n",
    "\n",
    "    tracer = ShapeTracer()\n",
    "    tracer.attach(encoder)\n",
    "\n",
    "    src = torch.randint(1, 1000, (2, 8))\n",
    "    _ = encoder(src)\n",
    "\n",
    "    tracer.print_traces()\n",
    "    tracer.detach()\n",
    "\n",
    "\n",
    "demo_shape_tracing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. GELU vs ReLU 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = torch.linspace(-4, 4, 200)\n",
    "\n",
    "gelu_out = F.gelu(x)\n",
    "relu_out = F.relu(x)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x.numpy(), gelu_out.numpy(), label=\"GELU\", linewidth=2)\n",
    "plt.plot(x.numpy(), relu_out.numpy(), label=\"ReLU\", linewidth=2, linestyle=\"--\")\n",
    "plt.axhline(y=0, color=\"gray\", linestyle=\"-\", alpha=0.3)\n",
    "plt.axvline(x=0, color=\"gray\", linestyle=\"-\", alpha=0.3)\n",
    "plt.xlabel(\"Input x\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.title(\"GELU vs ReLU 激活函数对比\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"观察: GELU 在负值区域平滑过渡，ReLU 硬截断为 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. RoPE: 旋转位置编码 ⭐⭐\n",
    "\n",
    "### 6.1 核心思想\n",
    "\n",
    "**问题**: 正弦位置编码是加性的，无法直接编码相对位置。\n",
    "\n",
    "**RoPE 解决方案**: 通过旋转矩阵将位置信息编码到注意力计算中。\n",
    "\n",
    "$$f_q(x_m, m) = (W_q x_m) e^{im\\theta}$$\n",
    "$$f_k(x_n, n) = (W_k x_n) e^{in\\theta}$$\n",
    "\n",
    "**关键性质**: $\\langle f_q(x_m, m), f_k(x_n, n) \\rangle$ 只依赖于相对位置 $m - n$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    \"\"\"旋转位置编码 (RoPE) - LLaMA/GPT-NeoX 标准。\n",
    "\n",
    "    核心思想:\n",
    "        将位置信息编码为旋转角度，使得注意力分数自然包含相对位置信息。\n",
    "\n",
    "    数学原理:\n",
    "        对于位置 m 的向量 x，应用旋转:\n",
    "        RoPE(x, m) = x * cos(m*theta) + rotate_half(x) * sin(m*theta)\n",
    "\n",
    "    优势:\n",
    "        1. 相对位置编码，外推性更好\n",
    "        2. 无需额外参数\n",
    "        3. 与注意力计算自然融合\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int, max_seq_len: int = 4096, base: float = 10000.0) -> None:\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.base = base\n",
    "\n",
    "        # 预计算频率: theta_i = base^(-2i/d)\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "        # 预计算 cos/sin 缓存\n",
    "        self._build_cache(max_seq_len)\n",
    "\n",
    "    def _build_cache(self, seq_len: int) -> None:\n",
    "        \"\"\"预计算 cos/sin 值。\"\"\"\n",
    "        t = torch.arange(seq_len, device=self.inv_freq.device)\n",
    "        freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)  # (seq_len, dim/2)\n",
    "        emb = torch.cat([freqs, freqs], dim=-1)  # (seq_len, dim)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos())\n",
    "        self.register_buffer(\"sin_cached\", emb.sin())\n",
    "\n",
    "    def _rotate_half(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"将向量的前半部分和后半部分交换并取负。\"\"\"\n",
    "        x1, x2 = x[..., : x.shape[-1] // 2], x[..., x.shape[-1] // 2 :]\n",
    "        return torch.cat([-x2, x1], dim=-1)\n",
    "\n",
    "    def forward(self, q: Tensor, k: Tensor, seq_len: int) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"应用 RoPE 到 Q 和 K。\n",
    "\n",
    "        Args:\n",
    "            q: Query (batch, n_heads, seq_len, head_dim)\n",
    "            k: Key (batch, n_heads, seq_len, head_dim)\n",
    "            seq_len: 序列长度\n",
    "\n",
    "        Returns:\n",
    "            q_rotated, k_rotated: 应用 RoPE 后的 Q, K\n",
    "        \"\"\"\n",
    "        cos = self.cos_cached[:seq_len].unsqueeze(0).unsqueeze(0)  # (1, 1, seq, dim)\n",
    "        sin = self.sin_cached[:seq_len].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # RoPE: x * cos + rotate_half(x) * sin\n",
    "        q_rotated = q * cos + self._rotate_half(q) * sin\n",
    "        k_rotated = k * cos + self._rotate_half(k) * sin\n",
    "\n",
    "        return q_rotated, k_rotated\n",
    "\n",
    "\n",
    "# 测试 RoPE\n",
    "def test_rope() -> None:\n",
    "    rope = RotaryPositionalEmbedding(dim=64, max_seq_len=512)\n",
    "    q = torch.randn(2, 8, 32, 64)  # (batch, heads, seq, dim)\n",
    "    k = torch.randn(2, 8, 32, 64)\n",
    "\n",
    "    q_rot, k_rot = rope(q, k, seq_len=32)\n",
    "    print(f\"Q 形状: {q.shape} -> {q_rot.shape}\")\n",
    "    print(f\"K 形状: {k.shape} -> {k_rot.shape}\")\n",
    "    print(\"[PASS] RoPE 测试通过\")\n",
    "\n",
    "\n",
    "test_rope()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ALiBi: 线性偏置注意力 ⭐⭐\n",
    "\n",
    "### 7.1 核心思想\n",
    "\n",
    "**ALiBi (Attention with Linear Biases)**: 直接在注意力分数上添加线性位置偏置。\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}} + m \\cdot [-(i-j)]\\right)V$$\n",
    "\n",
    "其中 $m$ 是每个头的斜率，$i, j$ 是位置索引。\n",
    "\n",
    "**优势**:\n",
    "1. **零额外参数**: 只需预计算偏置矩阵\n",
    "2. **外推性极强**: 训练 1024 长度，可推理 8192+\n",
    "3. **实现简单**: 只需在注意力分数上加偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALiBi(nn.Module):\n",
    "    \"\"\"ALiBi: Attention with Linear Biases。\n",
    "\n",
    "    核心思想:\n",
    "        在注意力分数上添加线性位置偏置，无需学习位置嵌入。\n",
    "\n",
    "    数学原理:\n",
    "        bias[i,j] = -m * |i - j|\n",
    "        其中 m 是每个头的斜率，按几何级数递减。\n",
    "\n",
    "    优势:\n",
    "        1. 零额外参数\n",
    "        2. 外推性极强 (训练 1K，推理 8K+)\n",
    "        3. 实现简单\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_heads: int, max_seq_len: int = 4096) -> None:\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # 计算每个头的斜率: 2^(-8/n), 2^(-16/n), ...\n",
    "        slopes = self._get_slopes(n_heads)\n",
    "        self.register_buffer(\"slopes\", slopes)\n",
    "\n",
    "        # 预计算偏置矩阵\n",
    "        bias = self._build_alibi_bias(max_seq_len, slopes)\n",
    "        self.register_buffer(\"bias\", bias)\n",
    "\n",
    "    def _get_slopes(self, n_heads: int) -> Tensor:\n",
    "        \"\"\"计算 ALiBi 斜率 (几何级数)。\"\"\"\n",
    "\n",
    "        def get_slopes_power_of_2(n: int) -> list:\n",
    "            start = 2 ** (-(2 ** -(math.log2(n) - 3)))\n",
    "            ratio = start\n",
    "            return [start * (ratio**i) for i in range(n)]\n",
    "\n",
    "        if math.log2(n_heads).is_integer():\n",
    "            return torch.tensor(get_slopes_power_of_2(n_heads))\n",
    "        else:\n",
    "            closest_power_of_2 = 2 ** math.floor(math.log2(n_heads))\n",
    "            slopes = get_slopes_power_of_2(closest_power_of_2)\n",
    "            extra_slopes = get_slopes_power_of_2(2 * closest_power_of_2)[0::2][\n",
    "                : n_heads - closest_power_of_2\n",
    "            ]\n",
    "            return torch.tensor(slopes + extra_slopes)\n",
    "\n",
    "    def _build_alibi_bias(self, seq_len: int, slopes: Tensor) -> Tensor:\n",
    "        \"\"\"构建 ALiBi 偏置矩阵。\"\"\"\n",
    "        # 相对位置矩阵: [0, -1, -2, ...], [1, 0, -1, ...], ...\n",
    "        positions = torch.arange(seq_len)\n",
    "        relative_positions = positions.unsqueeze(0) - positions.unsqueeze(1)  # (seq, seq)\n",
    "\n",
    "        # 偏置 = -slope * |relative_position|\n",
    "        bias = -slopes.unsqueeze(1).unsqueeze(1) * relative_positions.abs().unsqueeze(0)\n",
    "        return bias  # (n_heads, seq, seq)\n",
    "\n",
    "    def forward(self, attn_scores: Tensor) -> Tensor:\n",
    "        \"\"\"将 ALiBi 偏置添加到注意力分数。\n",
    "\n",
    "        Args:\n",
    "            attn_scores: (batch, n_heads, seq_q, seq_k)\n",
    "\n",
    "        Returns:\n",
    "            带偏置的注意力分数\n",
    "        \"\"\"\n",
    "        seq_len = attn_scores.shape[-1]\n",
    "        return attn_scores + self.bias[:, :seq_len, :seq_len].unsqueeze(0)\n",
    "\n",
    "\n",
    "# 测试 ALiBi\n",
    "def test_alibi() -> None:\n",
    "    alibi = ALiBi(n_heads=8, max_seq_len=512)\n",
    "    scores = torch.randn(2, 8, 32, 32)  # (batch, heads, seq, seq)\n",
    "\n",
    "    scores_with_bias = alibi(scores)\n",
    "    print(f\"注意力分数形状: {scores.shape}\")\n",
    "    print(f\"ALiBi 偏置形状: {alibi.bias.shape}\")\n",
    "    print(f\"斜率: {alibi.slopes[:4].tolist()}\")\n",
    "    print(\"[PASS] ALiBi 测试通过\")\n",
    "\n",
    "\n",
    "test_alibi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. 梯度检查点 (Gradient Checkpointing) ⭐\n",
    "\n",
    "### 8.1 核心思想\n",
    "\n",
    "**问题**: 深层 Transformer 需要存储所有中间激活值用于反向传播，内存消耗巨大。\n",
    "\n",
    "**解决方案**: 只存储部分激活值，反向传播时重新计算其他激活值。\n",
    "\n",
    "**权衡**:\n",
    "- **内存**: 减少 $O(n)$ 到 $O(\\sqrt{n})$\n",
    "- **计算**: 增加约 33% 的计算量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "\n",
    "class CheckpointedEncoderLayer(nn.Module):\n",
    "    \"\"\"支持梯度检查点的 Encoder Layer。\n",
    "\n",
    "    核心思想:\n",
    "        使用 torch.utils.checkpoint 在反向传播时重新计算激活值，\n",
    "        以内存换计算，适合训练超深网络。\n",
    "\n",
    "    内存节省:\n",
    "        - 标准: O(n_layers) 激活值存储\n",
    "        - 检查点: O(sqrt(n_layers)) 激活值存储\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: EncoderConfig, use_checkpoint: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.norm_first = config.norm_first\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(config)\n",
    "        self.ffn = PositionwiseFeedForward(config)\n",
    "        self.norm1 = nn.LayerNorm(config.d_model)\n",
    "        self.norm2 = nn.LayerNorm(config.d_model)\n",
    "        self.dropout1 = nn.Dropout(config.dropout)\n",
    "        self.dropout2 = nn.Dropout(config.dropout)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor, mask: Optional[Tensor] = None) -> Tensor:\n",
    "        \"\"\"实际的前向传播逻辑。\"\"\"\n",
    "        if self.norm_first:\n",
    "            attn_out, _ = self.self_attn(self.norm1(x), self.norm1(x), self.norm1(x), mask)\n",
    "            x = x + self.dropout1(attn_out)\n",
    "            x = x + self.dropout2(self.ffn(self.norm2(x)))\n",
    "        else:\n",
    "            attn_out, _ = self.self_attn(x, x, x, mask)\n",
    "            x = self.norm1(x + self.dropout1(attn_out))\n",
    "            x = self.norm2(x + self.dropout2(self.ffn(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor, mask: Optional[Tensor] = None) -> Tensor:\n",
    "        if self.use_checkpoint and self.training:\n",
    "            # 使用梯度检查点，反向传播时重新计算\n",
    "            return checkpoint(self._forward_impl, x, mask, use_reentrant=False)\n",
    "        else:\n",
    "            return self._forward_impl(x, mask)\n",
    "\n",
    "\n",
    "# 测试梯度检查点\n",
    "def test_gradient_checkpointing() -> None:\n",
    "    config = EncoderConfig(d_model=256, n_heads=4)\n",
    "\n",
    "    layer_standard = EncoderLayer(config)\n",
    "    layer_checkpoint = CheckpointedEncoderLayer(config, use_checkpoint=True)\n",
    "\n",
    "    x = torch.randn(2, 10, 256, requires_grad=True)\n",
    "\n",
    "    # 标准层\n",
    "    layer_standard.train()\n",
    "    out_std = layer_standard(x.clone())\n",
    "\n",
    "    # 检查点层\n",
    "    layer_checkpoint.train()\n",
    "    out_ckpt = layer_checkpoint(x.clone())\n",
    "\n",
    "    print(f\"标准层输出形状: {out_std.shape}\")\n",
    "    print(f\"检查点层输出形状: {out_ckpt.shape}\")\n",
    "    print(\"[PASS] 梯度检查点测试通过\")\n",
    "\n",
    "\n",
    "test_gradient_checkpointing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. 位置编码方法对比\n",
    "\n",
    "| 方法 | 类型 | 外推性 | 参数量 | 适用场景 |\n",
    "|:-----|:-----|:-------|:-------|:---------|\n",
    "| **正弦编码** | 绝对 | 差 | 0 | BERT, 原始 Transformer |\n",
    "| **可学习编码** | 绝对 | 差 | O(L*d) | GPT-2 |\n",
    "| **RoPE** | 相对 | 好 | 0 | LLaMA, GPT-NeoX |\n",
    "| **ALiBi** | 相对 | 极好 | 0 | BLOOM, MPT |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_alibi_bias(n_heads: int = 4, seq_len: int = 16) -> None:\n",
    "    \"\"\"可视化 ALiBi 偏置矩阵。\"\"\"\n",
    "    alibi = ALiBi(n_heads=n_heads, max_seq_len=seq_len)\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_heads, figsize=(4 * n_heads, 4))\n",
    "    if n_heads == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        bias = alibi.bias[i, :seq_len, :seq_len].numpy()\n",
    "        im = ax.imshow(bias, cmap=\"RdBu_r\", aspect=\"auto\")\n",
    "        ax.set_title(f\"Head {i+1}\\nslope={alibi.slopes[i]:.4f}\")\n",
    "        ax.set_xlabel(\"Key Position\")\n",
    "        ax.set_ylabel(\"Query Position\")\n",
    "        plt.colorbar(im, ax=ax)\n",
    "\n",
    "    plt.suptitle(\"ALiBi Bias Matrices (越远越负)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_alibi_bias()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. 总结\n",
    "\n",
    "| 特性 | Pre-LN (GPT) | Post-LN (BERT) |\n",
    "|:-----|:-------------|:---------------|\n",
    "| 归一化位置 | 子层之前 | 子层之后 |\n",
    "| 梯度稳定性 | 更稳定 | 需要 Warmup |\n",
    "| 深层训练 | 更容易 | 较困难 |\n",
    "| 最终 LayerNorm | 需要 | 不需要 |\n",
    "\n",
    "**高级技术**:\n",
    "- **GELU**: 平滑可微、概率解释、SOTA 标配\n",
    "- **RoPE**: 旋转位置编码，相对位置，外推性好\n",
    "- **ALiBi**: 线性偏置，零参数，外推性极强\n",
    "- **梯度检查点**: 内存换计算，训练超深网络"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
