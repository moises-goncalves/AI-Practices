---
title: 理论笔记
date: 2024-01-01 00:00:00
permalink: /modules/08-theory/
categories:
  - 学习模块
tags:
  - 理论
  - 数学
  - 笔记
author:
  name: zimingttkx
  link: https://github.com/zimingttkx
---

# 理论笔记

深度学习的数学基础和理论分析。

## 模块概览

| 属性 | 值 |
|:-----|:---|
| **前置要求** | 线性代数, 微积分, 概率论 |
| **内容类型** | 理论笔记、公式推导 |
| **难度** | ⭐⭐⭐⭐ 高级 |

## 内容目录

### 01. 线性代数基础

| 主题 | 内容 |
|:-----|:-----|
| 矩阵分解 | SVD, 特征分解, QR 分解 |
| 范数 | L1, L2, Frobenius 范数 |
| 矩阵微分 | 梯度、Jacobian、Hessian |

**SVD 分解：**

$$A = U \Sigma V^T$$

### 02. 概率论与统计

| 主题 | 内容 |
|:-----|:-----|
| 概率分布 | 高斯、伯努利、分类分布 |
| 信息论 | 熵、KL 散度、互信息 |
| 贝叶斯推断 | 先验、后验、MAP |

**KL 散度：**

$$D_{KL}(P \| Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}$$

### 03. 优化理论

| 主题 | 内容 |
|:-----|:-----|
| 凸优化 | 凸函数、凸集、对偶性 |
| 梯度下降 | 收敛性分析 |
| 二阶方法 | 牛顿法、拟牛顿法 |

**梯度下降收敛条件：**

对于 L-光滑凸函数，学习率 $\eta \leq \frac{1}{L}$ 时：

$$f(x_t) - f(x^*) \leq \frac{\|x_0 - x^*\|^2}{2\eta t}$$

### 04. 深度学习理论

| 主题 | 内容 |
|:-----|:-----|
| 万能近似定理 | 神经网络表达能力 |
| 泛化理论 | VC 维、Rademacher 复杂度 |
| 损失曲面 | 局部最小值、鞍点 |

### 05. 信息论视角

| 主题 | 内容 |
|:-----|:-----|
| 信息瓶颈 | 表示学习理论 |
| 最大熵原理 | 分布建模 |
| 变分推断 | ELBO 推导 |

## 重要公式速查

### 激活函数导数

| 函数 | 导数 |
|:-----|:-----|
| Sigmoid | $\sigma'(x) = \sigma(x)(1-\sigma(x))$ |
| Tanh | $\tanh'(x) = 1 - \tanh^2(x)$ |
| ReLU | $\text{ReLU}'(x) = \mathbf{1}_{x>0}$ |

### 损失函数

| 损失 | 公式 |
|:-----|:-----|
| MSE | $\frac{1}{n}\sum_i(y_i - \hat{y}_i)^2$ |
| Cross-Entropy | $-\sum_i y_i \log \hat{y}_i$ |
| Hinge | $\max(0, 1 - y \cdot \hat{y})$ |

## 参考资料

- Goodfellow, I., et al. (2016). *Deep Learning*. MIT Press.
- Boyd, S., & Vandenberghe, L. (2004). *Convex Optimization*. Cambridge University Press.
