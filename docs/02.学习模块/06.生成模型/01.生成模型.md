---
title: 生成模型
date: 2024-01-01 00:00:00
permalink: /modules/06-generative/
categories:
  - 学习模块
tags:
  - VAE
  - GAN
  - Diffusion
  - 生成模型
author:
  name: zimingttkx
  link: https://github.com/zimingttkx
---

# 生成模型

探索深度生成模型的前沿技术。

## 模块概览

| 属性 | 值 |
|:-----|:---|
| **前置要求** | 02-neural-networks, 概率论 |
| **学习时长** | 4-5 周 |
| **Notebooks** | 20+ |
| **难度** | ⭐⭐⭐⭐⭐ 专家级 |

## 学习目标

- ✅ 理解变分自编码器（VAE）的数学原理
- ✅ 掌握生成对抗网络（GAN）的训练技巧
- ✅ 深入理解扩散模型（Diffusion Models）
- ✅ 应用生成模型解决实际问题

## 子模块详解

### 01. Variational Autoencoders | 变分自编码器

**VAE 目标函数（ELBO）：**

$$\mathcal{L}(\theta, \phi; x) = \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) \| p(z))$$

| 组件 | 功能 |
|:-----|:-----|
| Encoder | 学习后验分布 $q_\phi(z|x)$ |
| Decoder | 学习生成分布 $p_\theta(x|z)$ |
| Reparameterization | 可微采样 |

### 02. Generative Adversarial Networks | 生成对抗网络

**GAN 目标函数：**

$$\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]$$

| 变体 | 特点 | 应用 |
|:-----|:-----|:-----|
| DCGAN | 卷积架构 | 图像生成 |
| WGAN | Wasserstein 距离 | 稳定训练 |
| StyleGAN | 风格控制 | 高质量人脸 |
| CycleGAN | 无配对翻译 | 风格迁移 |

### 03. Diffusion Models | 扩散模型

**前向扩散过程：**

$$q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)$$

**反向去噪过程：**

$$p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$$

| 模型 | 特点 |
|:-----|:-----|
| DDPM | 基础扩散模型 |
| DDIM | 加速采样 |
| Stable Diffusion | 潜空间扩散 |
| DALL-E | 文本到图像 |

```python
# 简化的扩散模型训练
def train_step(model, x_0, noise_scheduler):
    # 采样时间步
    t = torch.randint(0, T, (batch_size,))

    # 添加噪声
    noise = torch.randn_like(x_0)
    x_t = noise_scheduler.add_noise(x_0, noise, t)

    # 预测噪声
    noise_pred = model(x_t, t)

    # 计算损失
    loss = F.mse_loss(noise_pred, noise)
    return loss
```

### 04. Applications | 应用

| 应用 | 模型 | 描述 |
|:-----|:-----|:-----|
| 图像生成 | StyleGAN, Diffusion | 高质量图像合成 |
| 图像编辑 | GAN Inversion | 真实图像编辑 |
| 超分辨率 | ESRGAN | 图像增强 |
| 文本到图像 | DALL-E, Midjourney | 文本引导生成 |

## 参考资料

- Kingma, D. P., & Welling, M. (2014). Auto-Encoding Variational Bayes. *ICLR*.
- Goodfellow, I., et al. (2014). Generative Adversarial Nets. *NeurIPS*.
- Ho, J., et al. (2020). Denoising Diffusion Probabilistic Models. *NeurIPS*.
