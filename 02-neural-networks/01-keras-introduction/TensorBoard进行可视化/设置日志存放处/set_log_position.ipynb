{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard可视化训练过程\n",
    "\n",
    "本教程介绍如何使用TensorBoard监控和可视化神经网络的训练过程。\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "1. 理解TensorBoard的基本功能\n",
    "2. 掌握日志目录的设置方法\n",
    "3. 学会使用TensorBoard回调\n",
    "4. 了解高级可视化功能\n",
    "\n",
    "## TensorBoard功能概览\n",
    "\n",
    "| 功能 | 描述 | 用途 |\n",
    "|------|------|------|\n",
    "| Scalars | 标量指标曲线 | 监控损失和指标 |\n",
    "| Graphs | 计算图可视化 | 理解模型结构 |\n",
    "| Distributions | 权重分布 | 检测梯度问题 |\n",
    "| Histograms | 直方图 | 分析权重变化 |\n",
    "| Images | 图像数据 | 可视化输入/输出 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境配置与数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# 划分数据集\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.25, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"训练集: {X_train.shape}\")\n",
    "print(f\"验证集: {X_valid.shape}\")\n",
    "print(f\"测试集: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 设置日志目录\n",
    "\n",
    "为每次训练创建唯一的日志目录，便于对比不同实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置根日志目录\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir(name=None):\n",
    "    \"\"\"\n",
    "    生成带时间戳的日志目录路径\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    name : str, optional\n",
    "        实验名称，用于区分不同的实验\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : 日志目录路径\n",
    "    \"\"\"\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    if name:\n",
    "        run_id = f\"{name}_{run_id}\"\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# 创建日志目录\n",
    "run_logdir = get_run_logdir(\"baseline\")\n",
    "print(f\"日志目录: {run_logdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 基本TensorBoard使用\n",
    "\n",
    "使用TensorBoard回调记录训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_hidden=2, n_neurons=30, activation='relu'):\n",
    "    \"\"\"\n",
    "    创建回归模型\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_hidden : int\n",
    "        隐藏层数量\n",
    "    n_neurons : int\n",
    "        每层神经元数量\n",
    "    activation : str\n",
    "        激活函数\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    keras.Model : 编译好的模型\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=[8]))\n",
    "    \n",
    "    for _ in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=activation))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='sgd',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "model = create_model()\n",
    "\n",
    "# 创建TensorBoard回调\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(\n",
    "    log_dir=run_logdir,\n",
    "    histogram_freq=1,      # 每个epoch记录直方图\n",
    "    write_graph=True,      # 记录计算图\n",
    "    write_images=False,    # 不记录权重图像\n",
    "    update_freq='epoch',   # 每个epoch更新\n",
    "    profile_batch=0        # 禁用性能分析（设为2可启用）\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[tensorboard_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n日志已保存到: {run_logdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 对比不同模型配置\n",
    "\n",
    "使用TensorBoard对比不同超参数配置的训练效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义不同的配置\n",
    "configs = [\n",
    "    {'name': 'shallow', 'n_hidden': 1, 'n_neurons': 30},\n",
    "    {'name': 'deep', 'n_hidden': 3, 'n_neurons': 30},\n",
    "    {'name': 'wide', 'n_hidden': 1, 'n_neurons': 100},\n",
    "]\n",
    "\n",
    "# 训练每个配置\n",
    "for config in configs:\n",
    "    print(f\"\\n训练配置: {config['name']}\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # 创建模型\n",
    "    model = create_model(\n",
    "        n_hidden=config['n_hidden'],\n",
    "        n_neurons=config['n_neurons']\n",
    "    )\n",
    "    \n",
    "    # 创建独立的日志目录\n",
    "    logdir = get_run_logdir(config['name'])\n",
    "    \n",
    "    # TensorBoard回调\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(\n",
    "        log_dir=logdir,\n",
    "        histogram_freq=1\n",
    "    )\n",
    "    \n",
    "    # 训练\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        callbacks=[tensorboard_cb],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 评估\n",
    "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"测试MSE: {test_loss:.4f}, 测试MAE: {test_mae:.4f}\")\n",
    "    print(f\"日志保存到: {logdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 自定义指标记录\n",
    "\n",
    "使用`tf.summary`记录自定义指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetricsCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    自定义指标回调\n",
    "    \n",
    "    记录学习率、梯度范数等自定义指标\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_dir):\n",
    "        super().__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.writer = None\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"训练开始时创建SummaryWriter\"\"\"\n",
    "        self.writer = tf.summary.create_file_writer(self.log_dir)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"每个epoch结束时记录自定义指标\"\"\"\n",
    "        with self.writer.as_default():\n",
    "            # 记录学习率\n",
    "            lr = float(self.model.optimizer.learning_rate)\n",
    "            tf.summary.scalar('learning_rate', lr, step=epoch)\n",
    "            \n",
    "            # 计算并记录训练/验证损失比率（用于检测过拟合）\n",
    "            train_loss = logs.get('loss', 0)\n",
    "            val_loss = logs.get('val_loss', 1)\n",
    "            if val_loss > 0:\n",
    "                overfit_ratio = train_loss / val_loss\n",
    "                tf.summary.scalar('overfit_ratio', overfit_ratio, step=epoch)\n",
    "            \n",
    "            # 记录权重统计信息\n",
    "            for layer in self.model.layers:\n",
    "                if hasattr(layer, 'kernel'):\n",
    "                    weights = layer.kernel\n",
    "                    tf.summary.scalar(\n",
    "                        f'{layer.name}/weight_mean', \n",
    "                        tf.reduce_mean(weights), \n",
    "                        step=epoch\n",
    "                    )\n",
    "                    tf.summary.scalar(\n",
    "                        f'{layer.name}/weight_std', \n",
    "                        tf.math.reduce_std(weights), \n",
    "                        step=epoch\n",
    "                    )\n",
    "            \n",
    "            self.writer.flush()\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        \"\"\"训练结束时关闭writer\"\"\"\n",
    "        if self.writer:\n",
    "            self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用自定义指标回调\n",
    "model = create_model(n_hidden=2, n_neurons=50)\n",
    "\n",
    "custom_logdir = get_run_logdir(\"custom_metrics\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir=custom_logdir, histogram_freq=1),\n",
    "    CustomMetricsCallback(log_dir=custom_logdir)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n自定义指标已记录到: {custom_logdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 使用HParams记录超参数\n",
    "\n",
    "使用TensorBoard的HParams功能记录和对比超参数实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# 定义超参数空间\n",
    "HP_NUM_HIDDEN = hp.HParam('num_hidden', hp.IntInterval(1, 4))\n",
    "HP_NUM_NEURONS = hp.HParam('num_neurons', hp.Discrete([30, 50, 100]))\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(0.001, 0.1))\n",
    "\n",
    "# 定义要追踪的指标\n",
    "METRIC_MSE = 'mse'\n",
    "METRIC_MAE = 'mae'\n",
    "\n",
    "def run_hparams_experiment(hparams, run_dir):\n",
    "    \"\"\"\n",
    "    运行超参数实验\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hparams : dict\n",
    "        超参数字典\n",
    "    run_dir : str\n",
    "        日志目录\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (test_mse, test_mae)\n",
    "    \"\"\"\n",
    "    # 创建模型\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=[8])\n",
    "    ])\n",
    "    \n",
    "    for _ in range(hparams[HP_NUM_HIDDEN]):\n",
    "        model.add(keras.layers.Dense(hparams[HP_NUM_NEURONS], activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=hparams[HP_LEARNING_RATE]),\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # 训练\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        callbacks=[\n",
    "            keras.callbacks.TensorBoard(log_dir=run_dir),\n",
    "            hp.KerasCallback(run_dir, hparams)\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 评估\n",
    "    test_mse, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_mse, test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行超参数搜索实验\n",
    "hparams_logdir = os.path.join(root_logdir, \"hparams_search\")\n",
    "\n",
    "# 配置HParams\n",
    "with tf.summary.create_file_writer(hparams_logdir).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_HIDDEN, HP_NUM_NEURONS, HP_LEARNING_RATE],\n",
    "        metrics=[hp.Metric(METRIC_MSE, display_name='MSE'),\n",
    "                 hp.Metric(METRIC_MAE, display_name='MAE')]\n",
    "    )\n",
    "\n",
    "# 定义实验配置\n",
    "experiments = [\n",
    "    {HP_NUM_HIDDEN: 1, HP_NUM_NEURONS: 30, HP_LEARNING_RATE: 0.01},\n",
    "    {HP_NUM_HIDDEN: 2, HP_NUM_NEURONS: 50, HP_LEARNING_RATE: 0.01},\n",
    "    {HP_NUM_HIDDEN: 2, HP_NUM_NEURONS: 100, HP_LEARNING_RATE: 0.005},\n",
    "    {HP_NUM_HIDDEN: 3, HP_NUM_NEURONS: 50, HP_LEARNING_RATE: 0.01},\n",
    "]\n",
    "\n",
    "# 运行每个实验\n",
    "print(\"超参数搜索实验:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, hparams in enumerate(experiments):\n",
    "    run_name = f\"run_{i}\"\n",
    "    run_dir = os.path.join(hparams_logdir, run_name)\n",
    "    \n",
    "    print(f\"\\n{run_name}: hidden={hparams[HP_NUM_HIDDEN]}, \"\n",
    "          f\"neurons={hparams[HP_NUM_NEURONS]}, lr={hparams[HP_LEARNING_RATE]}\")\n",
    "    \n",
    "    test_mse, test_mae = run_hparams_experiment(hparams, run_dir)\n",
    "    \n",
    "    # 记录最终指标\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        tf.summary.scalar(METRIC_MSE, test_mse, step=1)\n",
    "        tf.summary.scalar(METRIC_MAE, test_mae, step=1)\n",
    "    \n",
    "    print(f\"  MSE: {test_mse:.4f}, MAE: {test_mae:.4f}\")\n",
    "\n",
    "print(f\"\\n所有实验日志保存到: {hparams_logdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 启动TensorBoard\n",
    "\n",
    "### 方式一：命令行启动\n",
    "\n",
    "在终端中运行：\n",
    "```bash\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "```\n",
    "\n",
    "然后在浏览器中访问 `http://localhost:6006`\n",
    "\n",
    "### 方式二：在Jupyter中启动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在Jupyter中加载TensorBoard扩展\n",
    "# 注意：此功能需要jupyter-tensorboard扩展\n",
    "try:\n",
    "    %load_ext tensorboard\n",
    "    print(\"TensorBoard扩展已加载\")\n",
    "except:\n",
    "    print(\"无法加载TensorBoard扩展，请使用命令行启动\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动TensorBoard（在Jupyter中）\n",
    "# 取消注释下面的行以启动\n",
    "# %tensorboard --logdir ./my_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 清理日志文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# 列出所有日志目录\n",
    "print(\"已创建的日志目录:\")\n",
    "if os.path.exists(root_logdir):\n",
    "    for item in sorted(os.listdir(root_logdir)):\n",
    "        item_path = os.path.join(root_logdir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            # 计算目录大小\n",
    "            size = sum(\n",
    "                os.path.getsize(os.path.join(dirpath, f))\n",
    "                for dirpath, dirnames, filenames in os.walk(item_path)\n",
    "                for f in filenames\n",
    "            ) / 1024\n",
    "            print(f\"  {item} ({size:.1f} KB)\")\n",
    "\n",
    "# 取消注释以下代码来清理日志\n",
    "# if os.path.exists(root_logdir):\n",
    "#     shutil.rmtree(root_logdir)\n",
    "#     print(\"\\n已清理所有日志文件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "### TensorBoard回调参数\n",
    "\n",
    "| 参数 | 默认值 | 说明 |\n",
    "|------|--------|------|\n",
    "| log_dir | None | 日志保存目录 |\n",
    "| histogram_freq | 0 | 直方图记录频率（epoch数） |\n",
    "| write_graph | True | 是否记录计算图 |\n",
    "| write_images | False | 是否将权重可视化为图像 |\n",
    "| update_freq | 'epoch' | 更新频率（'batch'/'epoch'/整数） |\n",
    "| profile_batch | 0 | 性能分析的批次 |\n",
    "\n",
    "### 最佳实践\n",
    "\n",
    "1. **命名规范**: 为每个实验使用描述性名称\n",
    "2. **版本控制**: 在日志目录名中包含时间戳\n",
    "3. **定期清理**: 删除不需要的旧日志\n",
    "4. **记录超参数**: 使用HParams功能方便对比\n",
    "\n",
    "### 常用命令\n",
    "\n",
    "```bash\n",
    "# 基本启动\n",
    "tensorboard --logdir=./my_logs\n",
    "\n",
    "# 指定端口\n",
    "tensorboard --logdir=./my_logs --port=6007\n",
    "\n",
    "# 绑定所有网络接口（远程访问）\n",
    "tensorboard --logdir=./my_logs --host=0.0.0.0\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
