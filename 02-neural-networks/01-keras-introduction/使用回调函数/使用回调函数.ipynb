{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras回调函数详解\n",
    "\n",
    "本教程介绍Keras的回调机制，用于在训练过程中执行自定义操作。\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "1. 理解回调函数的工作机制\n",
    "2. 掌握常用内置回调的使用方法\n",
    "3. 学会实现自定义回调\n",
    "4. 了解回调函数的最佳实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境配置与数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.25, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"训练集: {X_train.shape[0]} 样本\")\n",
    "print(f\"验证集: {X_valid.shape[0]} 样本\")\n",
    "print(f\"测试集: {X_test.shape[0]} 样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"创建回归模型\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
    "        keras.layers.Dense(30, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ModelCheckpoint - 模型检查点\n",
    "\n",
    "自动保存训练过程中的最佳模型或定期保存检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "# ModelCheckpoint回调配置\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/best_model.h5',\n",
    "    monitor='val_loss',        # 监控指标\n",
    "    save_best_only=True,       # 只保存最佳模型\n",
    "    save_weights_only=False,   # 保存完整模型\n",
    "    mode='min',                # 监控指标越小越好\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[checkpoint_cb],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型进行评估\n",
    "best_model = keras.models.load_model('checkpoints/best_model.h5')\n",
    "test_loss, test_mae = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"最佳模型测试集 - MSE: {test_loss:.4f}, MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EarlyStopping - 早停\n",
    "\n",
    "当监控指标不再改善时提前停止训练，防止过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "# EarlyStopping回调配置\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',           # 监控验证损失\n",
    "    patience=10,                  # 连续10个epoch没有改善则停止\n",
    "    min_delta=0.001,              # 改善阈值\n",
    "    restore_best_weights=True,    # 恢复最佳权重\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  # 设置较大的epoch数，让早停来决定何时停止\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n实际训练轮数: {len(history.history['loss'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 组合使用回调函数\n",
    "\n",
    "结合ModelCheckpoint和EarlyStopping是最佳实践。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "# 组合回调函数\n",
    "callbacks = [\n",
    "    # 保存最佳模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'checkpoints/combined_best.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # 早停\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 评估\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n测试集 - MSE: {test_loss:.4f}, MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ReduceLROnPlateau - 学习率调度\n",
    "\n",
    "当指标停止改善时自动降低学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "# 学习率调度回调\n",
    "reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,              # 学习率降低因子\n",
    "    patience=5,              # 等待改善的epoch数\n",
    "    min_lr=1e-6,             # 最小学习率\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True),\n",
    "    reduce_lr_cb\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LearningRateScheduler - 自定义学习率调度\n",
    "\n",
    "按照自定义函数调整学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(epoch, lr):\n",
    "    \"\"\"\n",
    "    指数衰减学习率调度\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epoch : int\n",
    "        当前epoch\n",
    "    lr : float\n",
    "        当前学习率\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : 新学习率\n",
    "    \"\"\"\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.9\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "lr_scheduler_cb = keras.callbacks.LearningRateScheduler(exponential_decay, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler_cb],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化学习率变化\n",
    "if 'lr' in history.history:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['lr'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 自定义回调函数\n",
    "\n",
    "通过继承`keras.callbacks.Callback`创建自定义回调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    自定义训练监控回调\n",
    "    \n",
    "    功能：\n",
    "    - 记录每个epoch的训练状态\n",
    "    - 在验证损失改善时打印消息\n",
    "    - 跟踪最佳性能\n",
    "    \"\"\"\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"训练开始时调用\"\"\"\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_epoch = 0\n",
    "        print(\"训练开始...\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"每个epoch结束时调用\"\"\"\n",
    "        val_loss = logs.get('val_loss')\n",
    "        if val_loss < self.best_val_loss:\n",
    "            improvement = self.best_val_loss - val_loss\n",
    "            self.best_val_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            print(f\"  Epoch {epoch+1}: 验证损失改善 {improvement:.4f}\")\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        \"\"\"训练结束时调用\"\"\"\n",
    "        print(f\"\\n训练完成!\")\n",
    "        print(f\"最佳验证损失: {self.best_val_loss:.4f} (Epoch {self.best_epoch+1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "# 使用自定义回调\n",
    "custom_cb = TrainingMonitor()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[custom_cb],\n",
    "    verbose=0  # 关闭默认输出\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 可视化训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用完整回调组合进行最终训练\n",
    "model = create_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'checkpoints/final_best.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练曲线\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 损失曲线\n",
    "axes[0].plot(history.history['loss'], label='Training')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('Loss Curves')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE曲线\n",
    "axes[1].plot(history.history['mae'], label='Training')\n",
    "axes[1].plot(history.history['val_mae'], label='Validation')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('MAE Curves')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 最终评估\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n最终模型测试集 - MSE: {test_loss:.4f}, MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "### 常用回调函数\n",
    "\n",
    "| 回调 | 功能 | 典型用法 |\n",
    "|------|------|----------|\n",
    "| ModelCheckpoint | 保存模型 | 保存最佳模型 |\n",
    "| EarlyStopping | 早停 | 防止过拟合 |\n",
    "| ReduceLROnPlateau | 降低学习率 | 突破训练瓶颈 |\n",
    "| LearningRateScheduler | 自定义学习率 | 实现特定调度策略 |\n",
    "| TensorBoard | 可视化 | 监控训练过程 |\n",
    "\n",
    "### 最佳实践\n",
    "\n",
    "1. **始终使用ModelCheckpoint**: 避免因意外中断丢失进度\n",
    "2. **结合EarlyStopping使用restore_best_weights=True**: 确保获得最佳模型\n",
    "3. **设置合理的patience值**: 太小会过早停止，太大会浪费时间\n",
    "4. **监控val_loss而非loss**: 关注泛化能力而非训练表现"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
