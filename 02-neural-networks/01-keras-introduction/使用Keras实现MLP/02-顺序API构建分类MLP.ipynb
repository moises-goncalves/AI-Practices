{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Sequential API构建图像分类MLP\n",
    "\n",
    "本教程演示如何使用Keras的Sequential API构建多层感知机(MLP)来解决图像分类问题。\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "1. 理解图像分类任务的数据预处理流程\n",
    "2. 掌握多分类MLP的模型架构设计\n",
    "3. 学会使用交叉熵损失函数\n",
    "4. 理解Softmax输出和概率预测\n",
    "\n",
    "## 数据集介绍\n",
    "\n",
    "Fashion-MNIST数据集包含10类时尚商品的灰度图像：\n",
    "- 60,000张训练图像\n",
    "- 10,000张测试图像\n",
    "- 图像尺寸：28×28像素\n",
    "- 10个类别：T恤、裤子、套头衫、连衣裙、外套、凉鞋、衬衫、运动鞋、包、短靴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 设置随机种子确保结果可复现\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据加载与探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Keras内置API加载Fashion-MNIST数据集\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# 查看数据集基本信息\n",
    "print(\"数据集形状:\")\n",
    "print(f\"训练集: {X_train_full.shape}\")\n",
    "print(f\"测试集: {X_test.shape}\")\n",
    "print(f\"\\n数据类型: {X_train_full.dtype}\")\n",
    "print(f\"像素值范围: [{X_train_full.min()}, {X_train_full.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义类别名称\n",
    "class_names = [\n",
    "    'T-shirt/top',  # T恤\n",
    "    'Trouser',      # 裤子\n",
    "    'Pullover',     # 套头衫\n",
    "    'Dress',        # 连衣裙\n",
    "    'Coat',         # 外套\n",
    "    'Sandal',       # 凉鞋\n",
    "    'Shirt',        # 衬衫\n",
    "    'Sneaker',      # 运动鞋\n",
    "    'Bag',          # 包\n",
    "    'Ankle boot'    # 短靴\n",
    "]\n",
    "\n",
    "# 查看标签分布\n",
    "print(\"训练集标签分布:\")\n",
    "unique, counts = np.unique(y_train_full, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  {class_names[label]}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化部分样本\n",
    "def plot_samples(X, y, class_names, n_rows=3, n_cols=5):\n",
    "    \"\"\"\n",
    "    绘制数据集样本\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray\n",
    "        图像数据\n",
    "    y : ndarray\n",
    "        标签数据\n",
    "    class_names : list\n",
    "        类别名称列表\n",
    "    n_rows, n_cols : int\n",
    "        行数和列数\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 7))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(X[i], cmap='gray')\n",
    "        ax.set_title(class_names[y[i]], fontsize=10)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_samples(X_train_full, y_train_full, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据预处理\n",
    "\n",
    "### 关键步骤\n",
    "\n",
    "1. **划分验证集**: 从训练集中分离出验证数据\n",
    "2. **归一化**: 将像素值从[0, 255]缩放到[0, 1]\n",
    "3. **展平**: MLP需要一维输入（Flatten层会在模型中处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分验证集（前5000个样本作为验证集）\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape[0]}\")\n",
    "print(f\"验证集大小: {X_valid.shape[0]}\")\n",
    "print(f\"测试集大小: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化：将像素值缩放到[0, 1]范围\n",
    "# 这对梯度下降优化至关重要\n",
    "X_train = X_train / 255.0\n",
    "X_valid = X_valid / 255.0\n",
    "X_test = X_test / 255.0  # 测试集也必须归一化！\n",
    "\n",
    "print(f\"归一化后像素值范围: [{X_train.min():.1f}, {X_train.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 构建MLP分类模型\n",
    "\n",
    "### 模型架构\n",
    "\n",
    "```\n",
    "输入层 (28×28 = 784个像素)\n",
    "    ↓ Flatten\n",
    "展平层 (784个神经元)\n",
    "    ↓\n",
    "隐藏层1 (300个神经元, ReLU)\n",
    "    ↓\n",
    "隐藏层2 (100个神经元, ReLU)\n",
    "    ↓\n",
    "输出层 (10个神经元, Softmax)\n",
    "```\n",
    "\n",
    "### 设计要点\n",
    "\n",
    "- **Flatten层**: 将2D图像展平为1D向量\n",
    "- **ReLU激活**: 隐藏层使用ReLU解决梯度消失问题\n",
    "- **Softmax激活**: 输出层使用Softmax生成概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建Sequential模型\n",
    "model = keras.Sequential([\n",
    "    # 输入层：Flatten将28×28图像展平为784维向量\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    \n",
    "    # 隐藏层1：300个神经元，ReLU激活\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    \n",
    "    # 隐藏层2：100个神经元，ReLU激活\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    \n",
    "    # 输出层：10个神经元（对应10个类别），Softmax激活\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 查看模型结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看模型参数详情\n",
    "print(\"模型层信息:\")\n",
    "print(\"=\"*60)\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"层{i}: {layer.name}\")\n",
    "    if hasattr(layer, 'kernel'):\n",
    "        weights, biases = layer.get_weights()\n",
    "        print(f\"  权重形状: {weights.shape}\")\n",
    "        print(f\"  偏置形状: {biases.shape}\")\n",
    "        print(f\"  参数总数: {weights.size + biases.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 编译模型\n",
    "\n",
    "### 损失函数选择\n",
    "\n",
    "- **sparse_categorical_crossentropy**: 标签为整数形式 (0, 1, 2, ...)\n",
    "- **categorical_crossentropy**: 标签为one-hot编码形式\n",
    "\n",
    "我们的标签是整数形式，所以使用sparse_categorical_crossentropy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',  # 多分类交叉熵损失\n",
    "    optimizer='sgd',                          # SGD优化器\n",
    "    metrics=['accuracy']                      # 监控准确率\n",
    ")\n",
    "\n",
    "# 等效的显式写法\n",
    "# model.compile(\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "#     optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "#     metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,                              # 训练30个epoch\n",
    "    batch_size=32,                          # 批量大小\n",
    "    validation_data=(X_valid, y_valid),     # 验证数据\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 可视化训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制学习曲线\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 损失曲线\n",
    "axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss Curves')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 准确率曲线\n",
    "axes[1].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy Curves')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用pandas绘制所有指标\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Training History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估模型\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"测试集评估结果:\")\n",
    "print(f\"损失 (Cross-Entropy): {test_loss:.4f}\")\n",
    "print(f\"准确率: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 使用模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对测试集前3个样本进行预测\n",
    "X_new = X_test[:3]\n",
    "y_true = y_test[:3]\n",
    "\n",
    "# predict()返回每个类别的概率\n",
    "y_proba = model.predict(X_new, verbose=0)\n",
    "\n",
    "print(\"预测概率分布:\")\n",
    "print(y_proba.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取预测类别（概率最高的类别）\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "\n",
    "print(\"预测结果:\")\n",
    "print(\"=\"*50)\n",
    "for i in range(len(X_new)):\n",
    "    true_label = class_names[y_true[i]]\n",
    "    pred_label = class_names[y_pred[i]]\n",
    "    confidence = y_proba[i][y_pred[i]] * 100\n",
    "    status = \"Correct\" if y_true[i] == y_pred[i] else \"Wrong\"\n",
    "    print(f\"样本{i+1}: 真实={true_label}, 预测={pred_label}, 置信度={confidence:.1f}% [{status}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化预测结果\n",
    "def plot_prediction(X, y_true, y_proba, class_names, n_samples=5):\n",
    "    \"\"\"\n",
    "    可视化模型预测结果\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(12, 5))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # 显示图像\n",
    "        axes[0, i].imshow(X[i], cmap='gray')\n",
    "        pred_label = np.argmax(y_proba[i])\n",
    "        color = 'green' if y_true[i] == pred_label else 'red'\n",
    "        axes[0, i].set_title(f\"True: {class_names[y_true[i]]}\\n\"\n",
    "                             f\"Pred: {class_names[pred_label]}\", \n",
    "                             color=color, fontsize=9)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # 显示概率分布\n",
    "        axes[1, i].barh(range(10), y_proba[i])\n",
    "        axes[1, i].set_yticks(range(10))\n",
    "        axes[1, i].set_yticklabels(class_names, fontsize=7)\n",
    "        axes[1, i].set_xlim(0, 1)\n",
    "        axes[1, i].axvline(x=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 可视化前5个测试样本的预测\n",
    "X_sample = X_test[:5]\n",
    "y_sample = y_test[:5]\n",
    "y_proba_sample = model.predict(X_sample, verbose=0)\n",
    "plot_prediction(X_sample, y_sample, y_proba_sample, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 混淆矩阵分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# 对整个测试集进行预测\n",
    "y_pred_all = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred_all)\n",
    "\n",
    "# 可视化混淆矩阵\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印分类报告\n",
    "print(\"分类报告:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_all, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "### 多分类任务的关键点\n",
    "\n",
    "1. **数据归一化**: 像素值缩放到[0,1]对训练至关重要\n",
    "2. **输出层设计**: 使用Softmax激活，神经元数等于类别数\n",
    "3. **损失函数**: 使用交叉熵损失（sparse或one-hot编码）\n",
    "4. **预测输出**: Softmax输出概率分布，使用argmax获取类别\n",
    "\n",
    "### 模型性能分析\n",
    "\n",
    "从混淆矩阵可以看出：\n",
    "- 容易混淆的类别：Shirt vs T-shirt/top, Pullover vs Coat\n",
    "- 这些类别在视觉上确实相似\n",
    "\n",
    "### 改进方向\n",
    "\n",
    "1. 增加网络深度或宽度\n",
    "2. 添加Dropout正则化\n",
    "3. 使用更高级的优化器(Adam)\n",
    "4. 使用数据增强\n",
    "5. 使用卷积神经网络(CNN)替代MLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
