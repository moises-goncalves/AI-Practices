{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tensorflow自定义的模型和训练算法",
   "id": "d8e85819101ab7b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12.3.1 自定义损失函数",
   "id": "4bcda03ccc014cb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:06:00.300586Z",
     "start_time": "2025-10-25T06:05:54.917969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras.layers\n",
    "import tensorflow as tf\n",
    "from sympy.assumptions.lra_satask import lra_satask\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1.0\n",
    "    squared_loss = 0.5 * tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n"
   ],
   "id": "b7f179d4dd000065",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\DeepLearning-py310\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 导入并处理数据",
   "id": "beaa762de7e7209c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:08:05.404099Z",
     "start_time": "2025-10-25T06:08:05.329762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42\n",
    ")"
   ],
   "id": "7891de066d97c5f4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 创建并编译model",
   "id": "d74176a039809bb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:14:04.309460Z",
     "start_time": "2025-10-25T06:13:49.249857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Normalization(),\n",
    "    keras.layers.Dense(256, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.LayerNormalization(),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Normalization(),\n",
    "    keras.layers.Dense(1, activation= \"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), callbacks=[early_stopping])"
   ],
   "id": "191cdb981235d1d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 4s 3ms/step - loss: 0.7473 - val_loss: 0.7080\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x196a0b14850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:14:36.714071Z",
     "start_time": "2025-10-25T06:14:36.496801Z"
    }
   },
   "cell_type": "code",
   "source": "model.evaluate(X_test, y_test)",
   "id": "93ee214f2af894f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.7290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7289659976959229"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 保存model",
   "id": "b4c398e6c7673e97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:16:23.882851Z",
     "start_time": "2025-10-25T06:16:23.860906Z"
    }
   },
   "cell_type": "code",
   "source": "model.save(\"my_custom_model.h5\")",
   "id": "ba1b6ca67a594617",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12.3.2 保存和加载包含自定义组件的模型",
   "id": "5d39148851ffa467"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:16:59.304054Z",
     "start_time": "2025-10-25T06:16:59.228894Z"
    }
   },
   "cell_type": "code",
   "source": "model = keras.models.load_model(\"my_custom_model.h5\", custom_objects={\"huber_fn\": huber_fn})",
   "id": "c48873e563976473",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 实现不同阈值的损失函数",
   "id": "a64ba62c1087cc2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:19:33.056787Z",
     "start_time": "2025-10-25T06:19:33.052783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = 0.5 * tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - 0.5 * threshold ** 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ],
   "id": "fb5222240dab03cf",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用新的损失函数编译model",
   "id": "f4df400aeadae0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:19:33.824885Z",
     "start_time": "2025-10-25T06:19:33.818885Z"
    }
   },
   "cell_type": "code",
   "source": "model.compile(loss= create_huber, optimizer=\"nadam\")",
   "id": "386e8bcd91601d67",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:20:11.892894Z",
     "start_time": "2025-10-25T06:20:11.879892Z"
    }
   },
   "cell_type": "code",
   "source": "model.save(\"my_custom_model_threshold.h5\")",
   "id": "d6e1d1c3ae15a0cf",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = keras.models.load_model(\"my_custom_model_threshold.h5\", custom_objects={\"huber_fn\": create_huber(0.5)})n",
   "id": "7f4796902e85a7fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 创建一个keras.losses.loss类的子类来实现加载模型的时候自动保存阈值",
   "id": "a5c73135fe8dd200"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:30:16.805701Z",
     "start_time": "2025-10-25T06:30:16.799702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.losses import Loss\n",
    "class HuberLoss(Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2.0\n",
    "        linear_loss = self.threshold * tf.abs(error) - 0.5 * tf.square(self.threshold)\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold} # **表示将字典中的键值对从源字典里面取出来作为参数传入函数"
   ],
   "id": "52923bad9367da62",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用自定义的loss类来编译model",
   "id": "b4c19ac7a5e135ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:31:05.441137Z",
     "start_time": "2025-10-25T06:31:05.424139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(loss=HuberLoss(threshold=2.), optimizer= \"nadam\")\n",
    "model.save(\"My_custom_model_threshold2.h5\")"
   ],
   "id": "9bfa3830f1e69207",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:31:29.412321Z",
     "start_time": "2025-10-25T06:31:29.358750Z"
    }
   },
   "cell_type": "code",
   "source": "model = keras.models.load_model(\"My_custom_model_threshold2.h5\",custom_objects={\"HuberLoss\": HuberLoss})",
   "id": "fffb43883ae5ec3c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12.3.3 自定义激活函数 初始化 正则化器",
   "id": "8f87a2947899565d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:42:06.871470Z",
     "start_time": "2025-10-25T06:42:06.866469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2.0 / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(weights)) * 1e-3\n",
    "\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights < 0, tf.zeros_like(weights), weights)\n",
    "\n",
    "layer = keras.layers.Dense(10, activation=my_softplus, kernel_initializer=my_glorot_initializer, kernel_regularizer=my_l1_regularizer, bias_regularizer=my_l1_regularizer, activity_regularizer=my_l1_regularizer, kernel_constraint=my_positive_weights, bias_constraint=my_positive_weights)"
   ],
   "id": "2552d77367ae3c11",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 如果函数有需要和模型一起保存的参数 则需要继承相应的类\n",
    "#### 必须为损失 层 模型实现call方法 或者为正则化初始化和约束实现__call__方法"
   ],
   "id": "594c23022f9611e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(weights)) * self.factor\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ],
   "id": "5557ed60b9679c37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12.3.4自定义指标",
   "id": "38bd266b33410dfd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义一个流式度量 即每次返回的是基于此刻的预测总指标",
   "id": "e896588f26aa48d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:58:55.800826Z",
     "start_time": "2025-10-25T06:58:55.794320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "\n",
    "    # 初始化函数，设置阈值和Huber函数\n",
    "    # threshold: Huber函数的阈值，默认值为1.0\n",
    "    # **kwargs: 其他传递给父类的参数\n",
    "        super().__init__(**kwargs)  # 调用父类的初始化方法\n",
    "    # 设置Huber函数的阈值\n",
    "        self.threshold = threshold\n",
    "    # 创建Huber函数实例\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\") # 每次计算指标时都会更新这个变量\n",
    "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "\n",
    "        # 计算损失，使用huber_fn函数计算真实值和预测值之间的损失\n",
    "        loss = self.huber_fn(y_true, y_pred)\n",
    "        # 更新指标\n",
    "        self.total.assign_add(tf.reduce_sum(loss))\n",
    "        self.count.assign_add(tf.cast(tf.size(loss), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "    # 计算并返回平均值\n",
    "    # 通过将总数除以数量得到平均值\n",
    "        return self.total / self.count\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        return {\"threshold\": self.threshold}  # 返回包含阈值的配置字典"
   ],
   "id": "441145f7c7e35335",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12.3.5自定义层",
   "id": "d9191de7bdb7c76e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 创建keras.layers.Layer的子类来实现自定义层",
   "id": "f40fbe1aac8c9311"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:19:15.856906Z",
     "start_time": "2025-10-25T07:19:15.851904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(name=\"kernel\", shape=[batch_input_shape[-1], self.units], initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.bias = self.add_weight(name=\"bias\", shape=[self.units], initializer=\"zeros\", trainable=True)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.kernel) + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return (batch_input_shape[0], self.units)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config().copy()\n",
    "        return {**base_config, \"units\": self.units, \"activation\": self.activation}"
   ],
   "id": "1afdef3485334063",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 创建一个具有多个输入的Concatenate层",
   "id": "50b162773288ca7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e498a6662c8a4784"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:22:25.556107Z",
     "start_time": "2025-10-25T07:22:25.553107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Concatenate(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return [X1 + X2, X1 * X2, X1 / X2]\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        b1, b2 = batch_input_shape\n",
    "        return [b1, b1, b1]"
   ],
   "id": "93e2cf86898feee9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义一个训练期间添加高斯噪声测试期间什么都不做的",
   "id": "dda7b2cec405cdd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:25:32.048448Z",
     "start_time": "2025-10-25T07:25:32.044447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwarge):\n",
    "        super().__init__()\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), mean=0.0, stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ],
   "id": "62ca90c088934a9e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12.3.6 自定义模型",
   "id": "c37192a6eaffa038"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 创建一个跳过链接或者包含循环的model",
   "id": "c89207cd80ed5f6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:35:40.402466Z",
     "start_time": "2025-10-25T07:35:40.397466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_layers = n_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\", kernel_initializer=\"he_normal\") for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "\n",
    "        return inputs + Z"
   ],
   "id": "df4f52c5a5be9267",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:42:11.050348Z",
     "start_time": "2025-10-25T07:42:11.046347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n"
   ],
   "id": "879d265101bd5f47",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12.3.7 基于model内部的损失和指标",
   "id": "517f3bcb5e8e753c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:54:42.377665Z",
     "start_time": "2025-10-25T07:54:42.371667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",kernel_initializer=\"lecun_normal\") for _ in range(5)]\n",
    "\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        return self.out(Z)"
   ],
   "id": "dd77ea685a28bde2",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12.3.8 使用自动微分计算梯度",
   "id": "2b0a3a97418bde6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 12.3.9 使用自定义训练循环\n",
    "### 编写自定义训练循环会使代码更长 更加容易出错并且更加容易出错"
   ],
   "id": "8b013db40be92199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 创建一个简单的模型",
   "id": "86da426715d8dc1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T08:00:13.986548Z",
     "start_time": "2025-10-25T08:00:13.978551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l2_reg = keras.regularizers.l2(0.001)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_initializer = l2_reg)\n",
    "])"
   ],
   "id": "5f492fd1a7fb7c7a",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 创建一个函数用来对数据进行随机取样",
   "id": "5f47469b24389543"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def random_batch(X, y, batch_size):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ],
   "id": "2cedb464da6c5d40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义一个函数用来显示训练状态 包括步数 总步数 从轮次开始以来的平均损失",
   "id": "feec5e149c285e23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) for m in metrics])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - loss: {:.4f} - {}\".format(iteration, total, loss, metrics), end=end)"
   ],
   "id": "f982bf1135580ec2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义一些超参数 然后选择优化器 损失函数 指标",
   "id": "6809fd757f9208b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T08:05:28.422937Z",
     "start_time": "2025-10-25T08:05:28.415938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ],
   "id": "62c6fd8db1b40614",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义训练循环",
   "id": "b64c05fd39e8a140"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T08:09:25.291584Z",
     "start_time": "2025-10-25T08:09:25.267587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(n_steps):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch,training= True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = main_loss + sum(model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step, n_steps, mean_loss.result(), metrics)\n",
    "    print_status_bar(step, n_steps, mean_loss.result(), metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()\n"
   ],
   "id": "963a3a4604b2b5bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'random_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(epoch, n_epochs))\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_steps):\n\u001B[1;32m----> 4\u001B[0m     X_batch, y_batch \u001B[38;5;241m=\u001B[39m \u001B[43mrandom_batch\u001B[49m(X_train, y_train, batch_size)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[0;32m      6\u001B[0m         y_pred \u001B[38;5;241m=\u001B[39m model(X_batch,training\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'random_batch' is not defined"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cecaa6a63b393872"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
