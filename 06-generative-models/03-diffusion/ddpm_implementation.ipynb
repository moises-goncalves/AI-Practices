{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPM 完整实现：训练与采样\n",
    "\n",
    "本 Notebook 实现完整的 DDPM，包括：\n",
    "1. 带时间嵌入的简化 U-Net\n",
    "2. 训练算法（预测噪声）\n",
    "3. 采样算法（逆向去噪）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 超参数\n",
    "IMG_SIZE = 28\n",
    "CHANNELS = 1\n",
    "TIMESTEPS = 1000\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 噪声调度器 (DDPMScheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMScheduler:\n",
    "    \"\"\"DDPM 噪声调度器\"\"\"\n",
    "\n",
    "    def __init__(self, timesteps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        self.timesteps = timesteps\n",
    "        self.betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "        # 预计算系数\n",
    "        self.sqrt_alpha_bars = torch.sqrt(self.alpha_bars)\n",
    "        self.sqrt_one_minus_alpha_bars = torch.sqrt(1.0 - self.alpha_bars)\n",
    "\n",
    "        # 采样时需要的系数\n",
    "        self.sqrt_alphas = torch.sqrt(self.alphas)\n",
    "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n",
    "\n",
    "    def add_noise(self, x0, t, noise=None):\n",
    "        \"\"\"前向加噪: x_t = sqrt(alpha_bar_t) * x_0 + sqrt(1-alpha_bar_t) * noise\"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "\n",
    "        sqrt_alpha_bar = self.sqrt_alpha_bars[t].view(-1, 1, 1, 1).to(x0.device)\n",
    "        sqrt_one_minus_alpha_bar = self.sqrt_one_minus_alpha_bars[t].view(-1, 1, 1, 1).to(x0.device)\n",
    "\n",
    "        x_t = sqrt_alpha_bar * x0 + sqrt_one_minus_alpha_bar * noise\n",
    "        return x_t, noise\n",
    "\n",
    "\n",
    "scheduler = DDPMScheduler(timesteps=TIMESTEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 时间嵌入 (Sinusoidal Position Embedding)\n",
    "\n",
    "将标量时间步 $t$ 映射为高维向量，使用正弦位置编码：\n",
    "$$PE(t, 2i) = \\sin(t / 10000^{2i/d})$$\n",
    "$$PE(t, 2i+1) = \\cos(t / 10000^{2i/d})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbedding(nn.Module):\n",
    "    \"\"\"正弦位置编码，将时间步 t 映射为向量\"\"\"\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 简化 U-Net\n",
    "\n",
    "结构：Encoder (下采样) -> Bottleneck -> Decoder (上采样) + Skip Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"简化版 U-Net，带时间嵌入\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=1, time_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        # 时间嵌入\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbedding(time_dim), nn.Linear(time_dim, time_dim), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Encoder (下采样)\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1)  # 28->14\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=2, padding=1)  # 14->7\n",
    "\n",
    "        # 时间嵌入投影\n",
    "        self.time_proj1 = nn.Linear(time_dim, 64)\n",
    "        self.time_proj2 = nn.Linear(time_dim, 128)\n",
    "        self.time_proj3 = nn.Linear(time_dim, 256)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Decoder (上采样) + Skip Connections\n",
    "        self.up1 = nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1)  # 7->14\n",
    "        self.conv4 = nn.Conv2d(256, 128, 3, padding=1)  # 128+128 skip\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1)  # 14->28\n",
    "        self.conv5 = nn.Conv2d(128, 64, 3, padding=1)  # 64+64 skip\n",
    "\n",
    "        # 输出层\n",
    "        self.out = nn.Conv2d(64, in_channels, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # 时间嵌入\n",
    "        t_emb = self.time_mlp(t.float())\n",
    "\n",
    "        # Encoder\n",
    "        h1 = F.relu(self.conv1(x) + self.time_proj1(t_emb)[:, :, None, None])\n",
    "        h2 = F.relu(self.conv2(h1) + self.time_proj2(t_emb)[:, :, None, None])\n",
    "        h3 = F.relu(self.conv3(h2) + self.time_proj3(t_emb)[:, :, None, None])\n",
    "\n",
    "        # Bottleneck\n",
    "        h = self.bottleneck(h3)\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        h = self.up1(h)\n",
    "        h = torch.cat([h, h2], dim=1)\n",
    "        h = F.relu(self.conv4(h))\n",
    "\n",
    "        h = self.up2(h)\n",
    "        h = torch.cat([h, h1], dim=1)\n",
    "        h = F.relu(self.conv5(h))\n",
    "\n",
    "        return self.out(h)\n",
    "\n",
    "\n",
    "model = SimpleUNet(in_channels=CHANNELS).to(device)\n",
    "print(f\"模型参数量: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]  # 归一化到 [-1, 1]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "print(f\"训练集大小: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练算法\n",
    "\n",
    "**Algorithm 1 (Training)**:\n",
    "1. 采样 $x_0 \\sim q(x_0)$\n",
    "2. 采样 $t \\sim \\text{Uniform}(1, T)$\n",
    "3. 采样 $\\epsilon \\sim \\mathcal{N}(0, I)$\n",
    "4. 计算 $x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1-\\bar{\\alpha}_t} \\epsilon$\n",
    "5. 梯度下降: $\\nabla_\\theta \\|\\epsilon - \\epsilon_\\theta(x_t, t)\\|^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, x0, scheduler, optimizer):\n",
    "    \"\"\"单步训练\"\"\"\n",
    "    batch_size = x0.shape[0]\n",
    "\n",
    "    # 1. 随机采样时间步 t\n",
    "    t = torch.randint(0, scheduler.timesteps, (batch_size,), device=x0.device)\n",
    "\n",
    "    # 2. 随机采样噪声\n",
    "    noise = torch.randn_like(x0)\n",
    "\n",
    "    # 3. 构造加噪图片 x_t\n",
    "    x_t, _ = scheduler.add_noise(x0, t, noise)\n",
    "\n",
    "    # 4. 模型预测噪声\n",
    "    noise_pred = model(x_t, t)\n",
    "\n",
    "    # 5. 计算 MSE Loss\n",
    "    loss = F.mse_loss(noise_pred, noise)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 采样算法\n",
    "\n",
    "**Algorithm 2 (Sampling)**:\n",
    "1. $x_T \\sim \\mathcal{N}(0, I)$\n",
    "2. For $t = T, ..., 1$:\n",
    "   - $z \\sim \\mathcal{N}(0, I)$ if $t > 1$, else $z = 0$\n",
    "   - $x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}}\\left(x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\epsilon_\\theta(x_t, t)\\right) + \\sigma_t z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, scheduler, n_samples=64, img_size=28, channels=1):\n",
    "    \"\"\"DDPM 采样算法\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # 从纯噪声开始\n",
    "    x = torch.randn(n_samples, channels, img_size, img_size).to(device)\n",
    "\n",
    "    # 逆向去噪\n",
    "    for t in reversed(range(scheduler.timesteps)):\n",
    "        t_batch = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
    "\n",
    "        # 预测噪声\n",
    "        noise_pred = model(x, t_batch)\n",
    "\n",
    "        # 获取系数\n",
    "        alpha = scheduler.alphas[t]\n",
    "        alpha_bar = scheduler.alpha_bars[t]\n",
    "        beta = scheduler.betas[t]\n",
    "\n",
    "        # 计算 x_{t-1}\n",
    "        # x_{t-1} = 1/sqrt(alpha_t) * (x_t - (1-alpha_t)/sqrt(1-alpha_bar_t) * noise_pred) + sigma_t * z\n",
    "        coef1 = 1 / torch.sqrt(alpha)\n",
    "        coef2 = (1 - alpha) / torch.sqrt(1 - alpha_bar)\n",
    "\n",
    "        x = coef1 * (x - coef2 * noise_pred)\n",
    "\n",
    "        # 添加噪声 (t > 0 时)\n",
    "        if t > 0:\n",
    "            sigma = torch.sqrt(beta)\n",
    "            z = torch.randn_like(x)\n",
    "            x = x + sigma * z\n",
    "\n",
    "    model.train()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(samples, title=\"Generated Samples\"):\n",
    "    \"\"\"展示生成的样本 (8x8 grid)\"\"\"\n",
    "    samples = (samples + 1) / 2  # [-1,1] -> [0,1]\n",
    "    samples = samples.clamp(0, 1)\n",
    "    grid = make_grid(samples, nrow=8, padding=2)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy(), cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "losses = []\n",
    "\n",
    "print(\"开始训练 DDPM...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (x0, _) in enumerate(train_loader):\n",
    "        x0 = x0.to(device)\n",
    "        loss = train_step(model, x0, scheduler, optimizer)\n",
    "        epoch_loss += loss\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # 每 5 个 epoch 生成样本\n",
    "    if epoch % 5 == 0:\n",
    "        samples = sample(model, scheduler, n_samples=64)\n",
    "        show_samples(samples, title=f\"Epoch {epoch}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"训练完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"DDPM Training Loss\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终生成效果\n",
    "print(\"生成最终样本...\")\n",
    "final_samples = sample(model, scheduler, n_samples=64)\n",
    "show_samples(final_samples, title=\"Final Generated Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 可视化去噪过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_with_trajectory(model, scheduler, n_samples=1, save_every=100):\n",
    "    \"\"\"采样并保存中间状态\"\"\"\n",
    "    model.eval()\n",
    "    trajectory = []\n",
    "\n",
    "    x = torch.randn(n_samples, CHANNELS, IMG_SIZE, IMG_SIZE).to(device)\n",
    "    trajectory.append(x.clone())\n",
    "\n",
    "    for t in reversed(range(scheduler.timesteps)):\n",
    "        t_batch = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
    "        noise_pred = model(x, t_batch)\n",
    "\n",
    "        alpha = scheduler.alphas[t]\n",
    "        alpha_bar = scheduler.alpha_bars[t]\n",
    "        beta = scheduler.betas[t]\n",
    "\n",
    "        x = (1 / torch.sqrt(alpha)) * (x - (1 - alpha) / torch.sqrt(1 - alpha_bar) * noise_pred)\n",
    "\n",
    "        if t > 0:\n",
    "            x = x + torch.sqrt(beta) * torch.randn_like(x)\n",
    "\n",
    "        if t % save_every == 0:\n",
    "            trajectory.append(x.clone())\n",
    "\n",
    "    model.train()\n",
    "    return trajectory\n",
    "\n",
    "\n",
    "# 可视化去噪轨迹\n",
    "trajectory = sample_with_trajectory(model, scheduler, n_samples=1, save_every=100)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(trajectory), figsize=(20, 2))\n",
    "for i, img in enumerate(trajectory):\n",
    "    img = (img + 1) / 2\n",
    "    axes[i].imshow(img[0, 0].cpu().numpy(), cmap=\"gray\")\n",
    "    axes[i].axis(\"off\")\n",
    "    t = 999 - i * 100 if i < len(trajectory) - 1 else 0\n",
    "    axes[i].set_title(f\"t={t}\")\n",
    "\n",
    "plt.suptitle(\"Denoising Trajectory: From Noise to Image\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
