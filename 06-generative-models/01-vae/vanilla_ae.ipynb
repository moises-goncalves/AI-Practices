{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Autoencoder: Deterministic Representation Learning\n",
    "\n",
    "## Core Idea\n",
    "\n",
    "An autoencoder learns a compressed representation $z = f(x)$ by training to reconstruct its input\n",
    "through an information bottleneck. The encoder maps high-dimensional data to a low-dimensional\n",
    "latent space, forcing the network to learn the most salient features.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### Architecture\n",
    "\n",
    "$$x \\xrightarrow{\\text{Encoder } f_\\phi} z \\xrightarrow{\\text{Decoder } g_\\theta} \\hat{x}$$\n",
    "\n",
    "- Encoder: $f_\\phi: \\mathbb{R}^D \\to \\mathbb{R}^d$ where $d \\ll D$\n",
    "- Decoder: $g_\\theta: \\mathbb{R}^d \\to \\mathbb{R}^D$\n",
    "- Reconstruction: $\\hat{x} = g_\\theta(f_\\phi(x))$\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "$$\\mathcal{L}(\\phi, \\theta) = \\mathbb{E}_{x \\sim p_{\\text{data}}}[\\|x - g_\\theta(f_\\phi(x))\\|^2]$$\n",
    "\n",
    "For binary data (e.g., binarized MNIST):\n",
    "$$\\mathcal{L} = -\\sum_i [x_i \\log \\hat{x}_i + (1-x_i) \\log(1-\\hat{x}_i)]$$\n",
    "\n",
    "### Connection to PCA (Theorem)\n",
    "\n",
    "**Bourlard & Kamp (1988):** For a linear autoencoder (no activation functions) with MSE loss,\n",
    "the optimal encoder weights span the same subspace as the top-$d$ principal components of the data.\n",
    "\n",
    "**Implication:** Nonlinear autoencoders generalize PCA to nonlinear manifolds.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Dimensionality reduction methods face a trade-off:\n",
    "- **PCA:** Linear, closed-form, but cannot capture nonlinear structure\n",
    "- **Kernel PCA:** Nonlinear, but $O(n^3)$ complexity and fixed kernel\n",
    "- **Autoencoder:** Learns nonlinear mapping, scalable, flexible architecture\n",
    "\n",
    "## Algorithm Comparison\n",
    "\n",
    "| Method | Linearity | Complexity | Generative |\n",
    "|--------|-----------|------------|------------|\n",
    "| PCA | Linear | $O(D^2 n)$ | No |\n",
    "| Kernel PCA | Nonlinear | $O(n^3)$ | No |\n",
    "| Autoencoder | Nonlinear | $O(n \\cdot T)$ | Limited |\n",
    "| VAE | Nonlinear | $O(n \\cdot T)$ | Yes |\n",
    "\n",
    "## Complexity Analysis\n",
    "\n",
    "- **Time:** $O(n \\cdot L \\cdot h^2)$ per epoch, where $L$ = layers, $h$ = hidden dim\n",
    "- **Space:** $O(\\sum_l h_l \\cdot h_{l+1})$ for weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AEConfig:\n",
    "    \"\"\"Configuration for Autoencoder.\n",
    "    \n",
    "    Core Idea:\n",
    "        The latent_dim controls the information bottleneck.\n",
    "        Smaller = more compression = more information loss.\n",
    "    \n",
    "    Mathematical Theory:\n",
    "        Compression ratio = input_dim / latent_dim\n",
    "        For MNIST: 784 / 32 = 24.5x compression\n",
    "    \"\"\"\n",
    "    input_dim: int = 784\n",
    "    hidden_dims: Tuple[int, ...] = (256, 128)\n",
    "    latent_dim: int = 32\n",
    "    \n",
    "    lr: float = 1e-3\n",
    "    batch_size: int = 128\n",
    "    num_epochs: int = 20\n",
    "    \n",
    "    device: str = field(default_factory=lambda: \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    seed: int = 42\n",
    "    \n",
    "    @property\n",
    "    def compression_ratio(self) -> float:\n",
    "        return self.input_dim / self.latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder network: maps input to latent space.\n",
    "    \n",
    "    Core Idea:\n",
    "        Progressive dimensionality reduction through hidden layers,\n",
    "        forcing the network to learn compact representations.\n",
    "    \n",
    "    Mathematical Theory:\n",
    "        $z = f_\\phi(x) = W_L \\cdot \\sigma(W_{L-1} \\cdots \\sigma(W_1 x))$\n",
    "        where $\\sigma$ is ReLU activation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: AEConfig) -> None:\n",
    "        super().__init__()\n",
    "        dims = [config.input_dim] + list(config.hidden_dims) + [config.latent_dim]\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(len(dims) - 1):\n",
    "            layers.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            if i < len(dims) - 2:\n",
    "                layers.append(nn.ReLU(True))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.net(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder network: maps latent code to reconstruction.\n",
    "    \n",
    "    Core Idea:\n",
    "        Mirror architecture of encoder, progressively expanding\n",
    "        dimensions back to input space.\n",
    "    \n",
    "    Mathematical Theory:\n",
    "        $\\hat{x} = g_\\theta(z) = \\sigma_{out}(W_L \\cdot \\sigma(W_{L-1} \\cdots \\sigma(W_1 z)))$\n",
    "        where $\\sigma_{out}$ is Sigmoid for [0,1] normalized images.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: AEConfig) -> None:\n",
    "        super().__init__()\n",
    "        dims = [config.latent_dim] + list(reversed(config.hidden_dims)) + [config.input_dim]\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(len(dims) - 1):\n",
    "            layers.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            if i < len(dims) - 2:\n",
    "                layers.append(nn.ReLU(True))\n",
    "            else:\n",
    "                layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, z: Tensor) -> Tensor:\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"Complete Autoencoder model.\n",
    "    \n",
    "    Core Idea:\n",
    "        Composition of encoder and decoder with shared bottleneck.\n",
    "        The bottleneck forces learning of compressed representations.\n",
    "    \n",
    "    Comparison:\n",
    "        vs VAE: No probabilistic latent space, cannot sample new data\n",
    "        vs PCA: Nonlinear, but no closed-form solution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: AEConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon.view_as(x), z\n",
    "    \n",
    "    def encode(self, x: Tensor) -> Tensor:\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AETrainer:\n",
    "    \"\"\"Training orchestrator for Autoencoder.\n",
    "    \n",
    "    Core Idea:\n",
    "        Minimize reconstruction error via gradient descent.\n",
    "        MSE loss for continuous data, BCE for binary.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: AEConfig) -> None:\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.device)\n",
    "        \n",
    "        torch.manual_seed(config.seed)\n",
    "        \n",
    "        self.model = Autoencoder(config).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.history: Dict[str, List[float]] = {\"loss\": []}\n",
    "    \n",
    "    def train_epoch(self, dataloader: DataLoader) -> float:\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for x, _ in dataloader:\n",
    "            x = x.to(self.device)\n",
    "            \n",
    "            x_recon, _ = self.model(x)\n",
    "            loss = self.criterion(x_recon, x)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        self.history[\"loss\"].append(avg_loss)\n",
    "        return avg_loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def reconstruct(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        self.model.eval()\n",
    "        x = x.to(self.device)\n",
    "        x_recon, z = self.model(x)\n",
    "        return x_recon.cpu(), z.cpu()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_latent(self, dataloader: DataLoader) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        self.model.eval()\n",
    "        latents, labels = [], []\n",
    "        \n",
    "        for x, y in dataloader:\n",
    "            z = self.model.encode(x.to(self.device))\n",
    "            latents.append(z.cpu().numpy())\n",
    "            labels.append(y.numpy())\n",
    "        \n",
    "        return np.concatenate(latents), np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(config: AEConfig) -> DataLoader:\n",
    "    transform = transforms.ToTensor()\n",
    "    dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=config.batch_size, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction(trainer: AETrainer, dataset: datasets.MNIST, n: int = 10) -> None:\n",
    "    indices = torch.randperm(len(dataset))[:n]\n",
    "    x = torch.stack([dataset[i][0] for i in indices])\n",
    "    x_recon, _ = trainer.reconstruct(x)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n, figsize=(n, 2.5))\n",
    "    for i in range(n):\n",
    "        axes[0, i].imshow(x[i].squeeze(), cmap=\"gray\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "        axes[1, i].imshow(x_recon[i].squeeze(), cmap=\"gray\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "    axes[0, 0].set_ylabel(\"Original\")\n",
    "    axes[1, 0].set_ylabel(\"Recon\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_space(trainer: AETrainer, dataloader: DataLoader) -> None:\n",
    "    from sklearn.manifold import TSNE\n",
    "    \n",
    "    z, y = trainer.get_latent(dataloader)\n",
    "    z_sample = z[:2000]\n",
    "    y_sample = y[:2000]\n",
    "    \n",
    "    if z.shape[1] > 2:\n",
    "        z_2d = TSNE(n_components=2, random_state=42).fit_transform(z_sample)\n",
    "    else:\n",
    "        z_2d = z_sample\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(z_2d[:, 0], z_2d[:, 1], c=y_sample, cmap=\"tab10\", alpha=0.6, s=10)\n",
    "    plt.colorbar(scatter, label=\"Digit\")\n",
    "    plt.title(\"Latent Space (t-SNE projection)\")\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curve(history: Dict[str, List[float]]) -> None:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history[\"loss\"], marker=\"o\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = AEConfig(latent_dim=32, num_epochs=20)\n",
    "    dataloader = create_dataloader(config)\n",
    "    trainer = AETrainer(config)\n",
    "    \n",
    "    print(f\"Model parameters: {sum(p.numel() for p in trainer.model.parameters()):,}\")\n",
    "    print(f\"Compression ratio: {config.compression_ratio:.1f}x\")\n",
    "    print(f\"Device: {config.device}\")\n",
    "    \n",
    "    for epoch in range(config.num_epochs):\n",
    "        loss = trainer.train_epoch(dataloader)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{config.num_epochs}] Loss: {loss:.6f}\")\n",
    "    \n",
    "    plot_training_curve(trainer.history)\n",
    "    visualize_reconstruction(trainer, dataloader.dataset)\n",
    "    visualize_latent_space(trainer, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Vanilla autoencoders learn compressed representations through reconstruction:\n",
    "\n",
    "1. **Information bottleneck:** Latent dim << input dim forces feature learning\n",
    "2. **Nonlinear PCA:** Generalizes linear dimensionality reduction\n",
    "3. **Deterministic:** Unlike VAE, no probabilistic sampling in latent space\n",
    "\n",
    "**Limitations:**\n",
    "- Latent space is irregular (not suitable for generation)\n",
    "- No explicit regularization on latent structure\n",
    "- Cannot sample new data points reliably\n",
    "\n",
    "**Next:** VAE adds probabilistic structure to enable generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
