{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional GAN (DCGAN)\n",
    "\n",
    "## Core Idea\n",
    "\n",
    "DCGAN extends vanilla GAN with convolutional architectures, enabling generation of spatially coherent images.\n",
    "The generator uses transposed convolutions (fractionally-strided convolutions) for learned upsampling,\n",
    "while the discriminator uses strided convolutions for downsampling, eliminating pooling layers entirely.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### Transposed Convolution\n",
    "\n",
    "Standard convolution with kernel $K$, stride $s$, padding $p$:\n",
    "$$H_{out} = \\lfloor \\frac{H_{in} + 2p - k}{s} \\rfloor + 1$$\n",
    "\n",
    "Transposed convolution (learned upsampling):\n",
    "$$H_{out} = (H_{in} - 1) \\times s - 2p + k + p_{out}$$\n",
    "\n",
    "**Interpretation:** Transposed convolution is NOT the inverse of convolution. It's the gradient operation\n",
    "of convolution with respect to its input, which happens to perform upsampling.\n",
    "\n",
    "### Architecture Guidelines (Radford et al., 2015)\n",
    "\n",
    "1. Replace pooling with strided convolutions (discriminator) and transposed convolutions (generator)\n",
    "2. Use BatchNorm in both networks (except G output and D input layers)\n",
    "3. Remove fully connected layers for deeper architectures\n",
    "4. Use ReLU in generator (except output: Tanh)\n",
    "5. Use LeakyReLU in discriminator\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Vanilla GAN with fully-connected layers:\n",
    "- Loses spatial structure (flattening destroys 2D relationships)\n",
    "- Scales poorly with image resolution ($O(n^2)$ parameters)\n",
    "- Produces blurry, incoherent images\n",
    "\n",
    "DCGAN addresses these by leveraging convolutional inductive bias for images.\n",
    "\n",
    "## Algorithm Comparison\n",
    "\n",
    "| Aspect | FC-GAN | DCGAN |\n",
    "|--------|--------|-------|\n",
    "| Spatial structure | Lost | Preserved |\n",
    "| Parameter scaling | $O(H \\times W)$ | $O(k^2 \\times C)$ |\n",
    "| Max practical resolution | 28x28 | 64x64+ |\n",
    "| Training stability | Poor | Better |\n",
    "\n",
    "## Complexity Analysis\n",
    "\n",
    "- **Generator:** $O(\\sum_l k_l^2 \\cdot C_{in}^l \\cdot C_{out}^l \\cdot H_l \\cdot W_l)$\n",
    "- **Discriminator:** Same complexity, but spatial dims decrease\n",
    "- **Memory:** Dominated by intermediate feature maps, not weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DCGANConfig:\n",
    "    \"\"\"Configuration for DCGAN.\n",
    "    \n",
    "    Core Idea:\n",
    "        Hyperparameters following DCGAN paper recommendations.\n",
    "    \n",
    "    Mathematical Theory:\n",
    "        - ngf/ndf: Base channel multipliers. Feature maps scale as ngf*2^i.\n",
    "        - beta1=0.5: Reduced momentum in Adam prevents oscillation in adversarial training.\n",
    "    \"\"\"\n",
    "    latent_dim: int = 100\n",
    "    ngf: int = 64\n",
    "    ndf: int = 64\n",
    "    nc: int = 3\n",
    "    image_size: int = 32\n",
    "    \n",
    "    lr: float = 2e-4\n",
    "    beta1: float = 0.5\n",
    "    beta2: float = 0.999\n",
    "    \n",
    "    batch_size: int = 128\n",
    "    num_epochs: int = 50\n",
    "    label_smoothing: float = 0.9\n",
    "    \n",
    "    device: str = field(default_factory=lambda: \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    seed: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANGenerator(nn.Module):\n",
    "    \"\"\"DCGAN Generator with transposed convolutions.\n",
    "    \n",
    "    Core Idea:\n",
    "        Progressive upsampling from 1x1 latent to full resolution image.\n",
    "        Each transposed conv doubles spatial dimensions while halving channels.\n",
    "    \n",
    "    Mathematical Theory:\n",
    "        Transposed conv output size: $H_{out} = (H_{in}-1) \\times s - 2p + k$\n",
    "        With k=4, s=2, p=1: $H_{out} = 2 \\times H_{in}$ (exact doubling)\n",
    "    \n",
    "    Architecture:\n",
    "        z (100x1x1) -> 512x4x4 -> 256x8x8 -> 128x16x16 -> 64x32x32 -> 3x32x32\n",
    "    \n",
    "    Complexity:\n",
    "        Parameters: ~2.7M for ngf=64\n",
    "        FLOPs: O(ngf^2 * image_size^2)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: DCGANConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        ngf = config.ngf\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # z -> ngf*8 x 4 x 4\n",
    "            nn.ConvTranspose2d(config.latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # ngf*8 x 4 x 4 -> ngf*4 x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # ngf*4 x 8 x 8 -> ngf*2 x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # ngf*2 x 16 x 16 -> ngf x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # ngf x 32 x 32 -> nc x 32 x 32\n",
    "            nn.Conv2d(ngf, config.nc, 3, 1, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, z: Tensor) -> Tensor:\n",
    "        return self.main(z.view(-1, self.config.latent_dim, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANDiscriminator(nn.Module):\n",
    "    \"\"\"DCGAN Discriminator with strided convolutions.\n",
    "    \n",
    "    Core Idea:\n",
    "        Progressive downsampling from image to single probability.\n",
    "        Strided convolutions replace pooling for learned downsampling.\n",
    "    \n",
    "    Mathematical Theory:\n",
    "        Strided conv output: $H_{out} = \\lfloor(H_{in} + 2p - k) / s\\rfloor + 1$\n",
    "        With k=4, s=2, p=1: $H_{out} = H_{in} / 2$ (exact halving)\n",
    "    \n",
    "    Architecture:\n",
    "        3x32x32 -> 64x16x16 -> 128x8x8 -> 256x4x4 -> 1x1x1\n",
    "    \n",
    "    Problem Statement:\n",
    "        No BatchNorm in first layer: BN on input images can destabilize training.\n",
    "        LeakyReLU prevents dead neurons that ReLU causes in discriminator.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: DCGANConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        ndf = config.ndf\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # nc x 32 x 32 -> ndf x 16 x 16\n",
    "            nn.Conv2d(config.nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # ndf x 16 x 16 -> ndf*2 x 8 x 8\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # ndf*2 x 8 x 8 -> ndf*4 x 4 x 4\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # ndf*4 x 4 x 4 -> 1 x 1 x 1\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.main(x).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANTrainer:\n",
    "    \"\"\"Training orchestrator for DCGAN.\n",
    "    \n",
    "    Core Idea:\n",
    "        Standard GAN training with BCE loss. Key difference from MLP-GAN\n",
    "        is the convolutional architecture, not the training procedure.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: DCGANConfig) -> None:\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.device)\n",
    "        \n",
    "        torch.manual_seed(config.seed)\n",
    "        \n",
    "        self.generator = DCGANGenerator(config).to(self.device)\n",
    "        self.discriminator = DCGANDiscriminator(config).to(self.device)\n",
    "        \n",
    "        self.optimizer_g = torch.optim.Adam(\n",
    "            self.generator.parameters(), lr=config.lr, betas=(config.beta1, config.beta2)\n",
    "        )\n",
    "        self.optimizer_d = torch.optim.Adam(\n",
    "            self.discriminator.parameters(), lr=config.lr, betas=(config.beta1, config.beta2)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.fixed_noise = torch.randn(64, config.latent_dim, device=self.device)\n",
    "        self.history: Dict[str, List[float]] = {\"loss_d\": [], \"loss_g\": [], \"d_real\": [], \"d_fake\": []}\n",
    "    \n",
    "    def _train_discriminator(self, real: Tensor) -> Tuple[float, float, float]:\n",
    "        batch_size = real.size(0)\n",
    "        real_labels = torch.full((batch_size, 1), self.config.label_smoothing, device=self.device)\n",
    "        fake_labels = torch.zeros(batch_size, 1, device=self.device)\n",
    "        \n",
    "        self.optimizer_d.zero_grad()\n",
    "        \n",
    "        output_real = self.discriminator(real)\n",
    "        loss_real = self.criterion(output_real, real_labels)\n",
    "        \n",
    "        z = torch.randn(batch_size, self.config.latent_dim, device=self.device)\n",
    "        fake = self.generator(z).detach()\n",
    "        output_fake = self.discriminator(fake)\n",
    "        loss_fake = self.criterion(output_fake, fake_labels)\n",
    "        \n",
    "        loss_d = loss_real + loss_fake\n",
    "        loss_d.backward()\n",
    "        self.optimizer_d.step()\n",
    "        \n",
    "        return loss_d.item(), output_real.mean().item(), output_fake.mean().item()\n",
    "    \n",
    "    def _train_generator(self, batch_size: int) -> float:\n",
    "        real_labels = torch.full((batch_size, 1), self.config.label_smoothing, device=self.device)\n",
    "        \n",
    "        self.optimizer_g.zero_grad()\n",
    "        \n",
    "        z = torch.randn(batch_size, self.config.latent_dim, device=self.device)\n",
    "        fake = self.generator(z)\n",
    "        output = self.discriminator(fake)\n",
    "        \n",
    "        loss_g = self.criterion(output, real_labels)\n",
    "        loss_g.backward()\n",
    "        self.optimizer_g.step()\n",
    "        \n",
    "        return loss_g.item()\n",
    "    \n",
    "    def train_epoch(self, dataloader: DataLoader) -> Dict[str, float]:\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "        \n",
    "        epoch_metrics = {k: 0.0 for k in self.history.keys()}\n",
    "        num_batches = len(dataloader)\n",
    "        \n",
    "        for real, _ in dataloader:\n",
    "            real = real.to(self.device)\n",
    "            batch_size = real.size(0)\n",
    "            \n",
    "            loss_d, d_real, d_fake = self._train_discriminator(real)\n",
    "            loss_g = self._train_generator(batch_size)\n",
    "            \n",
    "            epoch_metrics[\"loss_d\"] += loss_d\n",
    "            epoch_metrics[\"loss_g\"] += loss_g\n",
    "            epoch_metrics[\"d_real\"] += d_real\n",
    "            epoch_metrics[\"d_fake\"] += d_fake\n",
    "        \n",
    "        for k in epoch_metrics:\n",
    "            epoch_metrics[k] /= num_batches\n",
    "            self.history[k].append(epoch_metrics[k])\n",
    "        \n",
    "        return epoch_metrics\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate_samples(self, num_samples: int = 64) -> Tensor:\n",
    "        self.generator.eval()\n",
    "        z = torch.randn(num_samples, self.config.latent_dim, device=self.device)\n",
    "        return self.generator(z).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(config: DCGANConfig) -> DataLoader:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(config.image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5] * config.nc, [0.5] * config.nc),\n",
    "    ])\n",
    "    dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=config.batch_size, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(samples: Tensor, title: str = \"Generated Samples\") -> None:\n",
    "    grid = make_grid(samples, nrow=8, normalize=True, value_range=(-1, 1))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(grid.permute(1, 2, 0).numpy())\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history: Dict[str, List[float]]) -> None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].plot(history[\"loss_d\"], label=\"Discriminator\", alpha=0.8)\n",
    "    axes[0].plot(history[\"loss_g\"], label=\"Generator\", alpha=0.8)\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"Training Loss\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history[\"d_real\"], label=\"D(real)\", alpha=0.8)\n",
    "    axes[1].plot(history[\"d_fake\"], label=\"D(fake)\", alpha=0.8)\n",
    "    axes[1].axhline(y=0.5, color=\"r\", linestyle=\"--\", label=\"Equilibrium\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Discriminator Output\")\n",
    "    axes[1].set_title(\"Discriminator Confidence\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = DCGANConfig(num_epochs=50, batch_size=128)\n",
    "    dataloader = create_dataloader(config)\n",
    "    trainer = DCGANTrainer(config)\n",
    "    \n",
    "    print(f\"Generator parameters: {sum(p.numel() for p in trainer.generator.parameters()):,}\")\n",
    "    print(f\"Discriminator parameters: {sum(p.numel() for p in trainer.discriminator.parameters()):,}\")\n",
    "    print(f\"Device: {config.device}\")\n",
    "    \n",
    "    for epoch in range(config.num_epochs):\n",
    "        metrics = trainer.train_epoch(dataloader)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{config.num_epochs}] \"\n",
    "                  f\"Loss_D: {metrics['loss_d']:.4f} Loss_G: {metrics['loss_g']:.4f} \"\n",
    "                  f\"D(real): {metrics['d_real']:.3f} D(fake): {metrics['d_fake']:.3f}\")\n",
    "            samples = trainer.generate_samples(64)\n",
    "            visualize_samples(samples, f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    plot_training_curves(trainer.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "DCGAN introduces convolutional architecture to GANs with key design principles:\n",
    "\n",
    "1. **Transposed convolutions** for learned upsampling (generator)\n",
    "2. **Strided convolutions** for learned downsampling (discriminator)\n",
    "3. **BatchNorm** everywhere except G output and D input\n",
    "4. **ReLU** in generator, **LeakyReLU** in discriminator\n",
    "5. **Adam** with $\\beta_1 = 0.5$ for stable adversarial training\n",
    "\n",
    "The convolutional inductive bias enables generation of spatially coherent images\n",
    "at higher resolutions than fully-connected GANs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
