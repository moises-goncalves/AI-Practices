{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# 15.3预测时间序列",
   "id": "32c0c49cb1e960a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T09:52:21.647467Z",
     "start_time": "2025-10-30T09:52:20.496216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras.losses\n",
    "import numpy as np\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    \"\"\"\n",
    "    生成时间序列数据的函数\n",
    "    参数:\n",
    "    batch_size (int): 每次生成的序列数量\n",
    "    n_steps (int): 每个序列的时间步长\n",
    "    返回:\n",
    "    numpy.ndarray: 形状为(batch_size, n_steps, 1)的时间序列数据\n",
    "    \"\"\"\n",
    "    # 生成4个随机数数组，分别用于控制两个正弦波的频率和相位偏移\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    # 创建时间序列，从0到1均匀分布n_steps个点\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    # 生成第一个正弦波，振幅为0.5\n",
    "    # 通过随机频率(freq1*10+10)和相位偏移(offsets1)控制波形\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  # wave 1\n",
    "    # 添加第二个正弦波，振幅为0.2\n",
    "    # 通过不同的随机频率(freq2*20+20)和相位偏移(offsets2)控制波形\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))  # wave 2\n",
    "    # 添加随机噪声，振幅为0.1\n",
    "    # 使用均匀分布生成随机数并减去0.5使其均值为0\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)  # noise\n",
    "    # 调整数组形状并转换为float32类型\n",
    "    return series[..., np.newaxis].astype(np.float32)\n"
   ],
   "id": "1b95f0ccc10c978a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 17:52:20.704235: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-30 17:52:20.710496: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-30 17:52:20.719098: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-30 17:52:20.721547: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-30 17:52:20.727634: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T09:52:27.306816Z",
     "start_time": "2025-10-30T09:52:27.290114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建训练集 验证集 测试集\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train,y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ],
   "id": "6712f52413efa388",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 15.3.1 基准指标",
   "id": "cb797c933f7cdc99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T09:53:32.210722Z",
     "start_time": "2025-10-30T09:53:27.418642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "model.evaluate(X_test, y_test)"
   ],
   "id": "264495ae45f61968",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.0792 - val_loss: 0.0462\n",
      "Epoch 2/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 872us/step - loss: 0.0336 - val_loss: 0.0253\n",
      "Epoch 3/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 960us/step - loss: 0.0199 - val_loss: 0.0163\n",
      "Epoch 4/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 875us/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 5/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 959us/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 6/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 930us/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 7/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 859us/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 8/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 840us/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 9/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 10/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 905us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 11/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 878us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 12/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 894us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 13/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 837us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 14/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 798us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 15/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 830us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 16/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 818us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 17/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 865us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 18/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 835us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 19/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 824us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 20/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 807us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00349472020752728"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 15.3.2 使用RNN",
   "id": "83db58b369dce801"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T09:56:32.966885Z",
     "start_time": "2025-10-30T09:56:10.332825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# 使用RNN\n",
    "# 目标：预测序列的下一个时间步（单值），即 Sequence-to-One 任务\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # 1. SimpleRNN：\n",
    "    #    - 移除 return_sequences=True：让 RNN 只输出最后一个时间步的隐藏状态。\n",
    "    #    - 此时输出形状变为 (None, 50)\n",
    "    keras.layers.SimpleRNN(50, input_shape=[n_steps, 1]),\n",
    "\n",
    "    # 2. Dense 层：\n",
    "    #    - 添加一个 Dense(1) 层，将 50 个神经元压缩为最终的 1 个预测值。\n",
    "    #    - 最终模型输出形状变为 (None, 1)，与 y_train 的形状 (None, 1) 兼容。\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# 现在可以正确运行了\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "model.evaluate(X_test, y_test)"
   ],
   "id": "dc71113acbc586ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - loss: 0.0143 - val_loss: 0.0044\n",
      "Epoch 2/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 3/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 4/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 5/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 6/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 7/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 8/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 9/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 10/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 11/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 12/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 13/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 14/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 15/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 16/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 17/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 18/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 19/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 20/20\n",
      "\u001B[1m219/219\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002343049505725503"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1e0e67fcebf73e0a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
