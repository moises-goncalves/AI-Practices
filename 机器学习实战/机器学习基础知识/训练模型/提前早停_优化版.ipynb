{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æå‰æ—©åœæ­£åˆ™åŒ– (Early Stopping)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "é€šè¿‡æœ¬æ•™ç¨‹ï¼Œä½ å°†å­¦ä¼šï¼š\n",
    "- ç†è§£æ—©åœæ³•çš„åŸç†\n",
    "- æŒæ¡æ—©åœä½œä¸ºæ­£åˆ™åŒ–æŠ€æœ¯çš„ä½œç”¨\n",
    "- å®ç°æ‰‹åŠ¨æ—©åœå’Œä½¿ç”¨å›è°ƒ\n",
    "- ç†è§£éªŒè¯é›†åœ¨æ—©åœä¸­çš„ä½œç”¨\n",
    "\n",
    "## ğŸ“‹ å‰ç½®çŸ¥è¯†\n",
    "\n",
    "- è¿‡æ‹Ÿåˆæ¦‚å¿µ\n",
    "- æ¢¯åº¦ä¸‹é™\n",
    "- è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†åˆ’åˆ†\n",
    "\n",
    "## â±ï¸ é¢„è®¡æ—¶é—´\n",
    "\n",
    "25-30åˆ†é’Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“– ç¬¬1éƒ¨åˆ†ï¼šç†è®ºèƒŒæ™¯\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯æ—©åœï¼Ÿ\n",
    "\n",
    "**æ—©åœï¼ˆEarly Stoppingï¼‰** æ˜¯ä¸€ç§éšå¼æ­£åˆ™åŒ–æŠ€æœ¯ï¼šåœ¨éªŒè¯è¯¯å·®å¼€å§‹å¢åŠ æ—¶åœæ­¢è®­ç»ƒï¼Œè€Œä¸æ˜¯ç­‰åˆ°è®­ç»ƒå®Œæˆã€‚\n",
    "\n",
    "### ä¸ºä»€ä¹ˆæ—©åœæœ‰æ•ˆï¼Ÿ\n",
    "\n",
    "éšç€è®­ç»ƒè¿›è¡Œï¼š\n",
    "1. **åˆæœŸ**ï¼šè®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®éƒ½ä¸‹é™\n",
    "2. **ä¸­æœŸ**ï¼šéªŒè¯è¯¯å·®å¼€å§‹è¶‹äºå¹³ç¨³æˆ–ä¸Šå‡\n",
    "3. **åæœŸ**ï¼šè®­ç»ƒè¯¯å·®ç»§ç»­ä¸‹é™ï¼ŒéªŒè¯è¯¯å·®å¢åŠ ï¼ˆè¿‡æ‹Ÿåˆï¼‰\n",
    "\n",
    "æ—©åœçš„ç›®æ ‡æ˜¯åœ¨\"æ‹ç‚¹\"å¤„åœæ­¢è®­ç»ƒã€‚\n",
    "\n",
    "### æ—©åœ vs å…¶ä»–æ­£åˆ™åŒ–\n",
    "\n",
    "| æ–¹æ³• | æœºåˆ¶ | ä¼˜ç‚¹ |\n",
    "|------|------|------|\n",
    "| L1/L2æ­£åˆ™åŒ– | æƒ©ç½šå¤§å‚æ•° | æ•°å­¦æ€§è´¨å¥½ |\n",
    "| Dropout | éšæœºä¸¢å¼ƒç¥ç»å…ƒ | é€‚åˆæ·±åº¦ç½‘ç»œ |\n",
    "| æ—©åœ | é™åˆ¶è®­ç»ƒæ—¶é—´ | ç®€å•ï¼Œæ— éœ€è°ƒè¶…å‚ |\n",
    "\n",
    "> ğŸ’¡ **å…³é”®æ´å¯Ÿ**: æ—©åœå¯ä»¥çœ‹ä½œæ˜¯å¯¹å‚æ•°ç©ºé—´çš„éšå¼æ­£åˆ™åŒ–â€”â€”å‚æ•°æ²¡æœ‰è¶³å¤Ÿæ—¶é—´èµ°å‘æç«¯å€¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’» ç¬¬2éƒ¨åˆ†ï¼šä»£ç å®ç°\n",
    "\n",
    "### æ­¥éª¤1: å‡†å¤‡å·¥ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# å¯¼å…¥åº“\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone\n",
    "\n",
    "# ============================================================\n",
    "# é…ç½®\n",
    "# ============================================================\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ“ é…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ­¥éª¤2: ç”Ÿæˆæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ç”ŸæˆäºŒæ¬¡å…³ç³»æ•°æ®\n",
    "# ============================================================\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "X = 6 * np.random.rand(n_samples, 1) - 3\n",
    "y = 0.5 * X**2 + X + 2 + np.random.randn(n_samples, 1)\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"âœ“ æ•°æ®ç”Ÿæˆå®Œæˆ\")\n",
    "print(f\"  è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬\")\n",
    "print(f\"  éªŒè¯é›†: {len(X_val)} æ ·æœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ­¥éª¤3: ç‰¹å¾é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# åˆ›å»ºé«˜æ¬¡å¤šé¡¹å¼ç‰¹å¾ï¼ˆå®¹æ˜“è¿‡æ‹Ÿåˆï¼‰\n",
    "# ============================================================\n",
    "\n",
    "POLY_DEGREE = 20  # ä½¿ç”¨20æ¬¡å¤šé¡¹å¼ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ\n",
    "\n",
    "# é¢„å¤„ç†ç®¡é“ï¼šå¤šé¡¹å¼ç‰¹å¾ + æ ‡å‡†åŒ–\n",
    "preprocessor = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=POLY_DEGREE, include_bias=False)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# è½¬æ¢æ•°æ®\n",
    "X_train_poly = preprocessor.fit_transform(X_train)\n",
    "X_val_poly = preprocessor.transform(X_val)\n",
    "\n",
    "print(f\"âœ“ ç‰¹å¾è½¬æ¢å®Œæˆ\")\n",
    "print(f\"  å¤šé¡¹å¼æ¬¡æ•°: {POLY_DEGREE}\")\n",
    "print(f\"  ç‰¹å¾æ•°é‡: {X_train_poly.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ­¥éª¤4: å®ç°æ—©åœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# æ‰‹åŠ¨å®ç°æ—©åœ\n",
    "# ============================================================\n",
    "\n",
    "# åˆ›å»ºSGDå›å½’å™¨\n",
    "# warm_start=True: å…è®¸åœ¨fitä¹‹é—´ä¿æŒæ¨¡å‹çŠ¶æ€\n",
    "# max_iter=1: æ¯æ¬¡fitåªè¿›è¡Œä¸€æ¬¡epoch\n",
    "sgd_reg = SGDRegressor(\n",
    "    learning_rate='constant',\n",
    "    eta0=0.001,\n",
    "    max_iter=1,\n",
    "    warm_start=True,     # å…³é”®ï¼šä¿æŒä¸Šä¸€æ¬¡è®­ç»ƒçš„çŠ¶æ€\n",
    "    penalty=None,        # æ— æ­£åˆ™åŒ–ï¼ˆä¾é æ—©åœï¼‰\n",
    "    random_state=RANDOM_SEED,\n",
    "    tol=None             # ç¦ç”¨è‡ªåŠ¨åœæ­¢\n",
    ")\n",
    "\n",
    "# æ—©åœå‚æ•°\n",
    "n_epochs = 500\n",
    "patience = 20  # å®¹å¿éªŒè¯è¯¯å·®ä¸ä¸‹é™çš„epochæ•°\n",
    "\n",
    "# è®°å½•å†å²\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "\n",
    "# æœ€ä½³æ¨¡å‹è¿½è¸ª\n",
    "minimum_val_error = float('inf')\n",
    "best_epoch = None\n",
    "best_model = None\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(\"å¼€å§‹è®­ç»ƒï¼ˆå¸¦æ—©åœï¼‰...\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # è®­ç»ƒä¸€ä¸ªepoch\n",
    "    sgd_reg.fit(X_train_poly, y_train.ravel())\n",
    "    \n",
    "    # è®¡ç®—è¯¯å·®\n",
    "    y_train_pred = sgd_reg.predict(X_train_poly)\n",
    "    y_val_pred = sgd_reg.predict(X_val_poly)\n",
    "    \n",
    "    train_error = mean_squared_error(y_train, y_train_pred)\n",
    "    val_error = mean_squared_error(y_val, y_val_pred)\n",
    "    \n",
    "    train_errors.append(train_error)\n",
    "    val_errors.append(val_error)\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹\n",
    "    if val_error < minimum_val_error:\n",
    "        minimum_val_error = val_error\n",
    "        best_epoch = epoch\n",
    "        best_model = clone(sgd_reg)\n",
    "        best_model.coef_ = sgd_reg.coef_.copy()\n",
    "        best_model.intercept_ = sgd_reg.intercept_.copy()\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    \n",
    "    # æ—©åœæ£€æŸ¥\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"\\næ—©åœè§¦å‘ï¼åœ¨epoch {epoch}åœæ­¢\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nè®­ç»ƒå®Œæˆ:\")\n",
    "print(f\"  æœ€ä½³epoch: {best_epoch}\")\n",
    "print(f\"  æœ€å°éªŒè¯MSE: {minimum_val_error:.6f}\")\n",
    "print(f\"  æ€»è®­ç»ƒepochs: {len(train_errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š ç¬¬3éƒ¨åˆ†ï¼šå¯è§†åŒ–æ—©åœæ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# å·¦å›¾ï¼šè¯¯å·®æ›²çº¿\n",
    "axes[0].plot(train_errors, 'b-', linewidth=2, label='è®­ç»ƒè¯¯å·®')\n",
    "axes[0].plot(val_errors, 'r-', linewidth=2, label='éªŒè¯è¯¯å·®')\n",
    "axes[0].axvline(x=best_epoch, color='green', linestyle='--', linewidth=2,\n",
    "               label=f'æœ€ä½³åœæ­¢ç‚¹ (epoch={best_epoch})')\n",
    "axes[0].scatter([best_epoch], [minimum_val_error], c='green', s=100, zorder=5)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE')\n",
    "axes[0].set_title('è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯¯å·®å˜åŒ–', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# å³å›¾ï¼šæ‹Ÿåˆæ›²çº¿å¯¹æ¯”\n",
    "X_line = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "X_line_poly = preprocessor.transform(X_line)\n",
    "\n",
    "# æœ€ç»ˆæ¨¡å‹é¢„æµ‹\n",
    "y_final = sgd_reg.predict(X_line_poly)\n",
    "\n",
    "# æœ€ä½³æ¨¡å‹é¢„æµ‹\n",
    "y_best = best_model.predict(X_line_poly)\n",
    "\n",
    "# çœŸå®æ›²çº¿\n",
    "y_true = 0.5 * X_line**2 + X_line + 2\n",
    "\n",
    "axes[1].scatter(X_train, y_train, c='blue', alpha=0.5, s=30, label='è®­ç»ƒæ•°æ®')\n",
    "axes[1].scatter(X_val, y_val, c='red', alpha=0.5, s=30, label='éªŒè¯æ•°æ®')\n",
    "axes[1].plot(X_line, y_true, 'g--', linewidth=2, label='çœŸå®æ›²çº¿')\n",
    "axes[1].plot(X_line, y_best, 'purple', linewidth=2, label=f'æ—©åœæ¨¡å‹ (epoch={best_epoch})')\n",
    "axes[1].plot(X_line, y_final, 'orange', linewidth=2, alpha=0.7, label=f'æœ€ç»ˆæ¨¡å‹ (epoch={len(train_errors)-1})')\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('y')\n",
    "axes[1].set_title('æ—©åœæ¨¡å‹ vs æœ€ç»ˆæ¨¡å‹', fontweight='bold')\n",
    "axes[1].set_ylim(-5, 15)\n",
    "axes[1].legend(loc='upper left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ ç¬¬4éƒ¨åˆ†ï¼šæ—©åœçš„ä¸åŒå®ç°æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# æ—©åœç±»å°è£…\n",
    "# ============================================================\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    æ—©åœç±»\n",
    "    \n",
    "    å‚æ•°:\n",
    "        patience: å®¹å¿éªŒè¯æŸå¤±ä¸ä¸‹é™çš„epochæ•°\n",
    "        min_delta: è®¤ä¸ºæœ‰æ”¹å–„çš„æœ€å°å˜åŒ–é‡\n",
    "        restore_best_weights: æ˜¯å¦æ¢å¤æœ€ä½³æƒé‡\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def __call__(self, val_score, model):\n",
    "        \"\"\"\n",
    "        æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢\n",
    "        \n",
    "        è¿”å›:\n",
    "            True: åº”è¯¥åœæ­¢è®­ç»ƒ\n",
    "            False: ç»§ç»­è®­ç»ƒ\n",
    "        \"\"\"\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "            self._save_weights(model)\n",
    "            return False\n",
    "            \n",
    "        if val_score < self.best_score - self.min_delta:\n",
    "            # æœ‰æ”¹å–„\n",
    "            self.best_score = val_score\n",
    "            self._save_weights(model)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            # æ— æ”¹å–„\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                if self.restore_best_weights:\n",
    "                    self._restore_weights(model)\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def _save_weights(self, model):\n",
    "        self.best_weights = {\n",
    "            'coef': model.coef_.copy(),\n",
    "            'intercept': model.intercept_.copy()\n",
    "        }\n",
    "    \n",
    "    def _restore_weights(self, model):\n",
    "        if self.best_weights:\n",
    "            model.coef_ = self.best_weights['coef']\n",
    "            model.intercept_ = self.best_weights['intercept']\n",
    "\n",
    "print(\"âœ“ EarlyStoppingç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ä½¿ç”¨EarlyStoppingç±»\n",
    "# ============================================================\n",
    "\n",
    "# é‡æ–°åˆ›å»ºæ¨¡å‹\n",
    "sgd_reg2 = SGDRegressor(\n",
    "    learning_rate='constant',\n",
    "    eta0=0.001,\n",
    "    max_iter=1,\n",
    "    warm_start=True,\n",
    "    penalty=None,\n",
    "    random_state=RANDOM_SEED,\n",
    "    tol=None\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20, min_delta=0.001)\n",
    "\n",
    "train_errors2 = []\n",
    "val_errors2 = []\n",
    "\n",
    "for epoch in range(500):\n",
    "    sgd_reg2.fit(X_train_poly, y_train.ravel())\n",
    "    \n",
    "    train_error = mean_squared_error(y_train, sgd_reg2.predict(X_train_poly))\n",
    "    val_error = mean_squared_error(y_val, sgd_reg2.predict(X_val_poly))\n",
    "    \n",
    "    train_errors2.append(train_error)\n",
    "    val_errors2.append(val_error)\n",
    "    \n",
    "    if early_stopping(val_error, sgd_reg2):\n",
    "        print(f\"æ—©åœè§¦å‘åœ¨epoch {epoch}\")\n",
    "        print(f\"æœ€ä½³éªŒè¯MSE: {early_stopping.best_score:.6f}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nä½¿ç”¨EarlyStoppingç±»è®­ç»ƒå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ æ€»ç»“\n",
    "\n",
    "### å…³é”®è¦ç‚¹\n",
    "\n",
    "1. âœ… **æ—©åœ**æ˜¯ä¸€ç§éšå¼æ­£åˆ™åŒ–æŠ€æœ¯\n",
    "2. âœ… åœ¨éªŒè¯è¯¯å·®å¼€å§‹å¢åŠ æ—¶åœæ­¢è®­ç»ƒ\n",
    "3. âœ… **patience**å‚æ•°æ§åˆ¶å®¹å¿åº¦\n",
    "4. âœ… é€šå¸¸è¦ä¿å­˜å¹¶æ¢å¤æœ€ä½³æ¨¡å‹æƒé‡\n",
    "\n",
    "### æ—©åœçš„ä¼˜ç¼ºç‚¹\n",
    "\n",
    "| ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
    "|------|------|\n",
    "| ç®€å•æœ‰æ•ˆ | éœ€è¦éªŒè¯é›† |\n",
    "| æ— éœ€è°ƒæ•´è¶…å‚æ•° | å¯èƒ½è¿‡æ—©åœæ­¢ |\n",
    "| èŠ‚çœè®­ç»ƒæ—¶é—´ | ä¸èƒ½ä¸å…¶ä»–æ­£åˆ™åŒ–å®Œç¾ç»“åˆ |\n",
    "\n",
    "### æœ€ä½³å®è·µ\n",
    "\n",
    "1. ä½¿ç”¨é€‚å½“çš„patienceå€¼ï¼ˆé€šå¸¸10-20ï¼‰\n",
    "2. å§‹ç»ˆä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "3. å¯ä»¥ä¸å…¶ä»–æ­£åˆ™åŒ–æŠ€æœ¯ç»“åˆä½¿ç”¨\n",
    "4. ç›‘æ§è®­ç»ƒæ›²çº¿ä»¥è°ƒæ•´è¶…å‚æ•°\n",
    "\n",
    "### ä¸‹ä¸€æ­¥å­¦ä¹ \n",
    "\n",
    "- ğŸ“˜ æ·±åº¦å­¦ä¹ ä¸­çš„Callbacks\n",
    "- ğŸ“™ æ¨¡å‹é€‰æ‹©å’Œäº¤å‰éªŒè¯\n",
    "- ğŸ“• è¶…å‚æ•°è°ƒä¼˜\n",
    "\n",
    "## ğŸ“š å‚è€ƒèµ„æ–™\n",
    "\n",
    "- ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹ç¬¬4ç« \n",
    "- [TensorFlow: EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
