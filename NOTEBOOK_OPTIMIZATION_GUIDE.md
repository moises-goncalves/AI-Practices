# Notebookä¼˜åŒ–æŒ‡å—

æœ¬æŒ‡å—æä¾›äº†ä¼˜åŒ–ç°æœ‰Jupyter Notebooksçš„è¯¦ç»†æ­¥éª¤å’Œæœ€ä½³å®è·µã€‚

## ğŸ“‹ ç›®å½•

- [ä¼˜åŒ–æ£€æŸ¥æ¸…å•](#ä¼˜åŒ–æ£€æŸ¥æ¸…å•)
- [ç»“æ„ä¼˜åŒ–](#ç»“æ„ä¼˜åŒ–)
- [ä»£ç ä¼˜åŒ–](#ä»£ç ä¼˜åŒ–)
- [æ–‡æ¡£ä¼˜åŒ–](#æ–‡æ¡£ä¼˜åŒ–)
- [å¯è§†åŒ–ä¼˜åŒ–](#å¯è§†åŒ–ä¼˜åŒ–)
- [ç¤ºä¾‹å¯¹æ¯”](#ç¤ºä¾‹å¯¹æ¯”)

## âœ… ä¼˜åŒ–æ£€æŸ¥æ¸…å•

åœ¨ä¼˜åŒ–notebookæ—¶ï¼Œè¯·é€é¡¹æ£€æŸ¥ï¼š

### ç»“æ„å±‚é¢
- [ ] æœ‰æ¸…æ™°çš„æ ‡é¢˜å’Œç®€ä»‹
- [ ] åˆ—å‡ºå­¦ä¹ ç›®æ ‡å’Œå‰ç½®çŸ¥è¯†
- [ ] åŒ…å«ç›®å½•ï¼ˆå¯¹äºé•¿notebookï¼‰
- [ ] æœ‰æ˜ç¡®çš„ç« èŠ‚åˆ’åˆ†
- [ ] ç»“å°¾æœ‰æ€»ç»“å’Œä¸‹ä¸€æ­¥å»ºè®®

### ä»£ç å±‚é¢
- [ ] æ‰€æœ‰å¯¼å…¥è¯­å¥é›†ä¸­åœ¨å¼€å¤´
- [ ] è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
- [ ] ä»£ç æœ‰æ¸…æ™°çš„æ³¨é‡Š
- [ ] ä½¿ç”¨ä»£ç å—åˆ†éš”ç¬¦
- [ ] å˜é‡å‘½åæ¸…æ™°
- [ ] ç§»é™¤è°ƒè¯•ä»£ç å’Œæ— ç”¨import

### æ–‡æ¡£å±‚é¢
- [ ] æ¯ä¸ªä»£ç å—å‰æœ‰è¯´æ˜
- [ ] åŒ…å«ç†è®ºèƒŒæ™¯
- [ ] æœ‰æ•°å­¦å…¬å¼ï¼ˆå¦‚é€‚ç”¨ï¼‰
- [ ] ç»“æœæœ‰åˆ†æå’Œè§£é‡Š
- [ ] åŒ…å«é‡è¦æç¤ºå’Œæ³¨æ„äº‹é¡¹

### å¯è§†åŒ–å±‚é¢
- [ ] å›¾è¡¨æœ‰æ ‡é¢˜
- [ ] åæ ‡è½´æœ‰æ ‡ç­¾
- [ ] ä½¿ç”¨å›¾ä¾‹è¯´æ˜
- [ ] è®¾ç½®åˆé€‚çš„å›¾è¡¨å°ºå¯¸
- [ ] ä½¿ç”¨ç½‘æ ¼çº¿è¾…åŠ©é˜…è¯»
- [ ] é¢œè‰²æ­é…åˆç†

### æ•™å­¦å±‚é¢
- [ ] ç”±æµ…å…¥æ·±çš„å­¦ä¹ é¡ºåº
- [ ] åŒ…å«å®é™…æ¡ˆä¾‹
- [ ] æœ‰ç»ƒä¹ é¢˜æˆ–æ€è€ƒé¢˜
- [ ] æä¾›å‚è€ƒèµ„æ–™é“¾æ¥

## ğŸ—ï¸ ç»“æ„ä¼˜åŒ–

### 1. æ ‡å‡†Notebookç»“æ„

```markdown
# ============================================================
# æ ‡é¢˜ï¼šç®—æ³•/ä¸»é¢˜åç§°
# ============================================================

## ğŸ“š å­¦ä¹ ç›®æ ‡
- ç›®æ ‡1
- ç›®æ ‡2
- ç›®æ ‡3

## ğŸ“‹ å‰ç½®çŸ¥è¯†
- çŸ¥è¯†ç‚¹1
- çŸ¥è¯†ç‚¹2

## â±ï¸ é¢„è®¡æ—¶é—´
XX-XXåˆ†é’Ÿ

## ğŸ“– ç›®å½•ï¼ˆå¯é€‰ï¼Œç”¨äºé•¿notebookï¼‰
1. [ç†è®ºèƒŒæ™¯](#ç†è®ºèƒŒæ™¯)
2. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
3. [æ¨¡å‹å®ç°](#æ¨¡å‹å®ç°)
...

---

## ğŸ“– ç¬¬1éƒ¨åˆ†ï¼šç†è®ºèƒŒæ™¯

### æ¦‚å¿µä»‹ç»
...

### æ•°å­¦åŸç†
$$å…¬å¼$$

### ç®—æ³•æµç¨‹
...

---

## ğŸ’» ç¬¬2éƒ¨åˆ†ï¼šä»£ç å®ç°

### å¯¼å…¥åº“
...

### æ•°æ®å‡†å¤‡
...

### æ¨¡å‹è®­ç»ƒ
...

### ç»“æœè¯„ä¼°
...

---

## ğŸ“ æ€»ç»“

### å…³é”®è¦ç‚¹
- è¦ç‚¹1
- è¦ç‚¹2

### ä¸‹ä¸€æ­¥
- å»ºè®®1
- å»ºè®®2

### ç»ƒä¹ é¢˜
1. é—®é¢˜1
2. é—®é¢˜2

## ğŸ“š å‚è€ƒèµ„æ–™
- [é“¾æ¥1](url)
- [é“¾æ¥2](url)
```

### 2. å•å…ƒæ ¼ç±»å‹ç»„ç»‡

**Markdownå•å…ƒæ ¼ï¼š**
- æ ‡é¢˜å’Œç®€ä»‹
- ç†è®ºè¯´æ˜
- æ­¥éª¤è¯´æ˜
- ç»“æœåˆ†æ
- æ€»ç»“

**ä»£ç å•å…ƒæ ¼ï¼š**
- å¯¼å…¥åº“
- é…ç½®å’Œå¸¸é‡
- å‡½æ•°å®šä¹‰
- æ•°æ®å¤„ç†
- æ¨¡å‹è®­ç»ƒ
- å¯è§†åŒ–

## ğŸ’» ä»£ç ä¼˜åŒ–

### 1. å¯¼å…¥è¯­å¥ä¼˜åŒ–

**ä¼˜åŒ–å‰ï¼š**
```python
import numpy as np
# ä¸­é—´æœ‰å…¶ä»–ä»£ç 
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
```

**ä¼˜åŒ–åï¼š**
```python
# ============================================================
# å¯¼å…¥å¿…è¦çš„åº“
# ============================================================

# æ ‡å‡†åº“
import os
import sys
from pathlib import Path

# æ•°å€¼è®¡ç®—
import numpy as np
import pandas as pd

# å¯è§†åŒ–
import matplotlib.pyplot as plt
import seaborn as sns

# æœºå™¨å­¦ä¹ 
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# æ·±åº¦å­¦ä¹ 
import tensorflow as tf
from tensorflow import keras

# è®¾ç½®
np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['axes.unicode_minus'] = False  # è´Ÿå·æ˜¾ç¤º
%matplotlib inline

print("âœ“ æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ")
```

### 2. é…ç½®é›†ä¸­ç®¡ç†

**ä¼˜åŒ–å‰ï¼š**
```python
# ä»£ç åˆ†æ•£åœ¨å„å¤„
model.fit(X, y, epochs=100)
optimizer = Adam(0.001)
batch_size = 32
```

**ä¼˜åŒ–åï¼š**
```python
# ============================================================
# é…ç½®å‚æ•°
# ============================================================

# è®­ç»ƒå‚æ•°
EPOCHS = 100
BATCH_SIZE = 32
LEARNING_RATE = 0.001
VALIDATION_SPLIT = 0.2

# æ¨¡å‹å‚æ•°
HIDDEN_SIZE = 64
NUM_LAYERS = 3
DROPOUT_RATE = 0.5

# å…¶ä»–é…ç½®
RANDOM_SEED = 42
FIGURE_SIZE = (10, 6)

print("âœ“ é…ç½®åŠ è½½å®Œæˆ")
```

### 3. ä»£ç å—ç»„ç»‡

**ä½¿ç”¨åˆ†éš”ç¬¦ï¼š**
```python
# ============================================================
# æ•°æ®å‡†å¤‡
# ============================================================

# 1. ç”Ÿæˆæ•°æ®
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# 2. åˆ’åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_SEED
)

# 3. æ•°æ®æ ‡å‡†åŒ–
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"âœ“ æ•°æ®å‡†å¤‡å®Œæˆ")
print(f"  è®­ç»ƒé›†: {X_train.shape}")
print(f"  æµ‹è¯•é›†: {X_test.shape}")
```

### 4. å‡½æ•°å°è£…

**ä¼˜åŒ–å‰ï¼š**
```python
# é‡å¤çš„ä»£ç 
plt.figure(figsize=(10, 6))
plt.scatter(X, y)
plt.xlabel('X')
plt.ylabel('y')
plt.title('Data')
plt.show()

# åœ¨å¦ä¸€ä¸ªåœ°æ–¹åˆå†™ä¸€é
plt.figure(figsize=(10, 6))
plt.scatter(X2, y2)
plt.xlabel('X2')
plt.ylabel('y2')
plt.title('Data 2')
plt.show()
```

**ä¼˜åŒ–åï¼š**
```python
def plot_data(X, y, title='Data', xlabel='X', ylabel='y', figsize=(10, 6)):
    """
    ç»˜åˆ¶æ•£ç‚¹å›¾

    å‚æ•°:
        X: ç‰¹å¾æ•°æ®
        y: æ ‡ç­¾æ•°æ®
        title: å›¾è¡¨æ ‡é¢˜
        xlabel: xè½´æ ‡ç­¾
        ylabel: yè½´æ ‡ç­¾
        figsize: å›¾è¡¨å¤§å°
    """
    plt.figure(figsize=figsize)
    plt.scatter(X, y, alpha=0.6, s=50, edgecolors='k', linewidth=0.5)
    plt.xlabel(xlabel, fontsize=12)
    plt.ylabel(ylabel, fontsize=12)
    plt.title(title, fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3, linestyle='--')
    plt.tight_layout()
    plt.show()

# ä½¿ç”¨
plot_data(X, y, title='Training Data')
plot_data(X2, y2, title='Test Data')
```

### 5. è¯¦ç»†æ³¨é‡Š

**ä¼˜åŒ–å‰ï¼š**
```python
X_b = np.c_[np.ones((100, 1)), X]
theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)
```

**ä¼˜åŒ–åï¼š**
```python
# === ä½¿ç”¨æ­£è§„æ–¹ç¨‹æ±‚è§£çº¿æ€§å›å½’ ===

# æ­¥éª¤1: æ·»åŠ åç½®é¡¹ï¼ˆx0 = 1ï¼‰
# å°†åŸå§‹ç‰¹å¾Xæ‰©å±•ä¸º[1, X]çš„å½¢å¼ï¼Œä»¥ä¾¿åŒ…å«æˆªè·é¡¹
X_b = np.c_[np.ones((100, 1)), X]  # shape: (100, 2)

# æ­¥éª¤2: åº”ç”¨æ­£è§„æ–¹ç¨‹è®¡ç®—æœ€ä¼˜å‚æ•°
# å…¬å¼: Î¸ = (X^T * X)^(-1) * X^T * y
# è¿™æ˜¯çº¿æ€§å›å½’çš„è§£æè§£ï¼Œç›´æ¥å¾—åˆ°æœ€ä¼˜å‚æ•°
X_transpose_X = X_b.T.dot(X_b)  # X^T * X
X_transpose_X_inv = np.linalg.inv(X_transpose_X)  # (X^T * X)^(-1)
theta_best = X_transpose_X_inv.dot(X_b.T).dot(y)  # æœ€ç»ˆå‚æ•°

print("âœ“ å‚æ•°è®¡ç®—å®Œæˆ")
print(f"æˆªè· (Î¸0): {theta_best[0][0]:.4f}")
print(f"æ–œç‡ (Î¸1): {theta_best[1][0]:.4f}")
```

## ğŸ“– æ–‡æ¡£ä¼˜åŒ–

### 1. ç†è®ºèƒŒæ™¯

**ä¼˜åŒ–å‰ï¼š**
æ²¡æœ‰ç†è®ºè¯´æ˜ï¼Œç›´æ¥ä¸Šä»£ç 

**ä¼˜åŒ–åï¼š**
```markdown
## ğŸ“– ç†è®ºèƒŒæ™¯

### ä»€ä¹ˆæ˜¯çº¿æ€§å›å½’ï¼Ÿ

çº¿æ€§å›å½’æ˜¯ä¸€ç§ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œç”¨äºå»ºç«‹è¾“å…¥ç‰¹å¾å’Œè¾“å‡ºç›®æ ‡ä¹‹é—´çš„çº¿æ€§å…³ç³»ã€‚å®ƒæ˜¯æœ€ç®€å•ä¹Ÿæ˜¯æœ€å¸¸ç”¨çš„æœºå™¨å­¦ä¹ ç®—æ³•ä¹‹ä¸€ã€‚

### æ•°å­¦æ¨¡å‹

å¯¹äºå•å˜é‡çº¿æ€§å›å½’ï¼Œæ¨¡å‹å¯ä»¥è¡¨ç¤ºä¸ºï¼š

$$h_\theta(x) = \theta_0 + \theta_1 x$$

å…¶ä¸­ï¼š
- $h_\theta(x)$ æ˜¯é¢„æµ‹å€¼
- $\theta_0$ æ˜¯æˆªè·ï¼ˆåç½®ï¼‰
- $\theta_1$ æ˜¯æ–œç‡ï¼ˆæƒé‡ï¼‰
- $x$ æ˜¯è¾“å…¥ç‰¹å¾

### æŸå¤±å‡½æ•°

ä½¿ç”¨å‡æ–¹è¯¯å·®(MSE)ä½œä¸ºæŸå¤±å‡½æ•°ï¼š

$$J(\theta) = \frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})^2$$

å…¶ä¸­ $m$ æ˜¯æ ·æœ¬æ•°é‡ã€‚

### æ±‚è§£æ–¹æ³•

#### 1. æ­£è§„æ–¹ç¨‹æ³•ï¼ˆè§£æè§£ï¼‰

$$\theta = (X^TX)^{-1}X^Ty$$

**ä¼˜ç‚¹ï¼š**
- ä¸€æ­¥åˆ°ä½ï¼Œæ— éœ€è¿­ä»£
- ä¸éœ€è¦é€‰æ‹©å­¦ä¹ ç‡

**ç¼ºç‚¹ï¼š**
- ç‰¹å¾æ•°é‡å¤§æ—¶è®¡ç®—æ…¢ï¼ˆO(nÂ³)ï¼‰
- éœ€è¦è®¡ç®—çŸ©é˜µçš„é€†

#### 2. æ¢¯åº¦ä¸‹é™æ³•ï¼ˆè¿­ä»£ä¼˜åŒ–ï¼‰

$$\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta)$$

**ä¼˜ç‚¹ï¼š**
- ç‰¹å¾æ•°é‡å¤§æ—¶ä¹Ÿèƒ½é«˜æ•ˆè®¡ç®—
- å¯ä»¥åœ¨çº¿å­¦ä¹ 

**ç¼ºç‚¹ï¼š**
- éœ€è¦é€‰æ‹©å­¦ä¹ ç‡
- éœ€è¦å¤šæ¬¡è¿­ä»£
- å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼ˆè™½ç„¶å¯¹äºçº¿æ€§å›å½’è¿™ä¸ªæ˜¯å‡¸ä¼˜åŒ–é—®é¢˜ï¼‰

### é€‚ç”¨åœºæ™¯

çº¿æ€§å›å½’é€‚ç”¨äºï¼š
- ç‰¹å¾å’Œç›®æ ‡ä¹‹é—´æœ‰çº¿æ€§å…³ç³»
- æ•°æ®å™ªå£°æœä»æ­£æ€åˆ†å¸ƒ
- ç‰¹å¾ä¹‹é—´æ— ä¸¥é‡å¤šé‡å…±çº¿æ€§

> ğŸ’¡ **æç¤º**: å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥é€šè¿‡ç‰¹å¾å·¥ç¨‹ï¼ˆå¦‚å¤šé¡¹å¼ç‰¹å¾ï¼‰æ¥æ•è·éçº¿æ€§å…³ç³»ã€‚
```

### 2. ä»£ç è¯´æ˜

**ä¸ºæ¯ä¸ªä»£ç å—æ·»åŠ Markdownè¯´æ˜ï¼š**

```markdown
### æ­¥éª¤1: å¯¼å…¥åº“å’Œè®¾ç½®

é¦–å…ˆå¯¼å…¥éœ€è¦çš„åº“ï¼Œå¹¶è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡å¤ã€‚
```

```python
# ä»£ç 
```

```markdown
### æ­¥éª¤2: ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®

æˆ‘ä»¬ç”Ÿæˆç¬¦åˆçº¿æ€§å…³ç³»çš„æ•°æ®ï¼šy = 4 + 3x + noise

è¿™é‡Œï¼š
- çœŸå®çš„æˆªè·æ˜¯ 4
- çœŸå®çš„æ–œç‡æ˜¯ 3
- æ·»åŠ äº†é«˜æ–¯å™ªå£°æ¨¡æ‹Ÿå®é™…æ•°æ®çš„ä¸ç¡®å®šæ€§
```

```python
# ä»£ç 
```

### 3. ç»“æœåˆ†æ

**ä¼˜åŒ–å‰ï¼š**
åªæœ‰ä»£ç è¾“å‡ºï¼Œæ²¡æœ‰åˆ†æ

**ä¼˜åŒ–åï¼š**
```markdown
### ğŸ“Š ç»“æœåˆ†æ

ä»ä¸Šé¢çš„ç»“æœå¯ä»¥çœ‹åˆ°ï¼š

1. **å‚æ•°ä¼°è®¡å‡†ç¡®æ€§**
   - ä¼°è®¡çš„æˆªè·ä¸º 4.15ï¼Œéå¸¸æ¥è¿‘çœŸå®å€¼ 4.0
   - ä¼°è®¡çš„æ–œç‡ä¸º 2.98ï¼Œéå¸¸æ¥è¿‘çœŸå®å€¼ 3.0
   - è¯¯å·®ä¸»è¦æ¥è‡ªæˆ‘ä»¬æ·»åŠ çš„éšæœºå™ªå£°

2. **æ¨¡å‹æ€§èƒ½**
   - RÂ² åˆ†æ•°ä¸º 0.95ï¼Œè¯´æ˜æ¨¡å‹è§£é‡Šäº†95%çš„æ–¹å·®
   - RMSE ä¸º 0.32ï¼Œè¯¯å·®å¾ˆå°

3. **æ®‹å·®åˆ†æ**
   - æ®‹å·®å›¾æ˜¾ç¤ºæ®‹å·®éšæœºåˆ†å¸ƒåœ¨0é™„è¿‘
   - æ²¡æœ‰æ˜æ˜¾çš„æ¨¡å¼ï¼Œè¯´æ˜çº¿æ€§å‡è®¾åˆç†
   - æ®‹å·®è¿‘ä¼¼æœä»æ­£æ€åˆ†å¸ƒ

> âœ… **ç»“è®º**: æ¨¡å‹æ‹Ÿåˆæ•ˆæœå¾ˆå¥½ï¼Œå‚æ•°ä¼°è®¡å‡†ç¡®ã€‚

> âš ï¸ **æ³¨æ„**: å®é™…æ•°æ®å¯èƒ½ä¸ä¼šè¿™ä¹ˆç†æƒ³ï¼Œéœ€è¦è¿›è¡Œæ›´å¤šè¯Šæ–­æ£€æŸ¥ã€‚
```

### 4. ä½¿ç”¨æç¤ºæ¡†

```markdown
> ğŸ’¡ **æç¤º**: è¿™æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æç¤º

> âš ï¸ **æ³¨æ„**: è¿™éœ€è¦ç‰¹åˆ«æ³¨æ„

> âœ… **æœ€ä½³å®è·µ**: æ¨èçš„åšæ³•

> âŒ **é¿å…**: ä¸æ¨èçš„åšæ³•

> ğŸ“Œ **å…³é”®ç‚¹**: é‡è¦çš„æ¦‚å¿µ

> ğŸ” **æ·±å…¥ç†è§£**: è¿›é˜¶å†…å®¹
```

## ğŸ“Š å¯è§†åŒ–ä¼˜åŒ–

### 1. åŸºç¡€å›¾è¡¨ä¼˜åŒ–

**ä¼˜åŒ–å‰ï¼š**
```python
plt.plot(X, y)
plt.show()
```

**ä¼˜åŒ–åï¼š**
```python
# ============================================================
# æ•°æ®å¯è§†åŒ–
# ============================================================

plt.figure(figsize=(10, 6))

# ç»˜åˆ¶æ•£ç‚¹å›¾
plt.scatter(X, y, alpha=0.6, s=50, edgecolors='k',
            linewidth=0.5, label='æ•°æ®ç‚¹', color='steelblue')

# è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
plt.xlabel('ç‰¹å¾ X', fontsize=12, fontweight='bold')
plt.ylabel('ç›®æ ‡ y', fontsize=12, fontweight='bold')
plt.title('è®­ç»ƒæ•°æ®åˆ†å¸ƒ', fontsize=14, fontweight='bold', pad=15)

# æ·»åŠ ç½‘æ ¼
plt.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)

# æ·»åŠ å›¾ä¾‹
plt.legend(loc='best', frameon=True, shadow=True)

# è°ƒæ•´å¸ƒå±€
plt.tight_layout()
plt.show()

print("âœ“ å¯è§†åŒ–å®Œæˆ")
```

### 2. å¤šå­å›¾å¸ƒå±€

```python
# ============================================================
# å¤šè§’åº¦åˆ†æå¯è§†åŒ–
# ============================================================

fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('çº¿æ€§å›å½’å®Œæ•´åˆ†æ', fontsize=16, fontweight='bold', y=0.995)

# å·¦ä¸Šï¼šåŸå§‹æ•°æ®å’Œæ‹Ÿåˆçº¿
axes[0, 0].scatter(X, y, alpha=0.6, s=50, edgecolors='k',
                   linewidth=0.5, label='æ•°æ®ç‚¹')
axes[0, 0].plot(X_new, y_pred, 'r-', linewidth=2, label='æ‹Ÿåˆçº¿')
axes[0, 0].set_xlabel('X', fontsize=11)
axes[0, 0].set_ylabel('y', fontsize=11)
axes[0, 0].set_title('(a) æ•°æ®å’Œæ‹Ÿåˆç»“æœ', fontsize=12, pad=10)
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# å³ä¸Šï¼šæ®‹å·®å›¾
residuals = y - y_pred
axes[0, 1].scatter(y_pred, residuals, alpha=0.6, s=50,
                   edgecolors='k', linewidth=0.5)
axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)
axes[0, 1].set_xlabel('é¢„æµ‹å€¼', fontsize=11)
axes[0, 1].set_ylabel('æ®‹å·®', fontsize=11)
axes[0, 1].set_title('(b) æ®‹å·®å›¾', fontsize=12, pad=10)
axes[0, 1].grid(True, alpha=0.3)

# å·¦ä¸‹ï¼šæ®‹å·®åˆ†å¸ƒç›´æ–¹å›¾
axes[1, 0].hist(residuals, bins=20, edgecolor='black',
                alpha=0.7, color='steelblue')
axes[1, 0].set_xlabel('æ®‹å·®', fontsize=11)
axes[1, 0].set_ylabel('é¢‘æ•°', fontsize=11)
axes[1, 0].set_title('(c) æ®‹å·®åˆ†å¸ƒ', fontsize=12, pad=10)
axes[1, 0].grid(True, alpha=0.3, axis='y')

# å³ä¸‹ï¼šQQå›¾ï¼ˆæ®‹å·®æ­£æ€æ€§æ£€æŸ¥ï¼‰
from scipy import stats
stats.probplot(residuals.flatten(), dist="norm", plot=axes[1, 1])
axes[1, 1].set_title('(d) QQå›¾ï¼ˆæ­£æ€æ€§æ£€éªŒï¼‰', fontsize=12, pad=10)
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("âœ“ å®Œæ•´åˆ†æå¯è§†åŒ–å®Œæˆ")
```

### 3. è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–

```python
# ============================================================
# è®­ç»ƒå†å²å¯è§†åŒ–
# ============================================================

fig, axes = plt.subplots(1, 2, figsize=(15, 5))

epochs_range = range(1, len(history['loss']) + 1)

# å·¦å›¾ï¼šæŸå¤±æ›²çº¿
axes[0].plot(epochs_range, history['loss'], 'bo-',
             label='è®­ç»ƒæŸå¤±', linewidth=2, markersize=5)
axes[0].plot(epochs_range, history['val_loss'], 'ro-',
             label='éªŒè¯æŸå¤±', linewidth=2, markersize=5)
axes[0].set_xlabel('Epoch', fontsize=12)
axes[0].set_ylabel('Loss', fontsize=12)
axes[0].set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±', fontsize=14, fontweight='bold')
axes[0].legend(loc='best')
axes[0].grid(True, alpha=0.3)

# å³å›¾ï¼šå‡†ç¡®ç‡æ›²çº¿
axes[1].plot(epochs_range, history['accuracy'], 'bo-',
             label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2, markersize=5)
axes[1].plot(epochs_range, history['val_accuracy'], 'ro-',
             label='éªŒè¯å‡†ç¡®ç‡', linewidth=2, markersize=5)
axes[1].set_xlabel('Epoch', fontsize=12)
axes[1].set_ylabel('Accuracy', fontsize=12)
axes[1].set_title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡', fontsize=14, fontweight='bold')
axes[1].legend(loc='best')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# æ‰“å°æœ€ä½³ç»“æœ
best_epoch = np.argmax(history['val_accuracy']) + 1
print(f"\nâœ“ æœ€ä½³Epoch: {best_epoch}")
print(f"  è®­ç»ƒå‡†ç¡®ç‡: {history['accuracy'][best_epoch-1]:.4f}")
print(f"  éªŒè¯å‡†ç¡®ç‡: {history['val_accuracy'][best_epoch-1]:.4f}")
```

## ğŸ“ ç¤ºä¾‹å¯¹æ¯”

### å®Œæ•´çš„ä¼˜åŒ–å‰åå¯¹æ¯”

#### ä¼˜åŒ–å‰

```python
import numpy as np
X = 2 + np.random.rand(100, 1)
y = 4 + 3 * X + np.random.rand(100, 1)
X_b = np.c_[np.ones((100, 1)), X]
theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)
print(theta_best)
```

#### ä¼˜åŒ–å

```markdown
# çº¿æ€§å›å½’ï¼šæ­£è§„æ–¹ç¨‹æ³•

## ğŸ“š å­¦ä¹ ç›®æ ‡

- ç†è§£çº¿æ€§å›å½’çš„æ•°å­¦åŸç†
- æŒæ¡æ­£è§„æ–¹ç¨‹æ³•æ±‚è§£çº¿æ€§å›å½’
- å­¦ä¼šä½¿ç”¨NumPyå®ç°çº¿æ€§å›å½’
- äº†è§£æ¨¡å‹è¯„ä¼°æ–¹æ³•

## ğŸ“‹ å‰ç½®çŸ¥è¯†

- PythonåŸºç¡€
- NumPyåŸºæœ¬æ“ä½œ
- çº¿æ€§ä»£æ•°åŸºç¡€ï¼ˆçŸ©é˜µä¹˜æ³•ã€çŸ©é˜µçš„é€†ï¼‰

## â±ï¸ é¢„è®¡æ—¶é—´

20-30åˆ†é’Ÿ

---

## ğŸ“– ç¬¬1éƒ¨åˆ†ï¼šç†è®ºèƒŒæ™¯

### ä»€ä¹ˆæ˜¯çº¿æ€§å›å½’ï¼Ÿ

çº¿æ€§å›å½’æ˜¯ä¸€ç§ç›‘ç£å­¦ä¹ ç®—æ³•...
ï¼ˆè¯¦ç»†çš„ç†è®ºè¯´æ˜ï¼‰

### æ•°å­¦å…¬å¼

$$y = \theta_0 + \theta_1 x$$

### æ­£è§„æ–¹ç¨‹

$$\theta = (X^TX)^{-1}X^Ty$$

---

## ğŸ’» ç¬¬2éƒ¨åˆ†ï¼šä»£ç å®ç°
```

```python
# ============================================================
# å¯¼å…¥å¿…è¦çš„åº“
# ============================================================

import numpy as np
import matplotlib.pyplot as plt

# è®¾ç½®
np.random.seed(42)
plt.rcParams['font.sans-serif'] = ['SimHei']
%matplotlib inline

print("âœ“ åº“å¯¼å…¥æˆåŠŸ")
```

```markdown
### æ­¥éª¤1: ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®

æˆ‘ä»¬ç”Ÿæˆç¬¦åˆçº¿æ€§å…³ç³» y = 4 + 3x + noise çš„æ•°æ®ï¼š
```

```python
# ============================================================
# æ•°æ®ç”Ÿæˆ
# ============================================================

# ç”Ÿæˆ100ä¸ªæ ·æœ¬çš„è®­ç»ƒæ•°æ®
n_samples = 100
X = 2 * np.random.rand(n_samples, 1)  # ç‰¹å¾Xï¼ŒèŒƒå›´[0, 2]
y = 4 + 3 * X + 0.5 * np.random.randn(n_samples, 1)  # y = 4 + 3x + å™ªå£°

print(f"âœ“ æ•°æ®ç”Ÿæˆå®Œæˆ")
print(f"  æ ·æœ¬æ•°é‡: {n_samples}")
print(f"  Xå½¢çŠ¶: {X.shape}")
print(f"  yå½¢çŠ¶: {y.shape}")
print(f"  XèŒƒå›´: [{X.min():.2f}, {X.max():.2f}]")
print(f"  yèŒƒå›´: [{y.min():.2f}, {y.max():.2f}]")
```

```markdown
### æ­¥éª¤2: æ•°æ®å¯è§†åŒ–

è®©æˆ‘ä»¬å…ˆçœ‹çœ‹æ•°æ®çš„åˆ†å¸ƒï¼š
```

```python
# ============================================================
# æ•°æ®å¯è§†åŒ–
# ============================================================

plt.figure(figsize=(10, 6))
plt.scatter(X, y, alpha=0.6, s=50, edgecolors='k', linewidth=0.5)
plt.xlabel('X', fontsize=12)
plt.ylabel('y', fontsize=12)
plt.title('è®­ç»ƒæ•°æ®åˆ†å¸ƒ', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

```markdown
### æ­¥éª¤3: ä½¿ç”¨æ­£è§„æ–¹ç¨‹æ±‚è§£

åº”ç”¨æ­£è§„æ–¹ç¨‹ Î¸ = (X^T X)^(-1) X^T y è®¡ç®—æœ€ä¼˜å‚æ•°ï¼š
```

```python
# ============================================================
# æ­£è§„æ–¹ç¨‹æ±‚è§£
# ============================================================

# 1. æ·»åŠ åç½®é¡¹ x0 = 1
X_b = np.c_[np.ones((n_samples, 1)), X]

# 2. è®¡ç®— (X^T X)
X_transpose_X = X_b.T.dot(X_b)

# 3. è®¡ç®— (X^T X)^(-1)
X_transpose_X_inv = np.linalg.inv(X_transpose_X)

# 4. è®¡ç®— Î¸ = (X^T X)^(-1) X^T y
theta_best = X_transpose_X_inv.dot(X_b.T).dot(y)

print("âœ“ å‚æ•°è®¡ç®—å®Œæˆ\n")
print(f"ä¼°è®¡çš„å‚æ•°ï¼š")
print(f"  æˆªè· (Î¸0): {theta_best[0][0]:.4f}  (çœŸå®å€¼: 4.0)")
print(f"  æ–œç‡ (Î¸1): {theta_best[1][0]:.4f}  (çœŸå®å€¼: 3.0)")
```

...ï¼ˆç»§ç»­å®Œå–„å…¶ä»–éƒ¨åˆ†ï¼‰

## æ€»ç»“éƒ¨åˆ†ç­‰

## ğŸ¯ ä¼˜åŒ–ä¼˜å…ˆçº§

### é«˜ä¼˜å…ˆçº§ï¼ˆå¿…é¡»å®Œæˆï¼‰
1. æ·»åŠ æ¸…æ™°çš„æ ‡é¢˜å’Œç®€ä»‹
2. è¡¥å……å…³é”®ä»£ç æ³¨é‡Š
3. æ·»åŠ ç»“æœåˆ†æè¯´æ˜
4. ä¼˜åŒ–å¯è§†åŒ–æ•ˆæœ

### ä¸­ä¼˜å…ˆçº§ï¼ˆæ¨èå®Œæˆï¼‰
5. æ·»åŠ ç†è®ºèƒŒæ™¯
6. å‡½æ•°å°è£…å’Œä»£ç é‡æ„
7. æ·»åŠ æ€»ç»“å’Œç»ƒä¹ é¢˜
8. ç»Ÿä¸€ä»£ç é£æ ¼

### ä½ä¼˜å…ˆçº§ï¼ˆå¯é€‰å®Œæˆï¼‰
9. æ·»åŠ äº¤äº’å¼å¯è§†åŒ–
10. æ€§èƒ½ä¼˜åŒ–
11. æ·»åŠ é«˜çº§ä¸»é¢˜é“¾æ¥

## ğŸ”§ å®ç”¨å·¥å…·

### Jupyteræ‰©å±•æ¨è

```bash
# å®‰è£…Jupyteræ‰©å±•
pip install jupyter_contrib_nbextensions
jupyter contrib nbextension install --user

# æ¨èæ‰©å±•ï¼š
# - Table of Contents (TOC2) - è‡ªåŠ¨ç”Ÿæˆç›®å½•
# - Variable Inspector - å˜é‡æŸ¥çœ‹å™¨
# - ExecuteTime - æ˜¾ç¤ºå•å…ƒæ ¼æ‰§è¡Œæ—¶é—´
# - Code folding - ä»£ç æŠ˜å 
```

### ä»£ç æ ¼å¼åŒ–

```bash
# å®‰è£…blackæ ¼å¼åŒ–å·¥å…·
pip install black jupyter-black

# åœ¨notebookä¸­ä½¿ç”¨
%load_ext jupyter_black
```

## ğŸ“š å‚è€ƒèµ„æº

- [Jupyter Notebookæœ€ä½³å®è·µ](https://jupyter-notebook.readthedocs.io/)
- [æ•°æ®ç§‘å­¦NotebookæŒ‡å—](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)
- [ç§‘å­¦Pythonå¯è§†åŒ–](https://matplotlib.org/stable/tutorials/index.html)

---

éµå¾ªæœ¬æŒ‡å—å°†å¤§å¤§æé«˜Notebookçš„è´¨é‡å’Œå¯è¯»æ€§ï¼

[è¿”å›ä¸»é¡µ](README.md) | [ä»£ç è§„èŒƒ](CODE_STYLE.md)
