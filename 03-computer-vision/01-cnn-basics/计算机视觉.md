# 计算机视觉与卷积神经网络

## 概述

计算机视觉是深度学习最成功的应用领域之一。本文档系统总结CNN的核心概念、经典架构演进及实践要点。

**核心问题**：传统全连接网络处理图像时存在两个根本缺陷：
1. 参数爆炸：100×100图像需要10000个输入神经元
2. 空间关系丢失：相邻像素与远距离像素被同等对待

CNN通过**卷积层**和**池化层**解决了这两个问题。

---

## 卷积层

### 基本原理

卷积层的核心思想是**参数共享**和**局部连接**：
- 参数共享：同一滤波器扫描整张图像，权重共享
- 局部连接：每个神经元只与输入的局部区域连接

### 滤波器（卷积核）

滤波器是可学习的特征检测器：
- 浅层：检测边缘、角点、颜色斑块等低级特征
- 深层：组合低级特征形成高级语义（眼睛、轮子等）

**关键参数**：
| 参数 | 说明 | 常用值 |
|-----|------|--------|
| filters | 滤波器数量 | 32, 64, 128, 256 |
| kernel_size | 滤波器大小 | 3×3（最常用） |
| strides | 步幅 | 1 |
| padding | 填充方式 | 'same'（保持尺寸） |

### Keras实现

```python
from tensorflow.keras.layers import Conv2D

Conv2D(
    filters=32,         # 32个滤波器
    kernel_size=3,      # 3×3卷积核
    strides=1,          # 步幅1
    padding='same',     # 零填充保持尺寸
    activation='relu'   # ReLU激活
)
```

**padding选择**：
- `'same'`：大多数情况使用，保持空间维度
- `'valid'`：仅在明确需要缩小尺寸时使用

### 内存需求

CNN训练时需存储所有层的激活值用于反向传播，内存与batch_size和图像分辨率直接相关。OOM时首先减小batch_size。

---

## 池化层

### 作用

1. **下采样**：减少特征图尺寸，降低计算量
2. **平移不变性**：特征小幅移动不影响输出
3. **扩大感受野**：后续层能看到更大范围

### 最大池化 vs 平均池化

| 类型 | 操作 | 特点 | 适用场景 |
|-----|------|------|----------|
| MaxPooling | 取窗口最大值 | 保留最强特征 | 大多数分类任务 |
| AvgPooling | 取窗口均值 | 保留平均响应 | 需要平滑输出 |

### 全局平均池化（GAP）

替代传统Flatten+Dense的现代做法：

```python
# 传统方式: 参数量巨大
model.add(Flatten())        # 7×7×512 = 25088维
model.add(Dense(1000))      # 2500万参数

# GAP方式: 参数极少
model.add(GlobalAveragePooling2D())  # 512维
model.add(Dense(1000))               # 51.2万参数
```

GAP优势：
- 大幅减少参数
- 强正则化效果
- 强化特征图与类别的联系

---

## 经典CNN架构

### LeNet-5 (1998)

奠定CNN基本范式：Conv→Pool→Conv→Pool→FC

特点：使用tanh和AvgPool，现已过时，仅用于教学。

### AlexNet (2012)

引爆深度学习革命，关键贡献：
- 首次大规模使用ReLU
- 引入Dropout
- 数据增强成为标配
- GPU训练

局部响应归一化（LRN）已被BatchNorm取代。

### VGGNet (2014)

设计哲学：极度规整
- 只用3×3卷积
- 只用2×2最大池化

**为什么只用3×3**：两个3×3卷积的感受野等于一个5×5，但参数更少（18 vs 25），非线性更强。

缺点：全连接层参数量巨大（>500MB）。

### GoogLeNet/Inception (2014)

核心创新：**Inception模块**
- 并行使用1×1、3×3、5×5卷积和池化
- 输出在通道维度拼接

**1×1卷积（瓶颈层）的关键作用**：
- 降低通道数，减少计算量
- 跨通道特征学习
- 计算量减少一个数量级

### ResNet (2015)

**革命性贡献**：解决深度网络退化问题

**残差学习**：
```
y = F(x) + x
```
- F(x)：主路径学习残差
- x：跳跃连接直接传递输入

为什么有效：
- 恒等映射只需将F(x)权重学成0
- 梯度可通过跳跃连接直接回传

实现：
```python
input_tensor = x
x = Conv2D(64, 3, padding='same', activation='relu')(x)
x = Conv2D(64, 3, padding='same')(x)  # 相加前不激活
x = Add()([x, input_tensor])
x = Activation('relu')(x)  # 相加后激活
```

### Xception (2017)

**深度可分离卷积**：将空间卷积和通道卷积分离

1. 深度卷积：每个通道单独用3×3滤波器
2. 逐点卷积：1×1卷积混合通道信息

优势：计算量和参数量远小于标准卷积。

```python
keras.layers.SeparableConv2D(...)
```

### SENet (2017)

**通道注意力机制**：让网络学会关注重要通道

SE模块三步：
1. Squeeze：GAP压缩空间维度
2. Excitation：两个FC层学习通道权重
3. Rescale：权重乘回原特征图

可即插即用到任何架构（SE-ResNet, SE-Xception）。

---

## 使用预训练模型

### Keras Applications

```python
from tensorflow.keras.applications import ResNet50

# 完整模型（1000类分类）
model = ResNet50(weights='imagenet', include_top=True)

# 特征提取器
base = ResNet50(weights='imagenet', include_top=False)
```

### 迁移学习流程

**第一阶段：训练分类头**
```python
base_model.trainable = False
model.compile(optimizer=Adam(lr=1e-3), ...)
model.fit(...)
```

**第二阶段：微调**
```python
base_model.trainable = True
# 冻结前N层
for layer in base_model.layers[:100]:
    layer.trainable = False
# 使用更低学习率
model.compile(optimizer=Adam(lr=1e-5), ...)
model.fit(...)
```

**关键点**：
- 必须先冻结基础模型，否则随机初始化的分类头会破坏预训练权重
- 微调学习率需比初始训练低10-100倍

---

## 分类与定位

同时输出类别和边界框，需要多输出模型：

```python
# 分类头
class_output = Dense(num_classes, activation='softmax', name='class')(x)
# 定位头（回归）
bbox_output = Dense(4, activation='sigmoid', name='bbox')(x)

model = Model(inputs, [class_output, bbox_output])
model.compile(
    loss={'class': 'categorical_crossentropy', 'bbox': 'mse'},
    loss_weights={'class': 1.0, 'bbox': 10.0}
)
```

评估指标：IoU（交并比）

---

## 目标检测

### 全卷积网络（FCN）

将Dense层替换为Conv层实现"高效滑动窗口"：一次前向传播获得所有位置的预测。

### YOLO

**核心思想**：将检测视为单一回归问题

1. 图像划分为S×S网格
2. 物体中心所在网格负责预测该物体
3. 每个网格预测B个边界框和C个类别概率
4. 输出张量：S×S×(B×5 + C)

**YOLOv3改进**：引入锚框（Anchor Box）稳定训练

### 评估指标：mAP

1. 设定IoU阈值（如0.5）判定TP/FP
2. 计算每个类别的Precision-Recall曲线
3. 计算曲线下面积（AP）
4. mAP = 所有类别AP的平均值

---

## 语义分割

**目标**：为每个像素分配类别标签

### Encoder-Decoder架构

- Encoder：下采样提取特征（VGG/ResNet）
- Decoder：上采样恢复分辨率

### 上采样方法

1. **双线性插值**：简单，不可学习
2. **转置卷积**：可学习的上采样

```python
Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same')
```

### U-Net跳跃连接

将Encoder对应层特征拼接到Decoder，同时保留：
- 深层的语义信息
- 浅层的空间细节

---

## 实践建议

### 模型选择

| 场景 | 推荐 |
|-----|------|
| 最高精度 | EfficientNetB7 |
| 平衡精度/速度 | ResNet50, EfficientNetB0 |
| 移动端 | MobileNetV2/V3 |
| 迁移学习基础 | ResNet50, VGG16 |

### 常用技巧

1. 使用3×3卷积堆叠替代大卷积核
2. 网络加深时增加滤波器数量
3. 使用BatchNorm加速训练
4. GAP替代Flatten+Dense
5. 数据增强防止过拟合

### 调试清单

- OOM：减小batch_size
- 过拟合：增加数据增强、Dropout
- 训练不稳定：检查学习率、使用BatchNorm
- 收敛慢：使用预训练权重
