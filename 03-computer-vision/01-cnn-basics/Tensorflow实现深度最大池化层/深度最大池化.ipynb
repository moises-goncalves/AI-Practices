{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 深度池化：沿通道维度的池化操作\n",
    "\n",
    "传统池化（MaxPool2D, AvgPool2D）在空间维度(H, W)上进行下采样。\n",
    "**深度池化**则是沿通道维度(C)进行池化，用于：\n",
    "\n",
    "1. **降低通道数** - 减少特征图的深度\n",
    "2. **特征融合** - 将相邻通道的特征进行聚合\n",
    "3. **学习通道间的不变性** - 类似于空间池化学习平移不变性\n",
    "\n",
    "本教程涵盖：\n",
    "- 深度最大池化的原理与实现\n",
    "- 使用Lambda层封装为Keras层\n",
    "- 全局平均池化的等效实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "## 第一部分：理解深度池化\n",
    "\n",
    "### 1.1 深度池化 vs 空间池化\n",
    "\n",
    "| 池化类型 | 操作维度 | 输入形状 | 输出形状 |\n",
    "|---------|---------|---------|----------|\n",
    "| 空间池化 (2x2) | H, W | (B, H, W, C) | (B, H/2, W/2, C) |\n",
    "| 深度池化 (ksize=3) | C | (B, H, W, C) | (B, H, W, C/3) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载示例图像\n",
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "# 加载RGB图像并归一化\n",
    "china = load_sample_image(\"china.jpg\") / 255.0\n",
    "flower = load_sample_image(\"flower.jpg\") / 255.0\n",
    "\n",
    "# 构建批次数据\n",
    "images = np.array([china, flower], dtype=np.float32)\n",
    "batch_size, height, width, channels = images.shape\n",
    "\n",
    "print(f\"输入图像形状: {images.shape}\")\n",
    "print(f\"批次大小: {batch_size}\")\n",
    "print(f\"空间尺寸: {height}x{width}\")\n",
    "print(f\"通道数: {channels} (RGB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "### 1.2 使用tf.nn.max_pool实现深度池化\n",
    "\n",
    "`tf.nn.max_pool`的`ksize`参数可以指定四个维度的池化窗口大小：\n",
    "- `ksize = (batch, height, width, channels)`\n",
    "- 深度池化设置: `ksize = (1, 1, 1, depth_factor)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度最大池化实现\n",
    "# ksize=(1,1,1,3) 表示在通道维度上每3个通道取最大值\n",
    "# strides=(1,1,1,3) 表示通道维度步幅为3，窗口不重叠\n",
    "\n",
    "# 注意：深度池化目前只能在CPU上运行\n",
    "with tf.device('/CPU:0'):\n",
    "    depth_pooled = tf.nn.max_pool(\n",
    "        input=images,\n",
    "        ksize=(1, 1, 1, 3),      # 在通道维度上池化窗口大小为3\n",
    "        strides=(1, 1, 1, 3),    # 通道维度步幅为3\n",
    "        padding='SAME'\n",
    "    )\n",
    "\n",
    "print(f\"输入形状: {images.shape}\")\n",
    "print(f\"深度池化后形状: {depth_pooled.shape}\")\n",
    "print(f\"通道数从 {images.shape[-1]} 降为 {depth_pooled.shape[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 理解深度池化的计算过程\n",
    "# 对于RGB图像，每个像素有3个通道值\n",
    "# 深度池化(ksize=3)会将R,G,B三个值取最大，输出单通道\n",
    "\n",
    "# 手动验证\n",
    "sample_pixel = images[0, 100, 200, :]  # 取一个像素的RGB值\n",
    "pooled_pixel = depth_pooled[0, 100, 200, 0]  # 对应的池化结果\n",
    "\n",
    "print(f\"原始RGB值: R={sample_pixel[0]:.4f}, G={sample_pixel[1]:.4f}, B={sample_pixel[2]:.4f}\")\n",
    "print(f\"max(R,G,B) = {np.max(sample_pixel):.4f}\")\n",
    "print(f\"深度池化结果: {pooled_pixel:.4f}\")\n",
    "print(f\"验证: {'通过' if np.abs(np.max(sample_pixel) - pooled_pixel) < 1e-6 else '失败'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化深度池化效果\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 原始彩色图像\n",
    "axes[0, 0].imshow(images[0])\n",
    "axes[0, 0].set_title('原始RGB图像')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# 深度池化结果（单通道，显示为灰度）\n",
    "axes[0, 1].imshow(depth_pooled[0, :, :, 0], cmap='gray')\n",
    "axes[0, 1].set_title('深度池化结果\\n(max across R,G,B)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# 花朵图像\n",
    "axes[1, 0].imshow(images[1])\n",
    "axes[1, 0].set_title('原始RGB图像')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(depth_pooled[1, :, :, 0], cmap='gray')\n",
    "axes[1, 1].set_title('深度池化结果\\n(max across R,G,B)')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f5",
   "metadata": {},
   "source": [
    "## 第二部分：封装为Keras层\n",
    "\n",
    "### 2.1 使用Lambda层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_depth_max_pool_layer(depth_factor=3):\n",
    "    \"\"\"\n",
    "    创建深度最大池化层\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    depth_factor : int\n",
    "        通道维度的池化窗口大小，输出通道数 = 输入通道数 / depth_factor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    keras.layers.Lambda\n",
    "        可用于Sequential或Functional API的深度池化层\n",
    "    \"\"\"\n",
    "    return keras.layers.Lambda(\n",
    "        lambda X: tf.nn.max_pool(\n",
    "            X,\n",
    "            ksize=(1, 1, 1, depth_factor),\n",
    "            strides=(1, 1, 1, depth_factor),\n",
    "            padding='SAME'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 测试\n",
    "depth_pool_layer = create_depth_max_pool_layer(depth_factor=3)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    layer_output = depth_pool_layer(images)\n",
    "    \n",
    "print(f\"Lambda层深度池化输出形状: {layer_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3a4b5",
   "metadata": {},
   "source": [
    "### 2.2 自定义Layer类（更灵活的实现）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthMaxPooling2D(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    深度最大池化层 - 沿通道维度进行最大池化\n",
    "    \n",
    "    与空间池化不同，此层在通道(深度)维度上进行下采样，\n",
    "    可用于降低特征图的通道数同时保留最显著的特征。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pool_size : int\n",
    "        沿通道维度的池化窗口大小\n",
    "    strides : int, optional\n",
    "        沿通道维度的步幅，默认等于pool_size\n",
    "    padding : str\n",
    "        填充方式，'SAME'或'VALID'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pool_size=3, strides=None, padding='SAME', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides if strides is not None else pool_size\n",
    "        self.padding = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.max_pool(\n",
    "            inputs,\n",
    "            ksize=(1, 1, 1, self.pool_size),\n",
    "            strides=(1, 1, 1, self.strides),\n",
    "            padding=self.padding\n",
    "        )\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        batch, h, w, c = input_shape\n",
    "        if self.padding == 'SAME':\n",
    "            new_c = int(np.ceil(c / self.strides))\n",
    "        else:\n",
    "            new_c = int(np.ceil((c - self.pool_size + 1) / self.strides))\n",
    "        return (batch, h, w, new_c)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'pool_size': self.pool_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# 测试自定义层\n",
    "custom_depth_pool = DepthMaxPooling2D(pool_size=3)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    custom_output = custom_depth_pool(images)\n",
    "    \n",
    "print(f\"自定义层深度池化输出形状: {custom_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "## 第三部分：全局平均池化的等效实现\n",
    "\n",
    "全局平均池化可以使用`tf.reduce_mean`实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟CNN特征图输出\n",
    "feature_maps = np.random.randn(2, 7, 7, 256).astype(np.float32)\n",
    "print(f\"模拟特征图形状: {feature_maps.shape}\")\n",
    "\n",
    "# 方法1: 使用Keras内置层\n",
    "keras_gap = keras.layers.GlobalAveragePooling2D()\n",
    "gap_keras = keras_gap(feature_maps)\n",
    "\n",
    "# 方法2: 使用tf.reduce_mean\n",
    "gap_manual = tf.reduce_mean(feature_maps, axis=[1, 2])\n",
    "\n",
    "# 方法3: 使用Lambda层封装\n",
    "gap_lambda = keras.layers.Lambda(\n",
    "    lambda X: tf.reduce_mean(X, axis=[1, 2])\n",
    ")\n",
    "gap_lambda_output = gap_lambda(feature_maps)\n",
    "\n",
    "print(f\"\\nKeras GlobalAveragePooling2D 输出形状: {gap_keras.shape}\")\n",
    "print(f\"tf.reduce_mean 输出形状: {gap_manual.shape}\")\n",
    "print(f\"Lambda层 输出形状: {gap_lambda_output.shape}\")\n",
    "\n",
    "# 验证结果一致性\n",
    "diff = np.max(np.abs(gap_keras.numpy() - gap_manual.numpy()))\n",
    "print(f\"\\n结果差异: {diff:.2e} (应为0或极小)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## 第四部分：在网络中应用深度池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_depth_pooling():\n",
    "    \"\"\"\n",
    "    构建包含深度池化的CNN模型\n",
    "    \n",
    "    深度池化用于降低中间层的通道数，减少计算量\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # 输入层\n",
    "        keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "        \n",
    "        # 第一卷积块: 1 -> 32通道\n",
    "        keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        keras.layers.MaxPooling2D(2),  # 空间池化: 28->14\n",
    "        \n",
    "        # 第二卷积块: 32 -> 64通道\n",
    "        keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        # 深度池化: 64 -> 32通道\n",
    "        keras.layers.Lambda(\n",
    "            lambda x: tf.nn.max_pool(x, ksize=(1,1,1,2), strides=(1,1,1,2), padding='SAME')\n",
    "        ),\n",
    "        keras.layers.MaxPooling2D(2),  # 空间池化: 14->7\n",
    "        \n",
    "        # 第三卷积块\n",
    "        keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        \n",
    "        # 分类头\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 构建并查看模型\n",
    "model = build_model_with_depth_pooling()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证模型可以正常运行\n",
    "(X_train, y_train), _ = keras.datasets.fashion_mnist.load_data()\n",
    "X_train = X_train[:500].reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train = y_train[:500]\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"验证模型训练...\")\n",
    "with tf.device('/CPU:0'):  # 深度池化需要在CPU上运行\n",
    "    history = model.fit(X_train, y_train, epochs=2, batch_size=32, verbose=1)\n",
    "    \n",
    "print(\"模型训练验证完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4b5c6",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 深度池化的特点\n",
    "\n",
    "| 特性 | 说明 |\n",
    "|-----|------|\n",
    "| 操作维度 | 通道维度(C)而非空间维度(H,W) |\n",
    "| 主要作用 | 降低特征图深度，融合相邻通道特征 |\n",
    "| 硬件限制 | 目前仅支持CPU运算 |\n",
    "| 实现方式 | `tf.nn.max_pool`配合特定ksize参数 |\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "1. 需要在保持空间分辨率的同时降低通道数\n",
    "2. 希望学习通道间的不变性表示\n",
    "3. 特征融合和通道压缩\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 深度池化目前仅支持CPU运算，可能影响训练速度\n",
    "- 输入通道数应能被pool_size整除（或使用SAME填充）\n",
    "- 实际应用中1x1卷积(瓶颈层)是更常用的通道降维方法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
