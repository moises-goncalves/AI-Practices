{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# ResNet-34 残差网络实现\n",
    "\n",
    "ResNet（Residual Network）是深度学习历史上最重要的架构之一，解决了深度网络的退化问题。\n",
    "\n",
    "## 核心创新：残差学习\n",
    "\n",
    "传统深度网络随着层数增加，训练误差反而上升（退化问题）。\n",
    "ResNet通过**跳跃连接（Skip Connection）**让网络学习残差映射：\n",
    "\n",
    "$$F(x) = H(x) - x$$\n",
    "\n",
    "最终输出：$y = F(x) + x$\n",
    "\n",
    "本教程涵盖：\n",
    "- 残差块（Residual Block）的原理与实现\n",
    "- ResNet-34完整架构构建\n",
    "- 使用Fashion MNIST进行训练验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")\n",
    "print(f\"GPU可用: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "## 第一部分：残差块实现\n",
    "\n",
    "### 1.1 基础残差块（Basic Block）\n",
    "\n",
    "ResNet-34使用基础残差块，结构为：\n",
    "```\n",
    "输入 ─────────────────────────────┐\n",
    "  │                               │\n",
    "  ├─→ Conv3x3 → BN → ReLU        │\n",
    "  │                               │\n",
    "  ├─→ Conv3x3 → BN               │\n",
    "  │                               │\n",
    "  └─→ Add ←───────────────────────┘\n",
    "       │\n",
    "       └─→ ReLU → 输出\n",
    "```\n",
    "\n",
    "当输入输出维度不同时，需要对跳跃连接进行投影变换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    残差单元（Residual Unit）\n",
    "    \n",
    "    实现ResNet的基础残差块，包含两个3x3卷积层和一个跳跃连接。\n",
    "    当输入输出维度不同时（strides>1），使用1x1卷积进行投影。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filters : int\n",
    "        卷积层的滤波器数量\n",
    "    strides : int, default=1\n",
    "        第一个卷积层的步幅。strides>1时进行下采样\n",
    "    activation : str or callable, default='relu'\n",
    "        激活函数\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - 使用BN-before-activation的顺序（原始ResNet论文）\n",
    "    - 卷积层不使用偏置（use_bias=False），因为BN会学习偏置\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.strides = strides\n",
    "        self.activation_fn = keras.activations.get(activation)\n",
    "        \n",
    "        # 主路径：两个3x3卷积 + BN\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv2D(\n",
    "                filters, kernel_size=3, strides=strides,\n",
    "                padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal'\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation(activation),\n",
    "            keras.layers.Conv2D(\n",
    "                filters, kernel_size=3, strides=1,\n",
    "                padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal'\n",
    "            ),\n",
    "            keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        \n",
    "        # 跳跃连接：当维度变化时需要投影\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                keras.layers.Conv2D(\n",
    "                    filters, kernel_size=1, strides=strides,\n",
    "                    padding='same', use_bias=False,\n",
    "                    kernel_initializer='he_normal'\n",
    "                ),\n",
    "                keras.layers.BatchNormalization()\n",
    "            ]\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        # 主路径前向传播\n",
    "        z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            if isinstance(layer, keras.layers.BatchNormalization):\n",
    "                z = layer(z, training=training)\n",
    "            else:\n",
    "                z = layer(z)\n",
    "        \n",
    "        # 跳跃连接\n",
    "        skip_z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            if isinstance(layer, keras.layers.BatchNormalization):\n",
    "                skip_z = layer(skip_z, training=training)\n",
    "            else:\n",
    "                skip_z = layer(skip_z)\n",
    "        \n",
    "        # 残差相加并激活\n",
    "        return self.activation_fn(z + skip_z)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'strides': self.strides\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试残差单元\n",
    "test_input = np.random.randn(2, 32, 32, 64).astype(np.float32)\n",
    "\n",
    "# 不改变维度的残差块\n",
    "res_unit_same = ResidualUnit(filters=64, strides=1)\n",
    "output_same = res_unit_same(test_input)\n",
    "print(f\"输入形状: {test_input.shape}\")\n",
    "print(f\"strides=1 输出形状: {output_same.shape}\")\n",
    "\n",
    "# 下采样的残差块\n",
    "res_unit_down = ResidualUnit(filters=128, strides=2)\n",
    "output_down = res_unit_down(test_input)\n",
    "print(f\"strides=2 输出形状: {output_down.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2b3c4",
   "metadata": {},
   "source": [
    "## 第二部分：构建ResNet-34\n",
    "\n",
    "### 2.1 ResNet-34架构\n",
    "\n",
    "| 阶段 | 输出尺寸 | 残差块配置 |\n",
    "|------|---------|------------|\n",
    "| Conv1 | 112×112 | 7×7, 64, stride 2 |\n",
    "| Pool | 56×56 | 3×3 max pool, stride 2 |\n",
    "| Conv2_x | 56×56 | [3×3, 64] × 3 |\n",
    "| Conv3_x | 28×28 | [3×3, 128] × 4 |\n",
    "| Conv4_x | 14×14 | [3×3, 256] × 6 |\n",
    "| Conv5_x | 7×7 | [3×3, 512] × 3 |\n",
    "| GAP | 1×1 | Global Average Pooling |\n",
    "| FC | 1000 | Fully Connected |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet34(input_shape=(224, 224, 3), num_classes=1000):\n",
    "    \"\"\"\n",
    "    构建ResNet-34模型\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : tuple\n",
    "        输入图像形状\n",
    "    num_classes : int\n",
    "        分类类别数\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    keras.Model\n",
    "        ResNet-34模型\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name='ResNet34')\n",
    "    \n",
    "    # Stage 1: 初始卷积层\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        64, kernel_size=7, strides=2, padding='same',\n",
    "        use_bias=False, input_shape=input_shape,\n",
    "        kernel_initializer='he_normal',\n",
    "        name='conv1'\n",
    "    ))\n",
    "    model.add(keras.layers.BatchNormalization(name='bn1'))\n",
    "    model.add(keras.layers.Activation('relu', name='relu1'))\n",
    "    model.add(keras.layers.MaxPool2D(\n",
    "        pool_size=3, strides=2, padding='same', name='pool1'\n",
    "    ))\n",
    "    \n",
    "    # ResNet-34 残差块配置: [3, 4, 6, 3]\n",
    "    # 对应滤波器数量: [64, 128, 256, 512]\n",
    "    block_config = [\n",
    "        (64, 3),   # conv2_x: 3个块，64个滤波器\n",
    "        (128, 4),  # conv3_x: 4个块，128个滤波器\n",
    "        (256, 6),  # conv4_x: 6个块，256个滤波器\n",
    "        (512, 3)   # conv5_x: 3个块，512个滤波器\n",
    "    ]\n",
    "    \n",
    "    prev_filters = 64\n",
    "    for stage_idx, (filters, num_blocks) in enumerate(block_config):\n",
    "        for block_idx in range(num_blocks):\n",
    "            # 每个stage的第一个块可能需要下采样\n",
    "            if block_idx == 0 and filters != prev_filters:\n",
    "                strides = 2\n",
    "            else:\n",
    "                strides = 1\n",
    "            \n",
    "            model.add(ResidualUnit(\n",
    "                filters, strides=strides,\n",
    "                name=f'conv{stage_idx+2}_block{block_idx+1}'\n",
    "            ))\n",
    "        prev_filters = filters\n",
    "    \n",
    "    # 分类头\n",
    "    model.add(keras.layers.GlobalAveragePooling2D(name='avg_pool'))\n",
    "    model.add(keras.layers.Dense(\n",
    "        num_classes, activation='softmax',\n",
    "        kernel_initializer='he_normal',\n",
    "        name='predictions'\n",
    "    ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建完整的ResNet-34\n",
    "resnet34 = build_resnet34(input_shape=(224, 224, 3), num_classes=1000)\n",
    "\n",
    "# 显示模型摘要\n",
    "print(\"ResNet-34 模型结构:\")\n",
    "print(f\"总层数: {len(resnet34.layers)}\")\n",
    "print(f\"总参数量: {resnet34.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f5",
   "metadata": {},
   "source": [
    "## 第三部分：简化版ResNet用于Fashion MNIST\n",
    "\n",
    "由于Fashion MNIST图像较小(28×28)，我们构建一个简化版ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mini_resnet(input_shape=(28, 28, 1), num_classes=10):\n",
    "    \"\"\"\n",
    "    构建适用于小图像的简化版ResNet\n",
    "    \n",
    "    针对28×28图像优化，去除初始下采样层\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name='MiniResNet')\n",
    "    \n",
    "    # 初始卷积（不下采样）\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        32, kernel_size=3, padding='same',\n",
    "        use_bias=False, input_shape=input_shape,\n",
    "        kernel_initializer='he_normal'\n",
    "    ))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    \n",
    "    # 简化的残差块配置\n",
    "    block_config = [\n",
    "        (32, 2),   # 2个块，32个滤波器，28×28\n",
    "        (64, 2),   # 2个块，64个滤波器，14×14\n",
    "        (128, 2),  # 2个块，128个滤波器，7×7\n",
    "    ]\n",
    "    \n",
    "    prev_filters = 32\n",
    "    for stage_idx, (filters, num_blocks) in enumerate(block_config):\n",
    "        for block_idx in range(num_blocks):\n",
    "            if block_idx == 0 and filters != prev_filters:\n",
    "                strides = 2\n",
    "            else:\n",
    "                strides = 1\n",
    "            \n",
    "            model.add(ResidualUnit(filters, strides=strides))\n",
    "        prev_filters = filters\n",
    "    \n",
    "    # 分类头\n",
    "    model.add(keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(\n",
    "        num_classes, activation='softmax',\n",
    "        kernel_initializer='he_normal'\n",
    "    ))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 构建小型ResNet\n",
    "mini_resnet = build_mini_resnet()\n",
    "mini_resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3a4b5",
   "metadata": {},
   "source": [
    "## 第四部分：训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载Fashion MNIST数据\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 数据预处理\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# 划分验证集\n",
    "X_val, y_val = X_train[-5000:], y_train[-5000:]\n",
    "X_train, y_train = X_train[:-5000], y_train[:-5000]\n",
    "\n",
    "print(f\"训练集: {X_train.shape}\")\n",
    "print(f\"验证集: {X_val.shape}\")\n",
    "print(f\"测试集: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "mini_resnet.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 回调函数\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=5, restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "# 训练参数\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(\"开始训练...\")\n",
    "history = mini_resnet.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练过程\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 损失曲线\n",
    "axes[0].plot(history.history['loss'], label='训练损失')\n",
    "axes[0].plot(history.history['val_loss'], label='验证损失')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('损失曲线')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 准确率曲线\n",
    "axes[1].plot(history.history['accuracy'], label='训练准确率')\n",
    "axes[1].plot(history.history['val_accuracy'], label='验证准确率')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('准确率曲线')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估\n",
    "test_loss, test_accuracy = mini_resnet.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"测试集损失: {test_loss:.4f}\")\n",
    "print(f\"测试集准确率: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4f5a6",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### ResNet核心要点\n",
    "\n",
    "1. **残差连接**解决了深度网络的退化问题\n",
    "2. **恒等映射**通过跳跃连接使梯度能直接回传\n",
    "3. **BatchNorm**加速训练并稳定梯度\n",
    "\n",
    "### ResNet变体\n",
    "\n",
    "| 模型 | 层数 | 残差块配置 | 参数量 |\n",
    "|-----|------|-----------|--------|\n",
    "| ResNet-18 | 18 | [2,2,2,2] | 11.7M |\n",
    "| ResNet-34 | 34 | [3,4,6,3] | 21.8M |\n",
    "| ResNet-50 | 50 | [3,4,6,3] | 25.6M |\n",
    "| ResNet-101 | 101 | [3,4,23,3] | 44.5M |\n",
    "| ResNet-152 | 152 | [3,8,36,3] | 60.2M |\n",
    "\n",
    "### 进一步学习\n",
    "\n",
    "- ResNet-V2（预激活残差块）\n",
    "- ResNeXt（分组卷积）\n",
    "- SE-ResNet（通道注意力）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
