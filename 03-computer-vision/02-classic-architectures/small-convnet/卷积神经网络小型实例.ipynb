{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-section",
   "metadata": {},
   "source": [
    "# 卷积神经网络基础实践：MNIST手写数字识别\n",
    "\n",
    "## 概述\n",
    "\n",
    "本教程实现一个经典的卷积神经网络(Convolutional Neural Network, CNN)，用于MNIST手写数字识别任务。\n",
    "通过本教程，你将深入理解CNN的核心组件及其工作原理。\n",
    "\n",
    "## 知识要点\n",
    "\n",
    "1. **卷积层(Conv2D)**：提取图像的局部特征，通过可学习的滤波器在输入上滑动进行特征提取\n",
    "2. **池化层(MaxPooling2D)**：对特征图进行下采样，减少参数数量并增强平移不变性\n",
    "3. **全连接层(Dense)**：将提取的特征映射到最终的分类结果\n",
    "4. **激活函数**：ReLU用于隐藏层引入非线性，Softmax用于输出层生成概率分布\n",
    "\n",
    "## 网络架构\n",
    "\n",
    "```\n",
    "输入层 (28×28×1)\n",
    "    ↓\n",
    "Conv2D (32 filters, 3×3) → ReLU → 输出: 26×26×32\n",
    "    ↓\n",
    "MaxPooling2D (2×2) → 输出: 13×13×32\n",
    "    ↓\n",
    "Conv2D (64 filters, 3×3) → ReLU → 输出: 11×11×64\n",
    "    ↓\n",
    "MaxPooling2D (2×2) → 输出: 5×5×64\n",
    "    ↓\n",
    "Conv2D (64 filters, 3×3) → ReLU → 输出: 3×3×64\n",
    "    ↓\n",
    "Flatten → 输出: 576\n",
    "    ↓\n",
    "Dense (64 units) → ReLU\n",
    "    ↓\n",
    "Dense (10 units) → Softmax → 输出: 10类概率\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-setup",
   "metadata": {},
   "source": [
    "## 1. 环境配置与依赖导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "卷积神经网络基础实现\n",
    "使用Keras构建CNN进行MNIST手写数字识别\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# 抑制TensorFlow信息日志\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Keras组件导入\n",
    "from keras import layers, models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 设置随机种子，确保结果可复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 中文显示配置\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境配置完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "## 2. 数据加载与预处理\n",
    "\n",
    "MNIST数据集包含70,000张28×28像素的灰度手写数字图像：\n",
    "- 训练集：60,000张\n",
    "- 测试集：10,000张\n",
    "- 类别：0-9共10个数字\n",
    "\n",
    "### 预处理步骤\n",
    "1. **维度调整**：将图像从(28,28)调整为(28,28,1)以适配卷积层输入要求\n",
    "2. **归一化**：将像素值从[0,255]缩放到[0,1]，加速收敛并提升稳定性\n",
    "3. **One-Hot编码**：将标签转换为向量形式，适配Softmax输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    加载并预处理MNIST数据集\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_images, train_labels, test_images, test_labels)\n",
    "               预处理后的训练和测试数据\n",
    "    \"\"\"\n",
    "    # 加载原始数据\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    \n",
    "    print(f\"原始训练集形状: {train_images.shape}\")\n",
    "    print(f\"原始测试集形状: {test_images.shape}\")\n",
    "    \n",
    "    # 维度调整：添加通道维度\n",
    "    # 卷积层期望输入形状为 (batch_size, height, width, channels)\n",
    "    train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "    test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "    \n",
    "    # 归一化：将像素值缩放到[0,1]区间\n",
    "    # 这有助于梯度下降更快收敛\n",
    "    train_images = train_images.astype('float32') / 255.0\n",
    "    test_images = test_images.astype('float32') / 255.0\n",
    "    \n",
    "    # One-Hot编码\n",
    "    # 将整数标签转换为二进制类别矩阵\n",
    "    # 例如：3 → [0,0,0,1,0,0,0,0,0,0]\n",
    "    train_labels = to_categorical(train_labels, num_classes=10)\n",
    "    test_labels = to_categorical(test_labels, num_classes=10)\n",
    "    \n",
    "    print(f\"处理后训练集形状: {train_images.shape}\")\n",
    "    print(f\"标签形状: {train_labels.shape}\")\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "# 执行数据加载\n",
    "train_images, train_labels, test_images, test_labels = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-section",
   "metadata": {},
   "source": [
    "### 数据可视化\n",
    "\n",
    "查看数据集中的样本图像，直观理解数据特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(images, labels, num_samples=10):\n",
    "    \"\"\"\n",
    "    可视化数据样本\n",
    "    \n",
    "    Args:\n",
    "        images: 图像数组\n",
    "        labels: One-Hot编码的标签\n",
    "        num_samples: 显示的样本数量\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # 随机选择样本索引\n",
    "    indices = np.random.choice(len(images), num_samples, replace=False)\n",
    "    \n",
    "    for ax, idx in zip(axes, indices):\n",
    "        # 显示图像，squeeze去除单通道维度\n",
    "        ax.imshow(images[idx].squeeze(), cmap='gray')\n",
    "        # 从One-Hot编码恢复原始标签\n",
    "        label = np.argmax(labels[idx])\n",
    "        ax.set_title(f'Label: {label}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('MNIST Sample Images', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 展示训练集样本\n",
    "visualize_samples(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-section",
   "metadata": {},
   "source": [
    "## 3. 构建卷积神经网络\n",
    "\n",
    "### 3.1 卷积层原理\n",
    "\n",
    "卷积操作通过滤波器(kernel)在输入图像上滑动，计算局部区域的加权和：\n",
    "\n",
    "**输出尺寸计算公式**（无padding时）：\n",
    "$$output\\_size = input\\_size - kernel\\_size + 1$$\n",
    "\n",
    "例如：输入28×28，3×3卷积核 → 输出26×26\n",
    "\n",
    "### 3.2 池化层原理\n",
    "\n",
    "最大池化选取窗口内的最大值，实现特征降维：\n",
    "- 减少计算量和参数数量\n",
    "- 增强特征的平移不变性\n",
    "- 扩大后续层的感受野"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape=(28, 28, 1), num_classes=10):\n",
    "    \"\"\"\n",
    "    构建卷积神经网络模型\n",
    "    \n",
    "    Args:\n",
    "        input_shape: 输入图像形状，默认(28, 28, 1)\n",
    "        num_classes: 分类类别数，默认10\n",
    "    \n",
    "    Returns:\n",
    "        model: 编译好的Keras模型\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name='SimpleCNN')\n",
    "    \n",
    "    # ========== 特征提取部分 ==========\n",
    "    \n",
    "    # 第一个卷积块\n",
    "    # 32个3×3滤波器，提取低级特征（边缘、角点等）\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        input_shape=input_shape,\n",
    "        name='conv1'\n",
    "    ))\n",
    "    # 2×2最大池化，将特征图尺寸减半\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), name='pool1'))\n",
    "    \n",
    "    # 第二个卷积块\n",
    "    # 64个滤波器，提取中级特征（纹理、局部形状）\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        name='conv2'\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), name='pool2'))\n",
    "    \n",
    "    # 第三个卷积块\n",
    "    # 继续提取高级特征（数字的整体形状）\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        name='conv3'\n",
    "    ))\n",
    "    \n",
    "    # ========== 分类器部分 ==========\n",
    "    \n",
    "    # 展平层：将3D特征图转换为1D向量\n",
    "    # 3×3×64 = 576个特征\n",
    "    model.add(layers.Flatten(name='flatten'))\n",
    "    \n",
    "    # 全连接层：学习特征组合\n",
    "    model.add(layers.Dense(64, activation='relu', name='fc1'))\n",
    "    \n",
    "    # 输出层：Softmax激活产生概率分布\n",
    "    model.add(layers.Dense(num_classes, activation='softmax', name='output'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# 构建模型\n",
    "model = build_cnn_model()\n",
    "\n",
    "# 查看模型架构\n",
    "print(\"模型架构概览：\")\n",
    "print(\"=\" * 65)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parameter-analysis",
   "metadata": {},
   "source": [
    "### 3.3 参数量分析\n",
    "\n",
    "理解每层的参数计算对于模型设计至关重要：\n",
    "\n",
    "| 层 | 参数计算 | 参数量 |\n",
    "|---|---|---|\n",
    "| conv1 | (3×3×1+1)×32 | 320 |\n",
    "| conv2 | (3×3×32+1)×64 | 18,496 |\n",
    "| conv3 | (3×3×64+1)×64 | 36,928 |\n",
    "| fc1 | (576+1)×64 | 36,928 |\n",
    "| output | (64+1)×10 | 650 |\n",
    "| **总计** | | **93,322** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-section",
   "metadata": {},
   "source": [
    "## 4. 模型编译与训练\n",
    "\n",
    "### 训练配置\n",
    "\n",
    "- **优化器(Adam)**：自适应学习率优化算法，结合了Momentum和RMSprop的优点\n",
    "- **损失函数(Categorical Crossentropy)**：多分类任务的标准损失函数\n",
    "- **评估指标(Accuracy)**：分类正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-compile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"模型编译完成\")\n",
    "print(f\"优化器: Adam\")\n",
    "print(f\"损失函数: Categorical Crossentropy\")\n",
    "print(f\"评估指标: Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练参数配置\n",
    "EPOCHS = 5          # 训练轮次\n",
    "BATCH_SIZE = 64     # 批次大小\n",
    "VALIDATION_SPLIT = 0.1  # 验证集比例\n",
    "\n",
    "print(f\"开始训练...\")\n",
    "print(f\"训练轮次: {EPOCHS}\")\n",
    "print(f\"批次大小: {BATCH_SIZE}\")\n",
    "print(f\"验证集比例: {VALIDATION_SPLIT * 100}%\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n训练完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "history-section",
   "metadata": {},
   "source": [
    "### 训练历史可视化\n",
    "\n",
    "通过可视化训练曲线，可以判断模型是否存在过拟合或欠拟合问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    绘制训练历史曲线\n",
    "    \n",
    "    Args:\n",
    "        history: model.fit()返回的History对象\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # 准确率曲线\n",
    "    axes[0].plot(history.history['accuracy'], label='Training', marker='o')\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Validation', marker='s')\n",
    "    axes[0].set_title('Model Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 损失曲线\n",
    "    axes[1].plot(history.history['loss'], label='Training', marker='o')\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation', marker='s')\n",
    "    axes[1].set_title('Model Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 绘制训练历史\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-section",
   "metadata": {},
   "source": [
    "## 5. 模型评估\n",
    "\n",
    "在测试集上评估模型的泛化性能，测试集数据在训练过程中从未被模型见过。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集评估\n",
    "print(\"在测试集上评估模型...\")\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"测试集评估结果\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"测试损失: {test_loss:.4f}\")\n",
    "print(f\"测试准确率: {test_accuracy:.4f} ({test_accuracy * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prediction-section",
   "metadata": {},
   "source": [
    "### 预测结果可视化\n",
    "\n",
    "查看模型在测试样本上的预测结果，包括正确和错误的预测案例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prediction-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, images, labels, num_samples=10):\n",
    "    \"\"\"\n",
    "    可视化模型预测结果\n",
    "    \n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        images: 测试图像\n",
    "        labels: 真实标签(One-Hot)\n",
    "        num_samples: 显示样本数量\n",
    "    \"\"\"\n",
    "    # 随机选择样本\n",
    "    indices = np.random.choice(len(images), num_samples, replace=False)\n",
    "    sample_images = images[indices]\n",
    "    sample_labels = labels[indices]\n",
    "    \n",
    "    # 进行预测\n",
    "    predictions = model.predict(sample_images, verbose=0)\n",
    "    \n",
    "    # 可视化\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for ax, img, true_label, pred in zip(axes, sample_images, sample_labels, predictions):\n",
    "        true_class = np.argmax(true_label)\n",
    "        pred_class = np.argmax(pred)\n",
    "        confidence = pred[pred_class] * 100\n",
    "        \n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        \n",
    "        # 根据预测正确与否设置标题颜色\n",
    "        color = 'green' if true_class == pred_class else 'red'\n",
    "        ax.set_title(\n",
    "            f'True: {true_class}\\nPred: {pred_class} ({confidence:.1f}%)',\n",
    "            color=color,\n",
    "            fontsize=10\n",
    "        )\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Model Predictions (Green=Correct, Red=Wrong)', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 展示预测结果\n",
    "visualize_predictions(model, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confusion-section",
   "metadata": {},
   "source": [
    "### 混淆矩阵分析\n",
    "\n",
    "混淆矩阵能够直观展示模型在各类别上的分类表现，帮助识别容易混淆的数字对。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(model, images, labels):\n",
    "    \"\"\"\n",
    "    绘制混淆矩阵\n",
    "    \n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        images: 测试图像\n",
    "        labels: 真实标签(One-Hot)\n",
    "    \"\"\"\n",
    "    # 获取预测结果\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    pred_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(labels, axis=1)\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(true_classes, pred_classes)\n",
    "    \n",
    "    # 绘制热力图\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 添加数值标注\n",
    "    thresh = cm.max() / 2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha='center', va='center',\n",
    "                     color='white' if cm[i, j] > thresh else 'black',\n",
    "                     fontsize=9)\n",
    "    \n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks(range(10))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 计算每类准确率\n",
    "    print(\"\\n各类别准确率:\")\n",
    "    for i in range(10):\n",
    "        class_total = cm[i].sum()\n",
    "        class_correct = cm[i, i]\n",
    "        accuracy = class_correct / class_total * 100\n",
    "        print(f\"  数字 {i}: {accuracy:.2f}% ({class_correct}/{class_total})\")\n",
    "\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plot_confusion_matrix(model, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-section",
   "metadata": {},
   "source": [
    "## 6. 特征图可视化\n",
    "\n",
    "可视化卷积层的特征图，理解CNN如何逐层提取和抽象图像特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-visualization",
   "metadata": {},
   "outputs": [],
   "source": "def visualize_feature_maps(model, image, layer_names=None):\n    \"\"\"\n    可视化指定层的特征图\n    \n    Args:\n        model: 训练好的模型\n        image: 单张输入图像 (28, 28, 1)\n        layer_names: 要可视化的层名称列表\n    \"\"\"\n    if layer_names is None:\n        layer_names = ['conv1', 'conv2', 'conv3']\n    \n    # 构建特征提取模型（兼容Keras 2.x和3.x）\n    # 使用layers.Input显式定义输入\n    input_layer = layers.Input(shape=(28, 28, 1))\n    x = input_layer\n    layer_outputs = []\n    \n    for layer in model.layers:\n        x = layer(x)\n        if layer.name in layer_names:\n            layer_outputs.append(x)\n    \n    feature_model = models.Model(inputs=input_layer, outputs=layer_outputs)\n    \n    # 获取特征图\n    image_batch = np.expand_dims(image, axis=0)\n    feature_maps = feature_model.predict(image_batch, verbose=0)\n    \n    # 确保feature_maps是列表\n    if not isinstance(feature_maps, list):\n        feature_maps = [feature_maps]\n    \n    # 可视化每层的特征图\n    for layer_name, fmap in zip(layer_names, feature_maps):\n        n_features = min(fmap.shape[-1], 16)  # 最多显示16个特征图\n        \n        fig, axes = plt.subplots(2, 8, figsize=(14, 4))\n        axes = axes.flatten()\n        \n        for i in range(n_features):\n            axes[i].imshow(fmap[0, :, :, i], cmap='viridis')\n            axes[i].axis('off')\n        \n        # 隐藏多余的子图\n        for i in range(n_features, len(axes)):\n            axes[i].axis('off')\n        \n        plt.suptitle(f'Feature Maps - {layer_name} ({fmap.shape[1]}x{fmap.shape[2]}x{fmap.shape[3]})', \n                     fontsize=12)\n        plt.tight_layout()\n        plt.show()\n\n\n# 选择一张测试图像进行可视化\nsample_idx = np.random.randint(0, len(test_images))\nsample_image = test_images[sample_idx]\nsample_label = np.argmax(test_labels[sample_idx])\n\nprint(f\"可视化数字 {sample_label} 的特征图:\")\n\n# 显示原图\nplt.figure(figsize=(3, 3))\nplt.imshow(sample_image.squeeze(), cmap='gray')\nplt.title(f'Original Image (Label: {sample_label})')\nplt.axis('off')\nplt.show()\n\n# 显示特征图\nvisualize_feature_maps(model, sample_image)"
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## 7. 总结\n",
    "\n",
    "### 实验结果\n",
    "\n",
    "本实验实现了一个简洁而高效的CNN模型：\n",
    "- 模型参数量：约93K\n",
    "- 测试集准确率：约99%\n",
    "- 训练时间：约2分钟（5个epoch）\n",
    "\n",
    "### 核心知识点回顾\n",
    "\n",
    "1. **卷积层**：通过滤波器提取局部特征，参数共享减少模型复杂度\n",
    "2. **池化层**：下采样实现特征降维和平移不变性\n",
    "3. **全连接层**：将空间特征映射到分类空间\n",
    "4. **激活函数**：ReLU解决梯度消失，Softmax产生概率分布\n",
    "\n",
    "### 进阶方向\n",
    "\n",
    "1. **数据增强**：旋转、平移、缩放等增强泛化能力\n",
    "2. **正则化**：Dropout、L2正则化防止过拟合\n",
    "3. **批归一化**：加速训练收敛\n",
    "4. **更深的网络**：VGG、ResNet等经典架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终结果汇总\n",
    "print(\"=\" * 50)\n",
    "print(\"实验结果汇总\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"模型名称: SimpleCNN\")\n",
    "print(f\"总参数量: {model.count_params():,}\")\n",
    "print(f\"训练轮次: {EPOCHS}\")\n",
    "print(f\"最终训练准确率: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"最终验证准确率: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"测试集准确率: {test_accuracy:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}